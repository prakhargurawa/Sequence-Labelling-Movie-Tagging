{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eng-Flair-Sequence-Tagging.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "728ebdcc48fd4110a0187373d1abf319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5e3c58e2e8314c19918354c33ffd79ae",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7efe0a2d6efd45babff9b255859ea4de",
              "IPY_MODEL_cf314ec57a6842f0a2db69e9941eaaff"
            ]
          }
        },
        "5e3c58e2e8314c19918354c33ffd79ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7efe0a2d6efd45babff9b255859ea4de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_23a31a4ed7604be9837032bffd276770",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 432176557,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 432176557,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8df522dcbe60449085f8c68f6e74ac95"
          }
        },
        "cf314ec57a6842f0a2db69e9941eaaff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f5cd30104a4d48269d8cf36e84080fa0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 432M/432M [00:08&lt;00:00, 50.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7ad50fce325649e69611957a5b755f79"
          }
        },
        "23a31a4ed7604be9837032bffd276770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8df522dcbe60449085f8c68f6e74ac95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5cd30104a4d48269d8cf36e84080fa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7ad50fce325649e69611957a5b755f79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPwJWljEPvuq"
      },
      "source": [
        "# Setup Notebook and GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILSG_o7rPJXX",
        "outputId": "b0f2be51-183b-4196-8e46-0636eb090e35"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-1edc38dc-dd8b-ccf7-480b-94d2a92771b4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GllO5QzQPy41",
        "outputId": "c518277b-8585-4281-eeca-5a066ab93118"
      },
      "source": [
        "!lscpu |grep 'Model name'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model name:          Intel(R) Xeon(R) CPU @ 2.00GHz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLWrdX3XP1ul"
      },
      "source": [
        "# Sequence Tagging Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHct7aZWP2jl"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLGqDNl8P65k",
        "outputId": "f2d64b52-b326-4b90-dc51-e7eb74274a01"
      },
      "source": [
        "! pip install flair # https://github.com/flairNLP/flair"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flair\n",
            "  Downloading flair-0.8.0.post1-py3-none-any.whl (284 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 25.9 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20 kB 33.3 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 30 kB 40.0 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 40 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 51 kB 18.5 MB/s eta 0:00:01\r\u001b[K     |███████                         | 61 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 71 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 81 kB 15.3 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 92 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 102 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 112 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 122 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 133 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 143 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 153 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 163 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 174 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 184 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 194 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 204 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 215 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 225 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 235 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 245 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 256 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 266 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 276 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 284 kB 15.6 MB/s \n",
            "\u001b[?25hCollecting mpld3==0.3\n",
            "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
            "\u001b[K     |████████████████████████████████| 788 kB 31.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.2)\n",
            "Collecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 67.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n",
            "Requirement already satisfied: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n",
            "Collecting bpemb>=0.3.2\n",
            "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 70.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n",
            "Collecting gdown==3.12.2\n",
            "  Downloading gdown-3.12.2.tar.gz (8.2 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading segtok-1.5.10.tar.gz (25 kB)\n",
            "Collecting transformers>=4.0.0\n",
            "  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 58.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading sqlitedict-1.7.0.tar.gz (28 kB)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.41.1)\n",
            "Collecting torch<=1.7.1,>=1.5.0\n",
            "  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8 MB 13 kB/s \n",
            "\u001b[?25hCollecting deprecated>=1.2.4\n",
            "  Downloading Deprecated-1.2.12-py2.py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2019.12.20)\n",
            "Requirement already satisfied: numpy<1.20.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.19.5)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.0.15-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.4 MB/s \n",
            "\u001b[?25hCollecting janome\n",
            "  Downloading Janome-0.4.1-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7 MB 75 kB/s \n",
            "\u001b[?25hCollecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (0.22.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (1.15.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (3.0.12)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (5.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (3.11.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (2.5.1)\n",
            "Collecting overrides<4.0.0,>=3.0.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "Collecting requests\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 947 kB/s \n",
            "\u001b[?25hCollecting importlib-metadata<4.0.0,>=3.7.0\n",
            "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.0.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2021.5.30)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.0.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 66.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 55.0 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 72.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (21.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->flair) (7.1.2)\n",
            "Building wheels for collected packages: gdown, mpld3, overrides, segtok, sqlitedict, ftfy, langdetect\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-3.12.2-py3-none-any.whl size=9705 sha256=5d09649d6600f1760b05e680feec45599793b849d214e242e8426cb111805457\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/e0/7e/726e872a53f7358b4b96a9975b04e98113b005cd8609a63abc\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116701 sha256=db7d29102fbe6117139c6db0aec6be8f8c6d96dc2e1febf78d9decfff502e6d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/70/6a/1c79e59951a41b4045497da187b2724f5659ca64033cf4548e\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10188 sha256=d22e6bb90307f7784b4e8e05b09fce697e340128c16397994dce1f209544a0af\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-py3-none-any.whl size=25030 sha256=304ecaf506e353db43d3814dae799797af62d33f470afe664a6eacced971c743\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/b7/d0/a121106e61339eee5ed083bc230b1c8dc422c49a5a28c2addd\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-py3-none-any.whl size=14392 sha256=bb92ae70c98f4de23fd9831590864435671d86aa8f6393e50e0f1fcfa326e165\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/94/06/18c0e83e9e227da8f3582810b51f319bbfd181e508676a56c8\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41934 sha256=c7bdd8359f3668032b862a6baa95f2061a7d5578c2550833029f320e2b4d92fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993241 sha256=e7eee230a63b5801aebc8f16eedb582e7123765ad1db3ea3ea75d1f60b9c6918\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "Successfully built gdown mpld3 overrides segtok sqlitedict ftfy langdetect\n",
            "Installing collected packages: requests, importlib-metadata, tokenizers, sentencepiece, sacremoses, pyyaml, overrides, huggingface-hub, transformers, torch, sqlitedict, segtok, mpld3, langdetect, konoha, janome, gdown, ftfy, deprecated, bpemb, flair\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.6.1\n",
            "    Uninstalling importlib-metadata-4.6.1:\n",
            "      Successfully uninstalled importlib-metadata-4.6.1\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 3.6.4\n",
            "    Uninstalling gdown-3.6.4:\n",
            "      Successfully uninstalled gdown-3.6.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.10.0+cu102 requires torch==1.9.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.7.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed bpemb-0.3.3 deprecated-1.2.12 flair-0.8.0.post1 ftfy-6.0.3 gdown-3.12.2 huggingface-hub-0.0.12 importlib-metadata-3.10.1 janome-0.4.1 konoha-4.6.5 langdetect-1.0.9 mpld3-0.3 overrides-3.1.0 pyyaml-5.4.1 requests-2.26.0 sacremoses-0.0.45 segtok-1.5.10 sentencepiece-0.1.95 sqlitedict-1.7.0 tokenizers-0.10.3 torch-1.7.1 transformers-4.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nt7ObhjvP-Z-"
      },
      "source": [
        "Our aim to successfully train a custom NER/Sequence Tagging model. We are going to use Flair library (Link: https://github.com/flairNLP/flair), which is a powerful framework for Natural language processing build using PyTorch and even provides its own flair embeddings, assistance in number of NLP tasks like POS tagging, Named entity recognization, text classification. It even includes embeddings trained using powerful models like BERT and ELMO."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd0XwFdIQBC2"
      },
      "source": [
        "## Simple NER task performed using Flair"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237,
          "referenced_widgets": [
            "728ebdcc48fd4110a0187373d1abf319",
            "5e3c58e2e8314c19918354c33ffd79ae",
            "7efe0a2d6efd45babff9b255859ea4de",
            "cf314ec57a6842f0a2db69e9941eaaff",
            "23a31a4ed7604be9837032bffd276770",
            "8df522dcbe60449085f8c68f6e74ac95",
            "f5cd30104a4d48269d8cf36e84080fa0",
            "7ad50fce325649e69611957a5b755f79"
          ]
        },
        "id": "wMrrKZ0uQDA0",
        "outputId": "b37cce14-1dda-4761-ee43-25e3ccd35464"
      },
      "source": [
        "from flair.data import Sentence                               # The sentence objects holds a sentence that we may want to embed or tag\n",
        "from flair.models import SequenceTagger\n",
        "\n",
        "tagger = SequenceTagger.load('ner')                           # Pre-trained Sequence tagger of Flair\n",
        "sentence = Sentence('George Washington went to Washington .') # Sentence holds a textual sentence and is essentially a list of Token\n",
        "tagger.predict(sentence)\n",
        "print(sentence.to_tagged_string())\n",
        "\n",
        "for entity in sentence.get_spans('ner'):\n",
        "  print(entity)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-10 22:52:02,984 --------------------------------------------------------------------------------\n",
            "2021-08-10 22:52:02,985 The model key 'ner' now maps to 'https://huggingface.co/flair/ner-english' on the HuggingFace ModelHub\n",
            "2021-08-10 22:52:02,986  - The most current version of the model is automatically downloaded from there.\n",
            "2021-08-10 22:52:02,988  - (you can alternatively manually download the original model at https://nlp.informatik.hu-berlin.de/resources/models/ner/en-ner-conll03-v0.4.pt)\n",
            "2021-08-10 22:52:02,989 --------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "728ebdcc48fd4110a0187373d1abf319",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=432176557.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "2021-08-10 22:52:11,577 loading file /root/.flair/models/ner-english/4f4cdab26f24cb98b732b389e6cebc646c36f54cfd6e0b7d3b90b25656e4262f.8baa8ae8795f4df80b28e7f7b61d788ecbb057d1dc85aacb316f1bd02837a4a4\n",
            "George <B-PER> Washington <E-PER> went to Washington <S-LOC> .\n",
            "Span [1,2]: \"George Washington\"   [− Labels: PER (0.9989)]\n",
            "Span [5]: \"Washington\"   [− Labels: LOC (0.9942)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiMhXgo1QE1t",
        "outputId": "7fbbaf10-3b23-4d72-8526-272c5392b611"
      },
      "source": [
        "print(sentence.to_dict(tag_type='ner')) # confidence score of each predicted state"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': 'George Washington went to Washington .', 'labels': [], 'entities': [{'text': 'George Washington', 'start_pos': 0, 'end_pos': 17, 'labels': [PER (0.9989)]}, {'text': 'Washington', 'start_pos': 26, 'end_pos': 36, 'labels': [LOC (0.9942)]}]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDPwW3F6QHnl"
      },
      "source": [
        "## Learning on custom entities/ Sequence Tagging\n",
        "The task described in the given problem is generally defined as sequence tagging or sequence labelling in the literature. \n",
        "\n",
        "According to Wikipedia: In machine learning, sequence labeling is a type of pattern recognition task that involves the algorithmic assignment of a categorical label to each member of a sequence of observed values. A common example of a sequence labeling task is part of speech tagging, which seeks to assign a part of speech to each word in an input sentence or document. (Reference : https://en.wikipedia.org/wiki/Sequence_labeling)\n",
        "\n",
        "Chapter 9 of Book by Dan Jurafsky and James H. Martin, Speech and Language Processing goes in great depth by presenting deep learning models for sequence processing. (Reference: https://web.stanford.edu/~jurafsky/slp3/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAd7cAwtQJ-U"
      },
      "source": [
        "#### Importing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-tafbPoQLhd",
        "outputId": "d1800f35-382d-4acb-8a96-74f4a1a97ed7"
      },
      "source": [
        "from flair.data import Corpus # Corpus represents a dataset that you use to train a model. It consists of a list of train sentences, a list of dev sentences, and a list of test sentences, which correspond to the training, validation and testing split during model training\n",
        "from flair.datasets import ColumnCorpus # To read a dataset, column structure as a dictionary and instantiate a ColumnCorpus\n",
        "\n",
        "# define columns, our data is in a format where first column is tag and second is word\n",
        "columns = {0:'ner',1:'text'}\n",
        "data_folder = './'\n",
        "# init a corpus using column format, data folder and the names of the train and test files\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='engtrain.txt',\n",
        "                              test_file='engtest.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-10 22:52:41,245 Reading data from .\n",
            "2021-08-10 22:52:41,247 Train: engtrain.txt\n",
            "2021-08-10 22:52:41,249 Dev: None\n",
            "2021-08-10 22:52:41,250 Test: engtest.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZhYokX7QTk0"
      },
      "source": [
        "Note : the Column Corpus reads the data, in following format\n",
        "* Sentences in the corpus are separated by an empty line\n",
        "* Each row have two columns, the word and the tag that needs to be learned.\n",
        "\n",
        "Our input data was in desired format so no data preprocessing was required in this case. Otherwise an additional step of preprocessing for converting data in format that ColumnCorpus accepts would be necessary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FVMVdYJQXFc"
      },
      "source": [
        "#### Train/Test set size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3w2Xu-OYQX5V",
        "outputId": "a12eebef-fe62-44e9-a8b1-41710bbd5590"
      },
      "source": [
        "print(\"Length of Training set: \",len(corpus.train)) # Number of example in training set\n",
        "print(\"Length of Test set: \",len(corpus.test))      # Number of example in test set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Training set:  8797\n",
            "Length of Test set:  2443\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K93lzKQEQdMV"
      },
      "source": [
        "#### Displaying an example from train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvKFRckrQfkm",
        "outputId": "a44dfc37-b74a-4e9b-b0f7-0cef10d9c3a1"
      },
      "source": [
        "print(corpus.train[0].to_tagged_string('ner')) # Displaying first example from train set\n",
        "\"\"\"\n",
        "O\tshow\n",
        "O\tme\n",
        "O\tfilms\n",
        "O\twith\n",
        "B-ACTOR\tdrew\n",
        "I-ACTOR\tbarrymore\n",
        "O\tfrom\n",
        "O\tthe\n",
        "B-YEAR\t1980s\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "show me films with drew <B-ACTOR> barrymore <I-ACTOR> from the 1980s <B-YEAR>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj9-b9JCRKIt"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpWyHEuARJIc"
      },
      "source": [
        "tag_type = 'ner' # tag to predict, column (we are predicting column 'ner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0VgHrWIROvd",
        "outputId": "6146ceae-37c1-4688-deee-5118ab6f3758"
      },
      "source": [
        "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type) # create a tag dictionary from the corpus\n",
        "print(tag_dictionary) # classes of tags from which predictions will belong"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dictionary with 28 tags: <unk>, O, B-ACTOR, I-ACTOR, B-YEAR, B-TITLE, B-GENRE, I-GENRE, B-DIRECTOR, I-DIRECTOR, B-SONG, I-SONG, B-PLOT, I-PLOT, B-REVIEW, B-CHARACTER, I-CHARACTER, B-RATING, B-RATINGS_AVERAGE, I-RATINGS_AVERAGE, I-TITLE, I-RATING, B-TRAILER, I-REVIEW, I-YEAR, I-TRAILER, <START>, <STOP>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O58r8cmmRRit"
      },
      "source": [
        "#### Word Embeddings\n",
        "Flair provides a number of pre-trained model for embedding creation such as BERT, ELMO. (Reference : https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_3_WORD_EMBEDDING.md). We will be using glove embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4troBVPRSaG",
        "outputId": "750f7a0b-74c7-443c-ea31-6c66b0cfd8a9"
      },
      "source": [
        "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings \n",
        "# StackedEmbeddings : combine different embeddings together, for instance if you want to use both traditional embeddings together with contextual string embeddings.\n",
        "from typing import List\n",
        "embedding_types : List[TokenEmbeddings] = [\n",
        "        WordEmbeddings('glove'), # GloVe embeddings are PyTorch vectors of dimensionality 100.\n",
        "        ## other embeddings\n",
        "        ]\n",
        "embeddings : StackedEmbeddings = StackedEmbeddings(\n",
        "                                 embeddings=embedding_types)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-10 22:56:08,207 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmpkvkg3904\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 160000128/160000128 [00:04<00:00, 38409676.22B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-08-10 22:56:12,443 copying /tmp/tmpkvkg3904 to cache at /root/.flair/embeddings/glove.gensim.vectors.npy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-08-10 22:56:12,591 removing temp file /tmp/tmpkvkg3904\n",
            "2021-08-10 22:56:14,729 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim not found in cache, downloading to /tmp/tmpt5j6b11u\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 21494764/21494764 [00:00<00:00, 34372858.83B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-08-10 22:56:15,430 copying /tmp/tmpt5j6b11u to cache at /root/.flair/embeddings/glove.gensim\n",
            "2021-08-10 22:56:15,453 removing temp file /tmp/tmpt5j6b11u\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnWG23_lRiHl"
      },
      "source": [
        "#### Training a Sequence Tagger\n",
        "Sequence Tagger used here is a bi-directional LSTM (Reference : https://en.wikipedia.org/wiki/Bidirectional_recurrent_neural_networks) for better generalization and capturing of relationship and sequencing among different tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roCn0Vm_RizW",
        "outputId": "446aa82e-e23c-409b-aab4-ccd1229f2241"
      },
      "source": [
        "from flair.models import SequenceTagger # initialize sequence tagger\n",
        "\n",
        "# Sequence tagger model source code : https://github.com/flairNLP/flair/blob/master/flair/models/sequence_tagger_model.py\n",
        "tagger: SequenceTagger = SequenceTagger(hidden_size=256,                # number of hidden states in RNN\n",
        "                                        embeddings=embeddings,          # word embeddings used in tagger\n",
        "                                        tag_dictionary=tag_dictionary,  # dictionary of tags you want to predict\n",
        "                                        tag_type=tag_type,              # string identifier for tag type\n",
        "                                        use_crf=True)                   # if True use CRF decoder, else project directly to tag space\n",
        "print(tagger)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings('glove')\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (rnn): LSTM(100, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=28, bias=True)\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeRzIu64RnqW",
        "outputId": "0f8ecd57-0d43-4cd6-e2c7-166014cea007"
      },
      "source": [
        "from flair.trainers import ModelTrainer # Initialize trainer\n",
        "\n",
        "# ModelTrainer source code : https://github.com/flairNLP/flair/blob/master/flair/trainers/trainer.py\n",
        "trainer: ModelTrainer = ModelTrainer(tagger, corpus) # corpus : The dataset used to train the model, should be of type Corpus and tagger : Sequence Tagger model\n",
        "# training process\n",
        "trainer.train('resources/taggers/example-pos',\n",
        "              learning_rate=0.1,                     # Initial learning rate\n",
        "              mini_batch_size=32,                    # Size of mini-batches during training\n",
        "              max_epochs=150)                        # Maximum number of epochs to train. Terminates training if this number is surpassed."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-10 22:56:51,355 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 22:56:51,357 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings('glove')\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (rnn): LSTM(100, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=28, bias=True)\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2021-08-10 22:56:51,359 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 22:56:51,360 Corpus: \"Corpus: 8797 train + 978 dev + 2443 test sentences\"\n",
            "2021-08-10 22:56:51,361 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 22:56:51,362 Parameters:\n",
            "2021-08-10 22:56:51,364  - learning_rate: \"0.1\"\n",
            "2021-08-10 22:56:51,365  - mini_batch_size: \"32\"\n",
            "2021-08-10 22:56:51,367  - patience: \"3\"\n",
            "2021-08-10 22:56:51,368  - anneal_factor: \"0.5\"\n",
            "2021-08-10 22:56:51,370  - max_epochs: \"150\"\n",
            "2021-08-10 22:56:51,371  - shuffle: \"True\"\n",
            "2021-08-10 22:56:51,373  - train_with_dev: \"False\"\n",
            "2021-08-10 22:56:51,374  - batch_growth_annealing: \"False\"\n",
            "2021-08-10 22:56:51,376 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 22:56:51,378 Model training base path: \"resources/taggers/example-pos\"\n",
            "2021-08-10 22:56:51,379 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 22:56:51,381 Device: cuda:0\n",
            "2021-08-10 22:56:51,388 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 22:56:51,389 Embeddings storage mode: cpu\n",
            "2021-08-10 22:56:51,394 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 22:56:53,360 epoch 1 - iter 27/275 - loss 19.46298553 - samples/sec: 440.39 - lr: 0.100000\n",
            "2021-08-10 22:56:55,286 epoch 1 - iter 54/275 - loss 16.43420283 - samples/sec: 449.44 - lr: 0.100000\n",
            "2021-08-10 22:56:57,259 epoch 1 - iter 81/275 - loss 15.32471345 - samples/sec: 438.85 - lr: 0.100000\n",
            "2021-08-10 22:56:59,217 epoch 1 - iter 108/275 - loss 14.58199128 - samples/sec: 442.09 - lr: 0.100000\n",
            "2021-08-10 22:57:01,465 epoch 1 - iter 135/275 - loss 14.53191164 - samples/sec: 384.88 - lr: 0.100000\n",
            "2021-08-10 22:57:03,919 epoch 1 - iter 162/275 - loss 14.14187135 - samples/sec: 352.52 - lr: 0.100000\n",
            "2021-08-10 22:57:06,166 epoch 1 - iter 189/275 - loss 13.35073219 - samples/sec: 385.23 - lr: 0.100000\n",
            "2021-08-10 22:57:09,347 epoch 1 - iter 216/275 - loss 12.59394326 - samples/sec: 271.91 - lr: 0.100000\n",
            "2021-08-10 22:57:11,665 epoch 1 - iter 243/275 - loss 11.90272567 - samples/sec: 373.38 - lr: 0.100000\n",
            "2021-08-10 22:57:13,777 epoch 1 - iter 270/275 - loss 11.35104959 - samples/sec: 409.76 - lr: 0.100000\n",
            "2021-08-10 22:57:14,068 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 22:57:14,070 EPOCH 1 done: loss 11.3530 - lr 0.1000000\n",
            "2021-08-10 22:57:15,424 DEV : loss 8.350046157836914 - score 0.5312\n",
            "2021-08-10 22:57:15,453 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 22:57:18,197 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 22:57:20,225 epoch 2 - iter 27/275 - loss 6.69986707 - samples/sec: 427.18 - lr: 0.100000\n",
            "2021-08-10 22:57:22,196 epoch 2 - iter 54/275 - loss 6.44514134 - samples/sec: 439.13 - lr: 0.100000\n",
            "2021-08-10 22:57:24,294 epoch 2 - iter 81/275 - loss 6.32214181 - samples/sec: 412.64 - lr: 0.100000\n",
            "2021-08-10 22:57:26,299 epoch 2 - iter 108/275 - loss 6.18395476 - samples/sec: 431.76 - lr: 0.100000\n",
            "2021-08-10 22:57:28,397 epoch 2 - iter 135/275 - loss 6.08760025 - samples/sec: 412.59 - lr: 0.100000\n",
            "2021-08-10 22:57:30,363 epoch 2 - iter 162/275 - loss 5.95776584 - samples/sec: 440.23 - lr: 0.100000\n",
            "2021-08-10 22:57:32,389 epoch 2 - iter 189/275 - loss 5.89163920 - samples/sec: 427.28 - lr: 0.100000\n",
            "2021-08-10 22:57:34,459 epoch 2 - iter 216/275 - loss 5.78275944 - samples/sec: 418.25 - lr: 0.100000\n",
            "2021-08-10 22:57:36,515 epoch 2 - iter 243/275 - loss 5.71727137 - samples/sec: 420.99 - lr: 0.100000\n",
            "2021-08-10 22:57:38,625 epoch 2 - iter 270/275 - loss 5.62502371 - samples/sec: 410.40 - lr: 0.100000\n",
            "2021-08-10 22:57:39,008 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 22:57:39,010 EPOCH 2 done: loss 5.6062 - lr 0.1000000\n",
            "2021-08-10 22:57:40,188 DEV : loss 3.6717288494110107 - score 0.7209\n",
            "2021-08-10 22:57:40,217 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 22:57:42,927 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 22:57:45,142 epoch 3 - iter 27/275 - loss 4.58941142 - samples/sec: 391.03 - lr: 0.100000\n",
            "2021-08-10 22:57:47,284 epoch 3 - iter 54/275 - loss 4.71610841 - samples/sec: 403.95 - lr: 0.100000\n",
            "2021-08-10 22:57:49,478 epoch 3 - iter 81/275 - loss 4.66532083 - samples/sec: 394.54 - lr: 0.100000\n",
            "2021-08-10 22:57:51,600 epoch 3 - iter 108/275 - loss 4.63115611 - samples/sec: 407.84 - lr: 0.100000\n",
            "2021-08-10 22:57:53,818 epoch 3 - iter 135/275 - loss 4.60191696 - samples/sec: 390.36 - lr: 0.100000\n",
            "2021-08-10 22:57:55,940 epoch 3 - iter 162/275 - loss 4.57552037 - samples/sec: 407.93 - lr: 0.100000\n",
            "2021-08-10 22:57:58,046 epoch 3 - iter 189/275 - loss 4.49783713 - samples/sec: 410.99 - lr: 0.100000\n",
            "2021-08-10 22:58:00,146 epoch 3 - iter 216/275 - loss 4.44870078 - samples/sec: 412.15 - lr: 0.100000\n",
            "2021-08-10 22:58:02,270 epoch 3 - iter 243/275 - loss 4.43620802 - samples/sec: 407.45 - lr: 0.100000\n",
            "2021-08-10 22:58:04,298 epoch 3 - iter 270/275 - loss 4.40506593 - samples/sec: 426.92 - lr: 0.100000\n",
            "2021-08-10 22:58:04,628 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 22:58:04,629 EPOCH 3 done: loss 4.3950 - lr 0.1000000\n",
            "2021-08-10 22:58:05,738 DEV : loss 3.112675189971924 - score 0.7576\n",
            "2021-08-10 22:58:05,767 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 22:58:08,344 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 22:58:10,350 epoch 4 - iter 27/275 - loss 4.00485472 - samples/sec: 431.72 - lr: 0.100000\n",
            "2021-08-10 22:58:12,546 epoch 4 - iter 54/275 - loss 3.91105179 - samples/sec: 394.04 - lr: 0.100000\n",
            "2021-08-10 22:58:14,710 epoch 4 - iter 81/275 - loss 3.90488818 - samples/sec: 400.01 - lr: 0.100000\n",
            "2021-08-10 22:58:16,786 epoch 4 - iter 108/275 - loss 3.88785889 - samples/sec: 416.95 - lr: 0.100000\n",
            "2021-08-10 22:58:18,883 epoch 4 - iter 135/275 - loss 3.93094641 - samples/sec: 412.90 - lr: 0.100000\n",
            "2021-08-10 22:58:21,092 epoch 4 - iter 162/275 - loss 3.96104028 - samples/sec: 391.83 - lr: 0.100000\n",
            "2021-08-10 22:58:23,235 epoch 4 - iter 189/275 - loss 3.87587920 - samples/sec: 403.89 - lr: 0.100000\n",
            "2021-08-10 22:58:25,393 epoch 4 - iter 216/275 - loss 3.87791219 - samples/sec: 401.06 - lr: 0.100000\n",
            "2021-08-10 22:58:27,479 epoch 4 - iter 243/275 - loss 3.85797830 - samples/sec: 414.97 - lr: 0.100000\n",
            "2021-08-10 22:58:29,600 epoch 4 - iter 270/275 - loss 3.84361980 - samples/sec: 407.98 - lr: 0.100000\n",
            "2021-08-10 22:58:30,016 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 22:58:30,018 EPOCH 4 done: loss 3.8503 - lr 0.1000000\n",
            "2021-08-10 22:58:31,192 DEV : loss 2.752936601638794 - score 0.7781\n",
            "2021-08-10 22:58:31,224 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 22:58:33,914 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 22:58:35,952 epoch 5 - iter 27/275 - loss 3.56429501 - samples/sec: 425.09 - lr: 0.100000\n",
            "2021-08-10 22:58:37,960 epoch 5 - iter 54/275 - loss 3.47772521 - samples/sec: 431.10 - lr: 0.100000\n",
            "2021-08-10 22:58:39,996 epoch 5 - iter 81/275 - loss 3.48784677 - samples/sec: 425.07 - lr: 0.100000\n",
            "2021-08-10 22:58:42,059 epoch 5 - iter 108/275 - loss 3.52413066 - samples/sec: 419.73 - lr: 0.100000\n",
            "2021-08-10 22:58:44,039 epoch 5 - iter 135/275 - loss 3.53916281 - samples/sec: 437.29 - lr: 0.100000\n",
            "2021-08-10 22:58:46,035 epoch 5 - iter 162/275 - loss 3.53927982 - samples/sec: 433.72 - lr: 0.100000\n",
            "2021-08-10 22:58:48,137 epoch 5 - iter 189/275 - loss 3.54815907 - samples/sec: 411.71 - lr: 0.100000\n",
            "2021-08-10 22:58:50,129 epoch 5 - iter 216/275 - loss 3.52100309 - samples/sec: 434.60 - lr: 0.100000\n",
            "2021-08-10 22:58:52,179 epoch 5 - iter 243/275 - loss 3.50791066 - samples/sec: 422.12 - lr: 0.100000\n",
            "2021-08-10 22:58:54,288 epoch 5 - iter 270/275 - loss 3.47357577 - samples/sec: 410.32 - lr: 0.100000\n",
            "2021-08-10 22:58:54,656 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 22:58:54,658 EPOCH 5 done: loss 3.4662 - lr 0.1000000\n",
            "2021-08-10 22:58:55,786 DEV : loss 2.6070942878723145 - score 0.8025\n",
            "2021-08-10 22:58:55,816 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 22:58:58,392 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 22:59:00,416 epoch 6 - iter 27/275 - loss 3.31051626 - samples/sec: 428.17 - lr: 0.100000\n",
            "2021-08-10 22:59:02,428 epoch 6 - iter 54/275 - loss 3.29789641 - samples/sec: 430.06 - lr: 0.100000\n",
            "2021-08-10 22:59:04,470 epoch 6 - iter 81/275 - loss 3.31092159 - samples/sec: 424.18 - lr: 0.100000\n",
            "2021-08-10 22:59:06,491 epoch 6 - iter 108/275 - loss 3.33831551 - samples/sec: 428.24 - lr: 0.100000\n",
            "2021-08-10 22:59:08,553 epoch 6 - iter 135/275 - loss 3.38441482 - samples/sec: 419.91 - lr: 0.100000\n",
            "2021-08-10 22:59:10,586 epoch 6 - iter 162/275 - loss 3.33998663 - samples/sec: 425.73 - lr: 0.100000\n",
            "2021-08-10 22:59:12,614 epoch 6 - iter 189/275 - loss 3.31867763 - samples/sec: 426.69 - lr: 0.100000\n",
            "2021-08-10 22:59:14,712 epoch 6 - iter 216/275 - loss 3.30818333 - samples/sec: 412.49 - lr: 0.100000\n",
            "2021-08-10 22:59:16,726 epoch 6 - iter 243/275 - loss 3.26743837 - samples/sec: 429.98 - lr: 0.100000\n",
            "2021-08-10 22:59:18,798 epoch 6 - iter 270/275 - loss 3.24998950 - samples/sec: 417.74 - lr: 0.100000\n",
            "2021-08-10 22:59:19,196 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 22:59:19,197 EPOCH 6 done: loss 3.2504 - lr 0.1000000\n",
            "2021-08-10 22:59:20,367 DEV : loss 2.447624683380127 - score 0.8053\n",
            "2021-08-10 22:59:20,403 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 22:59:23,111 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 22:59:25,323 epoch 7 - iter 27/275 - loss 3.20982750 - samples/sec: 391.69 - lr: 0.100000\n",
            "2021-08-10 22:59:27,437 epoch 7 - iter 54/275 - loss 3.06281149 - samples/sec: 409.44 - lr: 0.100000\n",
            "2021-08-10 22:59:29,581 epoch 7 - iter 81/275 - loss 3.07305841 - samples/sec: 403.64 - lr: 0.100000\n",
            "2021-08-10 22:59:31,776 epoch 7 - iter 108/275 - loss 3.07818264 - samples/sec: 394.29 - lr: 0.100000\n",
            "2021-08-10 22:59:33,897 epoch 7 - iter 135/275 - loss 3.10434797 - samples/sec: 408.00 - lr: 0.100000\n",
            "2021-08-10 22:59:36,016 epoch 7 - iter 162/275 - loss 3.10024793 - samples/sec: 408.60 - lr: 0.100000\n",
            "2021-08-10 22:59:38,093 epoch 7 - iter 189/275 - loss 3.10712017 - samples/sec: 416.70 - lr: 0.100000\n",
            "2021-08-10 22:59:40,186 epoch 7 - iter 216/275 - loss 3.08503398 - samples/sec: 413.49 - lr: 0.100000\n",
            "2021-08-10 22:59:42,215 epoch 7 - iter 243/275 - loss 3.08197206 - samples/sec: 426.66 - lr: 0.100000\n",
            "2021-08-10 22:59:44,233 epoch 7 - iter 270/275 - loss 3.08601470 - samples/sec: 428.89 - lr: 0.100000\n",
            "2021-08-10 22:59:44,612 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 22:59:44,613 EPOCH 7 done: loss 3.0899 - lr 0.1000000\n",
            "2021-08-10 22:59:45,707 DEV : loss 2.2388458251953125 - score 0.8232\n",
            "2021-08-10 22:59:45,736 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 22:59:48,309 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 22:59:50,370 epoch 8 - iter 27/275 - loss 2.88371011 - samples/sec: 420.27 - lr: 0.100000\n",
            "2021-08-10 22:59:52,473 epoch 8 - iter 54/275 - loss 2.93405830 - samples/sec: 411.56 - lr: 0.100000\n",
            "2021-08-10 22:59:54,489 epoch 8 - iter 81/275 - loss 2.91885565 - samples/sec: 429.34 - lr: 0.100000\n",
            "2021-08-10 22:59:56,450 epoch 8 - iter 108/275 - loss 3.00807226 - samples/sec: 441.45 - lr: 0.100000\n",
            "2021-08-10 22:59:58,432 epoch 8 - iter 135/275 - loss 3.00349927 - samples/sec: 436.64 - lr: 0.100000\n",
            "2021-08-10 23:00:00,480 epoch 8 - iter 162/275 - loss 3.01137894 - samples/sec: 422.90 - lr: 0.100000\n",
            "2021-08-10 23:00:02,497 epoch 8 - iter 189/275 - loss 2.98019730 - samples/sec: 429.12 - lr: 0.100000\n",
            "2021-08-10 23:00:04,591 epoch 8 - iter 216/275 - loss 2.96313316 - samples/sec: 413.14 - lr: 0.100000\n",
            "2021-08-10 23:00:06,594 epoch 8 - iter 243/275 - loss 2.95156863 - samples/sec: 432.31 - lr: 0.100000\n",
            "2021-08-10 23:00:08,590 epoch 8 - iter 270/275 - loss 2.91948721 - samples/sec: 433.65 - lr: 0.100000\n",
            "2021-08-10 23:00:08,971 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:00:08,972 EPOCH 8 done: loss 2.9242 - lr 0.1000000\n",
            "2021-08-10 23:00:10,074 DEV : loss 2.2438907623291016 - score 0.8273\n",
            "2021-08-10 23:00:10,104 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 23:00:12,655 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:00:14,694 epoch 9 - iter 27/275 - loss 2.91396209 - samples/sec: 424.95 - lr: 0.100000\n",
            "2021-08-10 23:00:16,809 epoch 9 - iter 54/275 - loss 2.85478721 - samples/sec: 409.34 - lr: 0.100000\n",
            "2021-08-10 23:00:18,814 epoch 9 - iter 81/275 - loss 2.78633707 - samples/sec: 431.77 - lr: 0.100000\n",
            "2021-08-10 23:00:20,834 epoch 9 - iter 108/275 - loss 2.76801894 - samples/sec: 428.35 - lr: 0.100000\n",
            "2021-08-10 23:00:22,874 epoch 9 - iter 135/275 - loss 2.79487220 - samples/sec: 424.40 - lr: 0.100000\n",
            "2021-08-10 23:00:24,988 epoch 9 - iter 162/275 - loss 2.81602782 - samples/sec: 409.38 - lr: 0.100000\n",
            "2021-08-10 23:00:27,051 epoch 9 - iter 189/275 - loss 2.79145848 - samples/sec: 419.61 - lr: 0.100000\n",
            "2021-08-10 23:00:29,155 epoch 9 - iter 216/275 - loss 2.78202561 - samples/sec: 411.51 - lr: 0.100000\n",
            "2021-08-10 23:00:31,304 epoch 9 - iter 243/275 - loss 2.79759118 - samples/sec: 402.84 - lr: 0.100000\n",
            "2021-08-10 23:00:33,456 epoch 9 - iter 270/275 - loss 2.79870940 - samples/sec: 402.22 - lr: 0.100000\n",
            "2021-08-10 23:00:33,861 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:00:33,863 EPOCH 9 done: loss 2.8013 - lr 0.1000000\n",
            "2021-08-10 23:00:35,053 DEV : loss 2.0877411365509033 - score 0.8341\n",
            "2021-08-10 23:00:35,084 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 23:00:37,770 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:00:39,959 epoch 10 - iter 27/275 - loss 2.74976324 - samples/sec: 395.68 - lr: 0.100000\n",
            "2021-08-10 23:00:42,072 epoch 10 - iter 54/275 - loss 2.82097027 - samples/sec: 409.85 - lr: 0.100000\n",
            "2021-08-10 23:00:44,191 epoch 10 - iter 81/275 - loss 2.81600783 - samples/sec: 408.38 - lr: 0.100000\n",
            "2021-08-10 23:00:46,333 epoch 10 - iter 108/275 - loss 2.80171300 - samples/sec: 404.06 - lr: 0.100000\n",
            "2021-08-10 23:00:48,343 epoch 10 - iter 135/275 - loss 2.80755733 - samples/sec: 430.75 - lr: 0.100000\n",
            "2021-08-10 23:00:50,395 epoch 10 - iter 162/275 - loss 2.79509478 - samples/sec: 421.74 - lr: 0.100000\n",
            "2021-08-10 23:00:52,420 epoch 10 - iter 189/275 - loss 2.77854585 - samples/sec: 427.43 - lr: 0.100000\n",
            "2021-08-10 23:00:54,427 epoch 10 - iter 216/275 - loss 2.77404431 - samples/sec: 431.37 - lr: 0.100000\n",
            "2021-08-10 23:00:56,449 epoch 10 - iter 243/275 - loss 2.74168633 - samples/sec: 427.97 - lr: 0.100000\n",
            "2021-08-10 23:00:58,486 epoch 10 - iter 270/275 - loss 2.74098345 - samples/sec: 425.15 - lr: 0.100000\n",
            "2021-08-10 23:00:58,848 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:00:58,849 EPOCH 10 done: loss 2.7408 - lr 0.1000000\n",
            "2021-08-10 23:00:59,934 DEV : loss 2.0780882835388184 - score 0.8438\n",
            "2021-08-10 23:00:59,961 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 23:01:02,563 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:01:04,558 epoch 11 - iter 27/275 - loss 2.65253772 - samples/sec: 434.17 - lr: 0.100000\n",
            "2021-08-10 23:01:06,558 epoch 11 - iter 54/275 - loss 2.67199703 - samples/sec: 432.90 - lr: 0.100000\n",
            "2021-08-10 23:01:08,546 epoch 11 - iter 81/275 - loss 2.73870413 - samples/sec: 435.43 - lr: 0.100000\n",
            "2021-08-10 23:01:10,501 epoch 11 - iter 108/275 - loss 2.68823090 - samples/sec: 442.75 - lr: 0.100000\n",
            "2021-08-10 23:01:12,492 epoch 11 - iter 135/275 - loss 2.68242843 - samples/sec: 434.71 - lr: 0.100000\n",
            "2021-08-10 23:01:14,442 epoch 11 - iter 162/275 - loss 2.68691932 - samples/sec: 443.83 - lr: 0.100000\n",
            "2021-08-10 23:01:16,384 epoch 11 - iter 189/275 - loss 2.66019524 - samples/sec: 445.49 - lr: 0.100000\n",
            "2021-08-10 23:01:18,309 epoch 11 - iter 216/275 - loss 2.63442233 - samples/sec: 449.78 - lr: 0.100000\n",
            "2021-08-10 23:01:20,285 epoch 11 - iter 243/275 - loss 2.64415607 - samples/sec: 438.16 - lr: 0.100000\n",
            "2021-08-10 23:01:22,293 epoch 11 - iter 270/275 - loss 2.63816056 - samples/sec: 431.03 - lr: 0.100000\n",
            "2021-08-10 23:01:22,665 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:01:22,667 EPOCH 11 done: loss 2.6517 - lr 0.1000000\n",
            "2021-08-10 23:01:23,745 DEV : loss 2.027496814727783 - score 0.8471\n",
            "2021-08-10 23:01:23,774 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 23:01:26,289 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:01:28,254 epoch 12 - iter 27/275 - loss 2.56767025 - samples/sec: 440.85 - lr: 0.100000\n",
            "2021-08-10 23:01:30,382 epoch 12 - iter 54/275 - loss 2.67300264 - samples/sec: 406.77 - lr: 0.100000\n",
            "2021-08-10 23:01:32,385 epoch 12 - iter 81/275 - loss 2.61868819 - samples/sec: 432.11 - lr: 0.100000\n",
            "2021-08-10 23:01:34,453 epoch 12 - iter 108/275 - loss 2.60792564 - samples/sec: 418.58 - lr: 0.100000\n",
            "2021-08-10 23:01:36,607 epoch 12 - iter 135/275 - loss 2.57003241 - samples/sec: 401.71 - lr: 0.100000\n",
            "2021-08-10 23:01:38,677 epoch 12 - iter 162/275 - loss 2.55839022 - samples/sec: 418.26 - lr: 0.100000\n",
            "2021-08-10 23:01:40,776 epoch 12 - iter 189/275 - loss 2.55993368 - samples/sec: 412.35 - lr: 0.100000\n",
            "2021-08-10 23:01:42,954 epoch 12 - iter 216/275 - loss 2.54575716 - samples/sec: 397.22 - lr: 0.100000\n",
            "2021-08-10 23:01:45,062 epoch 12 - iter 243/275 - loss 2.53734726 - samples/sec: 410.73 - lr: 0.100000\n",
            "2021-08-10 23:01:47,194 epoch 12 - iter 270/275 - loss 2.55786096 - samples/sec: 405.91 - lr: 0.100000\n",
            "2021-08-10 23:01:47,591 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:01:47,593 EPOCH 12 done: loss 2.5639 - lr 0.1000000\n",
            "2021-08-10 23:01:48,755 DEV : loss 1.8975800275802612 - score 0.851\n",
            "2021-08-10 23:01:48,786 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 23:01:51,480 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:01:53,562 epoch 13 - iter 27/275 - loss 2.44639567 - samples/sec: 416.09 - lr: 0.100000\n",
            "2021-08-10 23:01:55,562 epoch 13 - iter 54/275 - loss 2.50919639 - samples/sec: 432.86 - lr: 0.100000\n",
            "2021-08-10 23:01:57,614 epoch 13 - iter 81/275 - loss 2.52967636 - samples/sec: 421.61 - lr: 0.100000\n",
            "2021-08-10 23:01:59,699 epoch 13 - iter 108/275 - loss 2.45118700 - samples/sec: 415.30 - lr: 0.100000\n",
            "2021-08-10 23:02:01,679 epoch 13 - iter 135/275 - loss 2.50275645 - samples/sec: 437.14 - lr: 0.100000\n",
            "2021-08-10 23:02:03,629 epoch 13 - iter 162/275 - loss 2.52736067 - samples/sec: 443.77 - lr: 0.100000\n",
            "2021-08-10 23:02:05,643 epoch 13 - iter 189/275 - loss 2.53565653 - samples/sec: 430.31 - lr: 0.100000\n",
            "2021-08-10 23:02:07,720 epoch 13 - iter 216/275 - loss 2.53901257 - samples/sec: 416.78 - lr: 0.100000\n",
            "2021-08-10 23:02:09,713 epoch 13 - iter 243/275 - loss 2.54149031 - samples/sec: 434.40 - lr: 0.100000\n",
            "2021-08-10 23:02:11,668 epoch 13 - iter 270/275 - loss 2.51373330 - samples/sec: 442.75 - lr: 0.100000\n",
            "2021-08-10 23:02:12,047 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:02:12,048 EPOCH 13 done: loss 2.5182 - lr 0.1000000\n",
            "2021-08-10 23:02:13,158 DEV : loss 1.8896929025650024 - score 0.8538\n",
            "2021-08-10 23:02:13,189 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 23:02:15,759 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:02:17,782 epoch 14 - iter 27/275 - loss 2.39654895 - samples/sec: 428.19 - lr: 0.100000\n",
            "2021-08-10 23:02:19,775 epoch 14 - iter 54/275 - loss 2.38517114 - samples/sec: 434.15 - lr: 0.100000\n",
            "2021-08-10 23:02:21,745 epoch 14 - iter 81/275 - loss 2.43326832 - samples/sec: 439.42 - lr: 0.100000\n",
            "2021-08-10 23:02:23,704 epoch 14 - iter 108/275 - loss 2.44051460 - samples/sec: 441.74 - lr: 0.100000\n",
            "2021-08-10 23:02:25,697 epoch 14 - iter 135/275 - loss 2.44442289 - samples/sec: 434.77 - lr: 0.100000\n",
            "2021-08-10 23:02:27,691 epoch 14 - iter 162/275 - loss 2.41721688 - samples/sec: 434.10 - lr: 0.100000\n",
            "2021-08-10 23:02:29,722 epoch 14 - iter 189/275 - loss 2.41833427 - samples/sec: 426.17 - lr: 0.100000\n",
            "2021-08-10 23:02:31,795 epoch 14 - iter 216/275 - loss 2.40222799 - samples/sec: 418.01 - lr: 0.100000\n",
            "2021-08-10 23:02:33,795 epoch 14 - iter 243/275 - loss 2.39963283 - samples/sec: 432.73 - lr: 0.100000\n",
            "2021-08-10 23:02:35,863 epoch 14 - iter 270/275 - loss 2.40091493 - samples/sec: 418.60 - lr: 0.100000\n",
            "2021-08-10 23:02:36,263 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:02:36,265 EPOCH 14 done: loss 2.4029 - lr 0.1000000\n",
            "2021-08-10 23:02:37,454 DEV : loss 1.883002758026123 - score 0.8588\n",
            "2021-08-10 23:02:37,482 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 23:02:40,183 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:02:42,347 epoch 15 - iter 27/275 - loss 2.45875892 - samples/sec: 400.24 - lr: 0.100000\n",
            "2021-08-10 23:02:44,505 epoch 15 - iter 54/275 - loss 2.44111741 - samples/sec: 401.06 - lr: 0.100000\n",
            "2021-08-10 23:02:46,578 epoch 15 - iter 81/275 - loss 2.45433030 - samples/sec: 417.57 - lr: 0.100000\n",
            "2021-08-10 23:02:48,685 epoch 15 - iter 108/275 - loss 2.42098607 - samples/sec: 410.80 - lr: 0.100000\n",
            "2021-08-10 23:02:50,811 epoch 15 - iter 135/275 - loss 2.42174584 - samples/sec: 406.97 - lr: 0.100000\n",
            "2021-08-10 23:02:52,981 epoch 15 - iter 162/275 - loss 2.43846639 - samples/sec: 398.96 - lr: 0.100000\n",
            "2021-08-10 23:02:55,106 epoch 15 - iter 189/275 - loss 2.47248438 - samples/sec: 407.19 - lr: 0.100000\n",
            "2021-08-10 23:02:57,232 epoch 15 - iter 216/275 - loss 2.44901318 - samples/sec: 407.34 - lr: 0.100000\n",
            "2021-08-10 23:02:59,296 epoch 15 - iter 243/275 - loss 2.44334956 - samples/sec: 419.29 - lr: 0.100000\n",
            "2021-08-10 23:03:01,281 epoch 15 - iter 270/275 - loss 2.42319167 - samples/sec: 436.06 - lr: 0.100000\n",
            "2021-08-10 23:03:01,662 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:03:01,663 EPOCH 15 done: loss 2.4248 - lr 0.1000000\n",
            "2021-08-10 23:03:03,454 DEV : loss 1.8897616863250732 - score 0.8591\n",
            "2021-08-10 23:03:03,484 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 23:03:06,051 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:03:08,045 epoch 16 - iter 27/275 - loss 2.12396417 - samples/sec: 434.46 - lr: 0.100000\n",
            "2021-08-10 23:03:10,097 epoch 16 - iter 54/275 - loss 2.22162569 - samples/sec: 421.84 - lr: 0.100000\n",
            "2021-08-10 23:03:12,133 epoch 16 - iter 81/275 - loss 2.27041164 - samples/sec: 425.20 - lr: 0.100000\n",
            "2021-08-10 23:03:14,140 epoch 16 - iter 108/275 - loss 2.29945769 - samples/sec: 431.20 - lr: 0.100000\n",
            "2021-08-10 23:03:16,147 epoch 16 - iter 135/275 - loss 2.26302726 - samples/sec: 431.25 - lr: 0.100000\n",
            "2021-08-10 23:03:18,131 epoch 16 - iter 162/275 - loss 2.29644099 - samples/sec: 436.25 - lr: 0.100000\n",
            "2021-08-10 23:03:20,169 epoch 16 - iter 189/275 - loss 2.32849357 - samples/sec: 424.60 - lr: 0.100000\n",
            "2021-08-10 23:03:22,182 epoch 16 - iter 216/275 - loss 2.34421377 - samples/sec: 430.00 - lr: 0.100000\n",
            "2021-08-10 23:03:24,253 epoch 16 - iter 243/275 - loss 2.35938802 - samples/sec: 417.98 - lr: 0.100000\n",
            "2021-08-10 23:03:26,285 epoch 16 - iter 270/275 - loss 2.37225417 - samples/sec: 425.86 - lr: 0.100000\n",
            "2021-08-10 23:03:26,656 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:03:26,657 EPOCH 16 done: loss 2.3700 - lr 0.1000000\n",
            "2021-08-10 23:03:27,761 DEV : loss 1.8667683601379395 - score 0.8506\n",
            "2021-08-10 23:03:27,792 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 23:03:27,794 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:03:29,829 epoch 17 - iter 27/275 - loss 2.36608554 - samples/sec: 425.67 - lr: 0.100000\n",
            "2021-08-10 23:03:31,851 epoch 17 - iter 54/275 - loss 2.36335768 - samples/sec: 428.28 - lr: 0.100000\n",
            "2021-08-10 23:03:33,841 epoch 17 - iter 81/275 - loss 2.34235125 - samples/sec: 434.76 - lr: 0.100000\n",
            "2021-08-10 23:03:35,818 epoch 17 - iter 108/275 - loss 2.31226995 - samples/sec: 437.97 - lr: 0.100000\n",
            "2021-08-10 23:03:37,879 epoch 17 - iter 135/275 - loss 2.26764999 - samples/sec: 419.92 - lr: 0.100000\n",
            "2021-08-10 23:03:39,910 epoch 17 - iter 162/275 - loss 2.28303180 - samples/sec: 426.27 - lr: 0.100000\n",
            "2021-08-10 23:03:42,058 epoch 17 - iter 189/275 - loss 2.26884255 - samples/sec: 402.85 - lr: 0.100000\n",
            "2021-08-10 23:03:44,185 epoch 17 - iter 216/275 - loss 2.29825865 - samples/sec: 407.01 - lr: 0.100000\n",
            "2021-08-10 23:03:46,287 epoch 17 - iter 243/275 - loss 2.31285517 - samples/sec: 411.79 - lr: 0.100000\n",
            "2021-08-10 23:03:48,385 epoch 17 - iter 270/275 - loss 2.29527782 - samples/sec: 412.45 - lr: 0.100000\n",
            "2021-08-10 23:03:48,776 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:03:48,778 EPOCH 17 done: loss 2.2939 - lr 0.1000000\n",
            "2021-08-10 23:03:49,969 DEV : loss 1.7645069360733032 - score 0.8598\n",
            "2021-08-10 23:03:50,002 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 23:03:52,700 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:03:54,796 epoch 18 - iter 27/275 - loss 2.23510766 - samples/sec: 413.40 - lr: 0.100000\n",
            "2021-08-10 23:03:57,008 epoch 18 - iter 54/275 - loss 2.26249394 - samples/sec: 391.21 - lr: 0.100000\n",
            "2021-08-10 23:03:59,092 epoch 18 - iter 81/275 - loss 2.28209215 - samples/sec: 415.43 - lr: 0.100000\n",
            "2021-08-10 23:04:01,214 epoch 18 - iter 108/275 - loss 2.28370366 - samples/sec: 407.77 - lr: 0.100000\n",
            "2021-08-10 23:04:03,307 epoch 18 - iter 135/275 - loss 2.26466502 - samples/sec: 413.57 - lr: 0.100000\n",
            "2021-08-10 23:04:05,404 epoch 18 - iter 162/275 - loss 2.26739395 - samples/sec: 412.87 - lr: 0.100000\n",
            "2021-08-10 23:04:07,365 epoch 18 - iter 189/275 - loss 2.26476140 - samples/sec: 441.27 - lr: 0.100000\n",
            "2021-08-10 23:04:09,388 epoch 18 - iter 216/275 - loss 2.24069214 - samples/sec: 427.84 - lr: 0.100000\n",
            "2021-08-10 23:04:11,387 epoch 18 - iter 243/275 - loss 2.25321888 - samples/sec: 432.99 - lr: 0.100000\n",
            "2021-08-10 23:04:13,409 epoch 18 - iter 270/275 - loss 2.27261621 - samples/sec: 428.12 - lr: 0.100000\n",
            "2021-08-10 23:04:13,797 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:04:13,798 EPOCH 18 done: loss 2.2657 - lr 0.1000000\n",
            "2021-08-10 23:04:14,979 DEV : loss 1.8393474817276 - score 0.8591\n",
            "2021-08-10 23:04:15,008 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 23:04:15,010 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:04:17,129 epoch 19 - iter 27/275 - loss 2.11459101 - samples/sec: 408.77 - lr: 0.100000\n",
            "2021-08-10 23:04:19,207 epoch 19 - iter 54/275 - loss 2.15900366 - samples/sec: 416.64 - lr: 0.100000\n",
            "2021-08-10 23:04:21,346 epoch 19 - iter 81/275 - loss 2.12345800 - samples/sec: 404.71 - lr: 0.100000\n",
            "2021-08-10 23:04:23,495 epoch 19 - iter 108/275 - loss 2.15092267 - samples/sec: 402.83 - lr: 0.100000\n",
            "2021-08-10 23:04:25,614 epoch 19 - iter 135/275 - loss 2.18189665 - samples/sec: 408.54 - lr: 0.100000\n",
            "2021-08-10 23:04:27,766 epoch 19 - iter 162/275 - loss 2.20630364 - samples/sec: 402.15 - lr: 0.100000\n",
            "2021-08-10 23:04:29,963 epoch 19 - iter 189/275 - loss 2.23478829 - samples/sec: 393.89 - lr: 0.100000\n",
            "2021-08-10 23:04:32,057 epoch 19 - iter 216/275 - loss 2.23920309 - samples/sec: 413.36 - lr: 0.100000\n",
            "2021-08-10 23:04:34,191 epoch 19 - iter 243/275 - loss 2.24102967 - samples/sec: 405.58 - lr: 0.100000\n",
            "2021-08-10 23:04:36,283 epoch 19 - iter 270/275 - loss 2.24830100 - samples/sec: 413.83 - lr: 0.100000\n",
            "2021-08-10 23:04:36,679 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:04:36,682 EPOCH 19 done: loss 2.2441 - lr 0.1000000\n",
            "2021-08-10 23:04:37,851 DEV : loss 1.7648714780807495 - score 0.8563\n",
            "2021-08-10 23:04:37,880 BAD EPOCHS (no improvement): 2\n",
            "2021-08-10 23:04:37,882 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:04:39,968 epoch 20 - iter 27/275 - loss 2.36102081 - samples/sec: 415.23 - lr: 0.100000\n",
            "2021-08-10 23:04:41,972 epoch 20 - iter 54/275 - loss 2.25862119 - samples/sec: 431.97 - lr: 0.100000\n",
            "2021-08-10 23:04:44,039 epoch 20 - iter 81/275 - loss 2.25288970 - samples/sec: 418.79 - lr: 0.100000\n",
            "2021-08-10 23:04:46,013 epoch 20 - iter 108/275 - loss 2.21095430 - samples/sec: 438.34 - lr: 0.100000\n",
            "2021-08-10 23:04:47,937 epoch 20 - iter 135/275 - loss 2.22784330 - samples/sec: 450.13 - lr: 0.100000\n",
            "2021-08-10 23:04:49,924 epoch 20 - iter 162/275 - loss 2.21754413 - samples/sec: 435.49 - lr: 0.100000\n",
            "2021-08-10 23:04:51,943 epoch 20 - iter 189/275 - loss 2.20530764 - samples/sec: 428.70 - lr: 0.100000\n",
            "2021-08-10 23:04:53,985 epoch 20 - iter 216/275 - loss 2.18581322 - samples/sec: 423.85 - lr: 0.100000\n",
            "2021-08-10 23:04:55,992 epoch 20 - iter 243/275 - loss 2.18660458 - samples/sec: 431.37 - lr: 0.100000\n",
            "2021-08-10 23:04:57,997 epoch 20 - iter 270/275 - loss 2.20356891 - samples/sec: 431.56 - lr: 0.100000\n",
            "2021-08-10 23:04:58,359 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:04:58,361 EPOCH 20 done: loss 2.2021 - lr 0.1000000\n",
            "2021-08-10 23:04:59,474 DEV : loss 1.78157377243042 - score 0.8613\n",
            "2021-08-10 23:04:59,505 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 23:05:02,058 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:05:04,154 epoch 21 - iter 27/275 - loss 2.06045616 - samples/sec: 413.21 - lr: 0.100000\n",
            "2021-08-10 23:05:06,227 epoch 21 - iter 54/275 - loss 2.12182147 - samples/sec: 417.49 - lr: 0.100000\n",
            "2021-08-10 23:05:08,188 epoch 21 - iter 81/275 - loss 2.15220576 - samples/sec: 441.37 - lr: 0.100000\n",
            "2021-08-10 23:05:10,183 epoch 21 - iter 108/275 - loss 2.15755879 - samples/sec: 433.89 - lr: 0.100000\n",
            "2021-08-10 23:05:12,116 epoch 21 - iter 135/275 - loss 2.17378795 - samples/sec: 447.85 - lr: 0.100000\n",
            "2021-08-10 23:05:14,159 epoch 21 - iter 162/275 - loss 2.17804195 - samples/sec: 423.78 - lr: 0.100000\n",
            "2021-08-10 23:05:16,137 epoch 21 - iter 189/275 - loss 2.18224284 - samples/sec: 437.73 - lr: 0.100000\n",
            "2021-08-10 23:05:18,097 epoch 21 - iter 216/275 - loss 2.15232099 - samples/sec: 441.46 - lr: 0.100000\n",
            "2021-08-10 23:05:20,090 epoch 21 - iter 243/275 - loss 2.15214424 - samples/sec: 434.45 - lr: 0.100000\n",
            "2021-08-10 23:05:22,241 epoch 21 - iter 270/275 - loss 2.16678429 - samples/sec: 402.38 - lr: 0.100000\n",
            "2021-08-10 23:05:22,643 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:05:22,645 EPOCH 21 done: loss 2.1696 - lr 0.1000000\n",
            "2021-08-10 23:05:23,823 DEV : loss 1.7588436603546143 - score 0.864\n",
            "2021-08-10 23:05:23,855 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 23:05:26,539 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:05:28,686 epoch 22 - iter 27/275 - loss 2.00257684 - samples/sec: 403.35 - lr: 0.100000\n",
            "2021-08-10 23:05:30,782 epoch 22 - iter 54/275 - loss 2.17078444 - samples/sec: 413.02 - lr: 0.100000\n",
            "2021-08-10 23:05:32,915 epoch 22 - iter 81/275 - loss 2.16867242 - samples/sec: 405.75 - lr: 0.100000\n",
            "2021-08-10 23:05:35,051 epoch 22 - iter 108/275 - loss 2.17111530 - samples/sec: 405.33 - lr: 0.100000\n",
            "2021-08-10 23:05:37,213 epoch 22 - iter 135/275 - loss 2.16553201 - samples/sec: 400.54 - lr: 0.100000\n",
            "2021-08-10 23:05:39,396 epoch 22 - iter 162/275 - loss 2.12228191 - samples/sec: 396.40 - lr: 0.100000\n",
            "2021-08-10 23:05:41,462 epoch 22 - iter 189/275 - loss 2.14574992 - samples/sec: 418.94 - lr: 0.100000\n",
            "2021-08-10 23:05:43,560 epoch 22 - iter 216/275 - loss 2.15677671 - samples/sec: 412.50 - lr: 0.100000\n",
            "2021-08-10 23:05:45,623 epoch 22 - iter 243/275 - loss 2.14220478 - samples/sec: 419.58 - lr: 0.100000\n",
            "2021-08-10 23:05:47,696 epoch 22 - iter 270/275 - loss 2.14759653 - samples/sec: 417.56 - lr: 0.100000\n",
            "2021-08-10 23:05:48,075 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:05:48,077 EPOCH 22 done: loss 2.1423 - lr 0.1000000\n",
            "2021-08-10 23:05:49,176 DEV : loss 1.7639039754867554 - score 0.8594\n",
            "2021-08-10 23:05:49,206 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 23:05:49,208 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:05:51,207 epoch 23 - iter 27/275 - loss 1.98607725 - samples/sec: 433.60 - lr: 0.100000\n",
            "2021-08-10 23:05:53,229 epoch 23 - iter 54/275 - loss 1.95544157 - samples/sec: 428.09 - lr: 0.100000\n",
            "2021-08-10 23:05:55,207 epoch 23 - iter 81/275 - loss 2.10112305 - samples/sec: 437.51 - lr: 0.100000\n",
            "2021-08-10 23:05:57,217 epoch 23 - iter 108/275 - loss 2.04500794 - samples/sec: 430.62 - lr: 0.100000\n",
            "2021-08-10 23:05:59,293 epoch 23 - iter 135/275 - loss 2.04424345 - samples/sec: 416.97 - lr: 0.100000\n",
            "2021-08-10 23:06:01,327 epoch 23 - iter 162/275 - loss 2.09891893 - samples/sec: 425.46 - lr: 0.100000\n",
            "2021-08-10 23:06:03,305 epoch 23 - iter 189/275 - loss 2.11168379 - samples/sec: 437.77 - lr: 0.100000\n",
            "2021-08-10 23:06:05,365 epoch 23 - iter 216/275 - loss 2.11292319 - samples/sec: 420.00 - lr: 0.100000\n",
            "2021-08-10 23:06:07,400 epoch 23 - iter 243/275 - loss 2.12218083 - samples/sec: 425.42 - lr: 0.100000\n",
            "2021-08-10 23:06:09,422 epoch 23 - iter 270/275 - loss 2.11215441 - samples/sec: 428.10 - lr: 0.100000\n",
            "2021-08-10 23:06:09,804 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:06:09,806 EPOCH 23 done: loss 2.1066 - lr 0.1000000\n",
            "2021-08-10 23:06:10,912 DEV : loss 1.7452330589294434 - score 0.8631\n",
            "2021-08-10 23:06:10,943 BAD EPOCHS (no improvement): 2\n",
            "2021-08-10 23:06:10,945 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:06:13,009 epoch 24 - iter 27/275 - loss 1.88101342 - samples/sec: 419.62 - lr: 0.100000\n",
            "2021-08-10 23:06:15,025 epoch 24 - iter 54/275 - loss 2.01214099 - samples/sec: 429.36 - lr: 0.100000\n",
            "2021-08-10 23:06:17,053 epoch 24 - iter 81/275 - loss 2.03363765 - samples/sec: 426.90 - lr: 0.100000\n",
            "2021-08-10 23:06:19,063 epoch 24 - iter 108/275 - loss 2.10269862 - samples/sec: 430.67 - lr: 0.100000\n",
            "2021-08-10 23:06:20,981 epoch 24 - iter 135/275 - loss 2.08528661 - samples/sec: 451.11 - lr: 0.100000\n",
            "2021-08-10 23:06:22,983 epoch 24 - iter 162/275 - loss 2.09893352 - samples/sec: 432.38 - lr: 0.100000\n",
            "2021-08-10 23:06:24,975 epoch 24 - iter 189/275 - loss 2.12135380 - samples/sec: 434.62 - lr: 0.100000\n",
            "2021-08-10 23:06:27,062 epoch 24 - iter 216/275 - loss 2.11071831 - samples/sec: 414.55 - lr: 0.100000\n",
            "2021-08-10 23:06:29,174 epoch 24 - iter 243/275 - loss 2.10825518 - samples/sec: 409.94 - lr: 0.100000\n",
            "2021-08-10 23:06:31,299 epoch 24 - iter 270/275 - loss 2.09633056 - samples/sec: 407.16 - lr: 0.100000\n",
            "2021-08-10 23:06:31,676 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:06:31,678 EPOCH 24 done: loss 2.0913 - lr 0.1000000\n",
            "2021-08-10 23:06:32,857 DEV : loss 1.778531551361084 - score 0.863\n",
            "2021-08-10 23:06:32,888 BAD EPOCHS (no improvement): 3\n",
            "2021-08-10 23:06:32,890 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:06:35,049 epoch 25 - iter 27/275 - loss 1.88850252 - samples/sec: 401.23 - lr: 0.100000\n",
            "2021-08-10 23:06:37,164 epoch 25 - iter 54/275 - loss 2.01901320 - samples/sec: 409.16 - lr: 0.100000\n",
            "2021-08-10 23:06:39,277 epoch 25 - iter 81/275 - loss 2.03769692 - samples/sec: 409.70 - lr: 0.100000\n",
            "2021-08-10 23:06:41,437 epoch 25 - iter 108/275 - loss 2.05529464 - samples/sec: 400.64 - lr: 0.100000\n",
            "2021-08-10 23:06:43,573 epoch 25 - iter 135/275 - loss 2.11644775 - samples/sec: 405.24 - lr: 0.100000\n",
            "2021-08-10 23:06:45,682 epoch 25 - iter 162/275 - loss 2.08221079 - samples/sec: 410.40 - lr: 0.100000\n",
            "2021-08-10 23:06:47,725 epoch 25 - iter 189/275 - loss 2.05736572 - samples/sec: 423.82 - lr: 0.100000\n",
            "2021-08-10 23:06:49,821 epoch 25 - iter 216/275 - loss 2.05115419 - samples/sec: 412.88 - lr: 0.100000\n",
            "2021-08-10 23:06:51,839 epoch 25 - iter 243/275 - loss 2.08013558 - samples/sec: 428.95 - lr: 0.100000\n",
            "2021-08-10 23:06:53,826 epoch 25 - iter 270/275 - loss 2.08077372 - samples/sec: 435.84 - lr: 0.100000\n",
            "2021-08-10 23:06:54,220 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:06:54,222 EPOCH 25 done: loss 2.0823 - lr 0.1000000\n",
            "2021-08-10 23:06:55,318 DEV : loss 1.763561725616455 - score 0.8639\n",
            "Epoch    25: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2021-08-10 23:06:55,347 BAD EPOCHS (no improvement): 4\n",
            "2021-08-10 23:06:55,349 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:06:57,298 epoch 26 - iter 27/275 - loss 2.03181909 - samples/sec: 444.44 - lr: 0.050000\n",
            "2021-08-10 23:06:59,298 epoch 26 - iter 54/275 - loss 1.97965321 - samples/sec: 432.77 - lr: 0.050000\n",
            "2021-08-10 23:07:01,348 epoch 26 - iter 81/275 - loss 1.98740506 - samples/sec: 422.23 - lr: 0.050000\n",
            "2021-08-10 23:07:03,354 epoch 26 - iter 108/275 - loss 1.96289146 - samples/sec: 431.81 - lr: 0.050000\n",
            "2021-08-10 23:07:05,360 epoch 26 - iter 135/275 - loss 1.94586149 - samples/sec: 431.52 - lr: 0.050000\n",
            "2021-08-10 23:07:07,384 epoch 26 - iter 162/275 - loss 1.94478191 - samples/sec: 427.52 - lr: 0.050000\n",
            "2021-08-10 23:07:09,438 epoch 26 - iter 189/275 - loss 1.96686257 - samples/sec: 421.41 - lr: 0.050000\n",
            "2021-08-10 23:07:11,467 epoch 26 - iter 216/275 - loss 1.96887272 - samples/sec: 426.62 - lr: 0.050000\n",
            "2021-08-10 23:07:13,436 epoch 26 - iter 243/275 - loss 1.96380219 - samples/sec: 439.56 - lr: 0.050000\n",
            "2021-08-10 23:07:15,517 epoch 26 - iter 270/275 - loss 1.96580346 - samples/sec: 415.99 - lr: 0.050000\n",
            "2021-08-10 23:07:15,882 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:07:15,883 EPOCH 26 done: loss 1.9663 - lr 0.0500000\n",
            "2021-08-10 23:07:16,995 DEV : loss 1.6823792457580566 - score 0.8688\n",
            "2021-08-10 23:07:17,024 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 23:07:19,603 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:07:21,597 epoch 27 - iter 27/275 - loss 2.14974323 - samples/sec: 434.58 - lr: 0.050000\n",
            "2021-08-10 23:07:23,625 epoch 27 - iter 54/275 - loss 2.05910206 - samples/sec: 426.77 - lr: 0.050000\n",
            "2021-08-10 23:07:25,672 epoch 27 - iter 81/275 - loss 2.01341426 - samples/sec: 422.77 - lr: 0.050000\n",
            "2021-08-10 23:07:27,616 epoch 27 - iter 108/275 - loss 1.99047754 - samples/sec: 445.26 - lr: 0.050000\n",
            "2021-08-10 23:07:29,614 epoch 27 - iter 135/275 - loss 1.98847843 - samples/sec: 433.25 - lr: 0.050000\n",
            "2021-08-10 23:07:31,618 epoch 27 - iter 162/275 - loss 2.00504012 - samples/sec: 431.85 - lr: 0.050000\n",
            "2021-08-10 23:07:33,751 epoch 27 - iter 189/275 - loss 1.99157236 - samples/sec: 405.75 - lr: 0.050000\n",
            "2021-08-10 23:07:35,880 epoch 27 - iter 216/275 - loss 1.96982151 - samples/sec: 406.61 - lr: 0.050000\n",
            "2021-08-10 23:07:37,994 epoch 27 - iter 243/275 - loss 1.95447494 - samples/sec: 409.67 - lr: 0.050000\n",
            "2021-08-10 23:07:40,147 epoch 27 - iter 270/275 - loss 1.94852901 - samples/sec: 402.05 - lr: 0.050000\n",
            "2021-08-10 23:07:40,556 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:07:40,557 EPOCH 27 done: loss 1.9479 - lr 0.0500000\n",
            "2021-08-10 23:07:41,734 DEV : loss 1.6573522090911865 - score 0.8679\n",
            "2021-08-10 23:07:41,764 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 23:07:41,766 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:07:43,911 epoch 28 - iter 27/275 - loss 1.65382449 - samples/sec: 403.82 - lr: 0.050000\n",
            "2021-08-10 23:07:46,033 epoch 28 - iter 54/275 - loss 1.81677453 - samples/sec: 407.97 - lr: 0.050000\n",
            "2021-08-10 23:07:48,084 epoch 28 - iter 81/275 - loss 1.83000450 - samples/sec: 421.90 - lr: 0.050000\n",
            "2021-08-10 23:07:50,248 epoch 28 - iter 108/275 - loss 1.84530546 - samples/sec: 400.09 - lr: 0.050000\n",
            "2021-08-10 23:07:52,327 epoch 28 - iter 135/275 - loss 1.85403666 - samples/sec: 416.38 - lr: 0.050000\n",
            "2021-08-10 23:07:54,424 epoch 28 - iter 162/275 - loss 1.86003844 - samples/sec: 412.74 - lr: 0.050000\n",
            "2021-08-10 23:07:56,520 epoch 28 - iter 189/275 - loss 1.89884627 - samples/sec: 412.86 - lr: 0.050000\n",
            "2021-08-10 23:07:58,524 epoch 28 - iter 216/275 - loss 1.90102116 - samples/sec: 431.87 - lr: 0.050000\n",
            "2021-08-10 23:08:00,579 epoch 28 - iter 243/275 - loss 1.90480713 - samples/sec: 421.46 - lr: 0.050000\n",
            "2021-08-10 23:08:02,602 epoch 28 - iter 270/275 - loss 1.89982085 - samples/sec: 427.74 - lr: 0.050000\n",
            "2021-08-10 23:08:02,963 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:08:02,964 EPOCH 28 done: loss 1.9092 - lr 0.0500000\n",
            "2021-08-10 23:08:04,064 DEV : loss 1.6564821004867554 - score 0.8614\n",
            "2021-08-10 23:08:04,094 BAD EPOCHS (no improvement): 2\n",
            "2021-08-10 23:08:04,096 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:08:06,138 epoch 29 - iter 27/275 - loss 1.97734460 - samples/sec: 424.12 - lr: 0.050000\n",
            "2021-08-10 23:08:08,139 epoch 29 - iter 54/275 - loss 1.89691911 - samples/sec: 432.70 - lr: 0.050000\n",
            "2021-08-10 23:08:10,115 epoch 29 - iter 81/275 - loss 1.94102208 - samples/sec: 437.86 - lr: 0.050000\n",
            "2021-08-10 23:08:12,123 epoch 29 - iter 108/275 - loss 1.94132032 - samples/sec: 431.39 - lr: 0.050000\n",
            "2021-08-10 23:08:14,121 epoch 29 - iter 135/275 - loss 1.93150335 - samples/sec: 433.37 - lr: 0.050000\n",
            "2021-08-10 23:08:16,133 epoch 29 - iter 162/275 - loss 1.94065165 - samples/sec: 430.18 - lr: 0.050000\n",
            "2021-08-10 23:08:18,160 epoch 29 - iter 189/275 - loss 1.93115110 - samples/sec: 426.97 - lr: 0.050000\n",
            "2021-08-10 23:08:20,180 epoch 29 - iter 216/275 - loss 1.91936841 - samples/sec: 428.39 - lr: 0.050000\n",
            "2021-08-10 23:08:22,154 epoch 29 - iter 243/275 - loss 1.90635851 - samples/sec: 438.67 - lr: 0.050000\n",
            "2021-08-10 23:08:24,155 epoch 29 - iter 270/275 - loss 1.90795422 - samples/sec: 432.53 - lr: 0.050000\n",
            "2021-08-10 23:08:24,527 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:08:24,528 EPOCH 29 done: loss 1.9060 - lr 0.0500000\n",
            "2021-08-10 23:08:25,642 DEV : loss 1.6109166145324707 - score 0.8685\n",
            "2021-08-10 23:08:25,671 BAD EPOCHS (no improvement): 3\n",
            "2021-08-10 23:08:25,673 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:08:27,751 epoch 30 - iter 27/275 - loss 1.88289090 - samples/sec: 416.84 - lr: 0.050000\n",
            "2021-08-10 23:08:29,848 epoch 30 - iter 54/275 - loss 1.83251486 - samples/sec: 412.68 - lr: 0.050000\n",
            "2021-08-10 23:08:31,803 epoch 30 - iter 81/275 - loss 1.84286014 - samples/sec: 442.99 - lr: 0.050000\n",
            "2021-08-10 23:08:33,786 epoch 30 - iter 108/275 - loss 1.86552802 - samples/sec: 436.65 - lr: 0.050000\n",
            "2021-08-10 23:08:35,744 epoch 30 - iter 135/275 - loss 1.84845104 - samples/sec: 442.08 - lr: 0.050000\n",
            "2021-08-10 23:08:37,783 epoch 30 - iter 162/275 - loss 1.86693036 - samples/sec: 424.33 - lr: 0.050000\n",
            "2021-08-10 23:08:39,887 epoch 30 - iter 189/275 - loss 1.86314808 - samples/sec: 411.35 - lr: 0.050000\n",
            "2021-08-10 23:08:41,960 epoch 30 - iter 216/275 - loss 1.86722511 - samples/sec: 417.62 - lr: 0.050000\n",
            "2021-08-10 23:08:44,131 epoch 30 - iter 243/275 - loss 1.88354763 - samples/sec: 398.73 - lr: 0.050000\n",
            "2021-08-10 23:08:46,281 epoch 30 - iter 270/275 - loss 1.88338522 - samples/sec: 402.45 - lr: 0.050000\n",
            "2021-08-10 23:08:46,682 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:08:46,684 EPOCH 30 done: loss 1.8816 - lr 0.0500000\n",
            "2021-08-10 23:08:47,828 DEV : loss 1.6081266403198242 - score 0.8689\n",
            "2021-08-10 23:08:47,859 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 23:08:50,544 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:08:52,644 epoch 31 - iter 27/275 - loss 1.86255895 - samples/sec: 412.47 - lr: 0.050000\n",
            "2021-08-10 23:08:54,847 epoch 31 - iter 54/275 - loss 1.85989023 - samples/sec: 392.81 - lr: 0.050000\n",
            "2021-08-10 23:08:56,899 epoch 31 - iter 81/275 - loss 1.80939473 - samples/sec: 421.82 - lr: 0.050000\n",
            "2021-08-10 23:08:59,025 epoch 31 - iter 108/275 - loss 1.83757302 - samples/sec: 407.09 - lr: 0.050000\n",
            "2021-08-10 23:09:01,153 epoch 31 - iter 135/275 - loss 1.84789840 - samples/sec: 406.78 - lr: 0.050000\n",
            "2021-08-10 23:09:03,191 epoch 31 - iter 162/275 - loss 1.85828250 - samples/sec: 424.72 - lr: 0.050000\n",
            "2021-08-10 23:09:05,245 epoch 31 - iter 189/275 - loss 1.85270408 - samples/sec: 421.30 - lr: 0.050000\n",
            "2021-08-10 23:09:07,241 epoch 31 - iter 216/275 - loss 1.86539218 - samples/sec: 433.75 - lr: 0.050000\n",
            "2021-08-10 23:09:09,240 epoch 31 - iter 243/275 - loss 1.85212549 - samples/sec: 432.86 - lr: 0.050000\n",
            "2021-08-10 23:09:11,289 epoch 31 - iter 270/275 - loss 1.86971371 - samples/sec: 422.40 - lr: 0.050000\n",
            "2021-08-10 23:09:11,692 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:09:11,694 EPOCH 31 done: loss 1.8687 - lr 0.0500000\n",
            "2021-08-10 23:09:12,850 DEV : loss 1.626693606376648 - score 0.8706\n",
            "2021-08-10 23:09:12,880 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 23:09:15,571 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:09:17,732 epoch 32 - iter 27/275 - loss 1.89405920 - samples/sec: 401.00 - lr: 0.050000\n",
            "2021-08-10 23:09:19,879 epoch 32 - iter 54/275 - loss 1.85056390 - samples/sec: 402.99 - lr: 0.050000\n",
            "2021-08-10 23:09:21,975 epoch 32 - iter 81/275 - loss 1.87373265 - samples/sec: 413.06 - lr: 0.050000\n",
            "2021-08-10 23:09:24,142 epoch 32 - iter 108/275 - loss 1.89378040 - samples/sec: 399.23 - lr: 0.050000\n",
            "2021-08-10 23:09:26,272 epoch 32 - iter 135/275 - loss 1.90518653 - samples/sec: 406.36 - lr: 0.050000\n",
            "2021-08-10 23:09:28,316 epoch 32 - iter 162/275 - loss 1.88923187 - samples/sec: 423.61 - lr: 0.050000\n",
            "2021-08-10 23:09:30,470 epoch 32 - iter 189/275 - loss 1.86813105 - samples/sec: 401.79 - lr: 0.050000\n",
            "2021-08-10 23:09:32,548 epoch 32 - iter 216/275 - loss 1.85902560 - samples/sec: 416.41 - lr: 0.050000\n",
            "2021-08-10 23:09:34,686 epoch 32 - iter 243/275 - loss 1.85474943 - samples/sec: 404.86 - lr: 0.050000\n",
            "2021-08-10 23:09:36,654 epoch 32 - iter 270/275 - loss 1.85580047 - samples/sec: 439.79 - lr: 0.050000\n",
            "2021-08-10 23:09:37,060 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:09:37,061 EPOCH 32 done: loss 1.8546 - lr 0.0500000\n",
            "2021-08-10 23:09:38,177 DEV : loss 1.5893868207931519 - score 0.8756\n",
            "2021-08-10 23:09:38,206 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 23:09:40,757 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:09:42,750 epoch 33 - iter 27/275 - loss 1.91495018 - samples/sec: 434.55 - lr: 0.050000\n",
            "2021-08-10 23:09:44,799 epoch 33 - iter 54/275 - loss 1.81251344 - samples/sec: 422.48 - lr: 0.050000\n",
            "2021-08-10 23:09:46,856 epoch 33 - iter 81/275 - loss 1.80897570 - samples/sec: 420.79 - lr: 0.050000\n",
            "2021-08-10 23:09:48,849 epoch 33 - iter 108/275 - loss 1.80742680 - samples/sec: 434.39 - lr: 0.050000\n",
            "2021-08-10 23:09:50,837 epoch 33 - iter 135/275 - loss 1.83480244 - samples/sec: 435.38 - lr: 0.050000\n",
            "2021-08-10 23:09:52,855 epoch 33 - iter 162/275 - loss 1.84029397 - samples/sec: 428.75 - lr: 0.050000\n",
            "2021-08-10 23:09:54,878 epoch 33 - iter 189/275 - loss 1.85434624 - samples/sec: 428.05 - lr: 0.050000\n",
            "2021-08-10 23:09:56,944 epoch 33 - iter 216/275 - loss 1.84618985 - samples/sec: 418.94 - lr: 0.050000\n",
            "2021-08-10 23:09:58,966 epoch 33 - iter 243/275 - loss 1.84858700 - samples/sec: 428.04 - lr: 0.050000\n",
            "2021-08-10 23:10:00,946 epoch 33 - iter 270/275 - loss 1.85430938 - samples/sec: 437.01 - lr: 0.050000\n",
            "2021-08-10 23:10:01,305 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:10:01,307 EPOCH 33 done: loss 1.8479 - lr 0.0500000\n",
            "2021-08-10 23:10:02,416 DEV : loss 1.6187775135040283 - score 0.8719\n",
            "2021-08-10 23:10:02,445 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 23:10:02,447 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:10:04,472 epoch 34 - iter 27/275 - loss 1.82988775 - samples/sec: 427.86 - lr: 0.050000\n",
            "2021-08-10 23:10:06,445 epoch 34 - iter 54/275 - loss 1.85606817 - samples/sec: 438.70 - lr: 0.050000\n",
            "2021-08-10 23:10:08,437 epoch 34 - iter 81/275 - loss 1.87025066 - samples/sec: 434.36 - lr: 0.050000\n",
            "2021-08-10 23:10:10,440 epoch 34 - iter 108/275 - loss 1.83917401 - samples/sec: 432.23 - lr: 0.050000\n",
            "2021-08-10 23:10:12,431 epoch 34 - iter 135/275 - loss 1.81873591 - samples/sec: 434.62 - lr: 0.050000\n",
            "2021-08-10 23:10:14,424 epoch 34 - iter 162/275 - loss 1.81061538 - samples/sec: 434.33 - lr: 0.050000\n",
            "2021-08-10 23:10:16,449 epoch 34 - iter 189/275 - loss 1.82938045 - samples/sec: 427.39 - lr: 0.050000\n",
            "2021-08-10 23:10:18,529 epoch 34 - iter 216/275 - loss 1.81909984 - samples/sec: 416.16 - lr: 0.050000\n",
            "2021-08-10 23:10:20,600 epoch 34 - iter 243/275 - loss 1.82533626 - samples/sec: 417.98 - lr: 0.050000\n",
            "2021-08-10 23:10:22,784 epoch 34 - iter 270/275 - loss 1.82791737 - samples/sec: 396.20 - lr: 0.050000\n",
            "2021-08-10 23:10:23,198 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:10:23,199 EPOCH 34 done: loss 1.8204 - lr 0.0500000\n",
            "2021-08-10 23:10:25,042 DEV : loss 1.6264700889587402 - score 0.8714\n",
            "2021-08-10 23:10:25,072 BAD EPOCHS (no improvement): 2\n",
            "2021-08-10 23:10:25,074 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:10:27,215 epoch 35 - iter 27/275 - loss 1.71448513 - samples/sec: 404.55 - lr: 0.050000\n",
            "2021-08-10 23:10:29,326 epoch 35 - iter 54/275 - loss 1.78006985 - samples/sec: 409.97 - lr: 0.050000\n",
            "2021-08-10 23:10:31,390 epoch 35 - iter 81/275 - loss 1.80307651 - samples/sec: 419.37 - lr: 0.050000\n",
            "2021-08-10 23:10:33,510 epoch 35 - iter 108/275 - loss 1.84741692 - samples/sec: 408.33 - lr: 0.050000\n",
            "2021-08-10 23:10:35,605 epoch 35 - iter 135/275 - loss 1.84969298 - samples/sec: 413.31 - lr: 0.050000\n",
            "2021-08-10 23:10:37,718 epoch 35 - iter 162/275 - loss 1.83004745 - samples/sec: 409.63 - lr: 0.050000\n",
            "2021-08-10 23:10:39,859 epoch 35 - iter 189/275 - loss 1.83122436 - samples/sec: 404.32 - lr: 0.050000\n",
            "2021-08-10 23:10:41,928 epoch 35 - iter 216/275 - loss 1.83734246 - samples/sec: 418.22 - lr: 0.050000\n",
            "2021-08-10 23:10:43,879 epoch 35 - iter 243/275 - loss 1.82740734 - samples/sec: 443.72 - lr: 0.050000\n",
            "2021-08-10 23:10:45,939 epoch 35 - iter 270/275 - loss 1.83253256 - samples/sec: 420.27 - lr: 0.050000\n",
            "2021-08-10 23:10:46,291 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:10:46,293 EPOCH 35 done: loss 1.8265 - lr 0.0500000\n",
            "2021-08-10 23:10:47,405 DEV : loss 1.6179977655410767 - score 0.8711\n",
            "2021-08-10 23:10:47,434 BAD EPOCHS (no improvement): 3\n",
            "2021-08-10 23:10:47,435 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:10:49,456 epoch 36 - iter 27/275 - loss 1.81358525 - samples/sec: 428.66 - lr: 0.050000\n",
            "2021-08-10 23:10:51,513 epoch 36 - iter 54/275 - loss 1.82570287 - samples/sec: 420.82 - lr: 0.050000\n",
            "2021-08-10 23:10:53,482 epoch 36 - iter 81/275 - loss 1.83552850 - samples/sec: 439.46 - lr: 0.050000\n",
            "2021-08-10 23:10:55,482 epoch 36 - iter 108/275 - loss 1.81139442 - samples/sec: 432.72 - lr: 0.050000\n",
            "2021-08-10 23:10:57,521 epoch 36 - iter 135/275 - loss 1.79644809 - samples/sec: 424.64 - lr: 0.050000\n",
            "2021-08-10 23:10:59,501 epoch 36 - iter 162/275 - loss 1.79862031 - samples/sec: 437.20 - lr: 0.050000\n",
            "2021-08-10 23:11:01,547 epoch 36 - iter 189/275 - loss 1.78098432 - samples/sec: 422.99 - lr: 0.050000\n",
            "2021-08-10 23:11:03,561 epoch 36 - iter 216/275 - loss 1.78877669 - samples/sec: 429.76 - lr: 0.050000\n",
            "2021-08-10 23:11:05,585 epoch 36 - iter 243/275 - loss 1.80246380 - samples/sec: 427.60 - lr: 0.050000\n",
            "2021-08-10 23:11:07,585 epoch 36 - iter 270/275 - loss 1.80467601 - samples/sec: 432.97 - lr: 0.050000\n",
            "2021-08-10 23:11:07,951 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:11:07,953 EPOCH 36 done: loss 1.8012 - lr 0.0500000\n",
            "2021-08-10 23:11:09,058 DEV : loss 1.6392091512680054 - score 0.8677\n",
            "Epoch    36: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2021-08-10 23:11:09,086 BAD EPOCHS (no improvement): 4\n",
            "2021-08-10 23:11:09,090 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:11:11,120 epoch 37 - iter 27/275 - loss 1.73467566 - samples/sec: 426.75 - lr: 0.025000\n",
            "2021-08-10 23:11:13,168 epoch 37 - iter 54/275 - loss 1.72307095 - samples/sec: 422.70 - lr: 0.025000\n",
            "2021-08-10 23:11:15,190 epoch 37 - iter 81/275 - loss 1.74749626 - samples/sec: 427.97 - lr: 0.025000\n",
            "2021-08-10 23:11:17,207 epoch 37 - iter 108/275 - loss 1.72956163 - samples/sec: 429.11 - lr: 0.025000\n",
            "2021-08-10 23:11:19,192 epoch 37 - iter 135/275 - loss 1.72158943 - samples/sec: 436.00 - lr: 0.025000\n",
            "2021-08-10 23:11:21,243 epoch 37 - iter 162/275 - loss 1.72017975 - samples/sec: 422.12 - lr: 0.025000\n",
            "2021-08-10 23:11:23,209 epoch 37 - iter 189/275 - loss 1.71662168 - samples/sec: 440.17 - lr: 0.025000\n",
            "2021-08-10 23:11:25,258 epoch 37 - iter 216/275 - loss 1.72007021 - samples/sec: 422.52 - lr: 0.025000\n",
            "2021-08-10 23:11:27,376 epoch 37 - iter 243/275 - loss 1.74189049 - samples/sec: 408.64 - lr: 0.025000\n",
            "2021-08-10 23:11:29,485 epoch 37 - iter 270/275 - loss 1.75151535 - samples/sec: 410.39 - lr: 0.025000\n",
            "2021-08-10 23:11:29,906 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:11:29,908 EPOCH 37 done: loss 1.7494 - lr 0.0250000\n",
            "2021-08-10 23:11:31,071 DEV : loss 1.6004177331924438 - score 0.8688\n",
            "2021-08-10 23:11:31,103 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 23:11:31,105 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:11:33,191 epoch 38 - iter 27/275 - loss 1.79057208 - samples/sec: 415.24 - lr: 0.025000\n",
            "2021-08-10 23:11:35,324 epoch 38 - iter 54/275 - loss 1.78503087 - samples/sec: 405.82 - lr: 0.025000\n",
            "2021-08-10 23:11:37,356 epoch 38 - iter 81/275 - loss 1.78234442 - samples/sec: 425.91 - lr: 0.025000\n",
            "2021-08-10 23:11:39,506 epoch 38 - iter 108/275 - loss 1.75731055 - samples/sec: 402.51 - lr: 0.025000\n",
            "2021-08-10 23:11:41,602 epoch 38 - iter 135/275 - loss 1.76136443 - samples/sec: 412.84 - lr: 0.025000\n",
            "2021-08-10 23:11:43,717 epoch 38 - iter 162/275 - loss 1.75532898 - samples/sec: 409.32 - lr: 0.025000\n",
            "2021-08-10 23:11:45,856 epoch 38 - iter 189/275 - loss 1.73694905 - samples/sec: 404.55 - lr: 0.025000\n",
            "2021-08-10 23:11:47,992 epoch 38 - iter 216/275 - loss 1.74587959 - samples/sec: 405.29 - lr: 0.025000\n",
            "2021-08-10 23:11:49,969 epoch 38 - iter 243/275 - loss 1.74242269 - samples/sec: 437.72 - lr: 0.025000\n",
            "2021-08-10 23:11:52,023 epoch 38 - iter 270/275 - loss 1.74616800 - samples/sec: 421.40 - lr: 0.025000\n",
            "2021-08-10 23:11:52,380 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:11:52,382 EPOCH 38 done: loss 1.7445 - lr 0.0250000\n",
            "2021-08-10 23:11:53,508 DEV : loss 1.5906106233596802 - score 0.8704\n",
            "2021-08-10 23:11:53,537 BAD EPOCHS (no improvement): 2\n",
            "2021-08-10 23:11:53,539 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:11:55,619 epoch 39 - iter 27/275 - loss 1.73677031 - samples/sec: 416.43 - lr: 0.025000\n",
            "2021-08-10 23:11:57,637 epoch 39 - iter 54/275 - loss 1.76477802 - samples/sec: 428.95 - lr: 0.025000\n",
            "2021-08-10 23:11:59,633 epoch 39 - iter 81/275 - loss 1.78082326 - samples/sec: 433.65 - lr: 0.025000\n",
            "2021-08-10 23:12:01,632 epoch 39 - iter 108/275 - loss 1.77761473 - samples/sec: 432.98 - lr: 0.025000\n",
            "2021-08-10 23:12:03,667 epoch 39 - iter 135/275 - loss 1.78404642 - samples/sec: 425.41 - lr: 0.025000\n",
            "2021-08-10 23:12:05,658 epoch 39 - iter 162/275 - loss 1.75713354 - samples/sec: 434.81 - lr: 0.025000\n",
            "2021-08-10 23:12:07,687 epoch 39 - iter 189/275 - loss 1.75080895 - samples/sec: 426.59 - lr: 0.025000\n",
            "2021-08-10 23:12:09,645 epoch 39 - iter 216/275 - loss 1.73224595 - samples/sec: 442.19 - lr: 0.025000\n",
            "2021-08-10 23:12:11,608 epoch 39 - iter 243/275 - loss 1.74241213 - samples/sec: 441.07 - lr: 0.025000\n",
            "2021-08-10 23:12:13,627 epoch 39 - iter 270/275 - loss 1.74439422 - samples/sec: 428.64 - lr: 0.025000\n",
            "2021-08-10 23:12:13,985 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:12:13,986 EPOCH 39 done: loss 1.7456 - lr 0.0250000\n",
            "2021-08-10 23:12:15,100 DEV : loss 1.5771229267120361 - score 0.8712\n",
            "2021-08-10 23:12:15,133 BAD EPOCHS (no improvement): 3\n",
            "2021-08-10 23:12:15,135 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:12:17,112 epoch 40 - iter 27/275 - loss 1.73936229 - samples/sec: 438.25 - lr: 0.025000\n",
            "2021-08-10 23:12:19,181 epoch 40 - iter 54/275 - loss 1.75971880 - samples/sec: 418.18 - lr: 0.025000\n",
            "2021-08-10 23:12:21,231 epoch 40 - iter 81/275 - loss 1.74277227 - samples/sec: 422.20 - lr: 0.025000\n",
            "2021-08-10 23:12:23,247 epoch 40 - iter 108/275 - loss 1.71366801 - samples/sec: 429.39 - lr: 0.025000\n",
            "2021-08-10 23:12:25,299 epoch 40 - iter 135/275 - loss 1.72612842 - samples/sec: 421.86 - lr: 0.025000\n",
            "2021-08-10 23:12:27,302 epoch 40 - iter 162/275 - loss 1.73917310 - samples/sec: 432.36 - lr: 0.025000\n",
            "2021-08-10 23:12:29,364 epoch 40 - iter 189/275 - loss 1.74187551 - samples/sec: 419.70 - lr: 0.025000\n",
            "2021-08-10 23:12:31,422 epoch 40 - iter 216/275 - loss 1.75422365 - samples/sec: 420.75 - lr: 0.025000\n",
            "2021-08-10 23:12:33,502 epoch 40 - iter 243/275 - loss 1.73553596 - samples/sec: 416.02 - lr: 0.025000\n",
            "2021-08-10 23:12:35,581 epoch 40 - iter 270/275 - loss 1.73354186 - samples/sec: 416.31 - lr: 0.025000\n",
            "2021-08-10 23:12:35,947 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:12:35,949 EPOCH 40 done: loss 1.7247 - lr 0.0250000\n",
            "2021-08-10 23:12:37,123 DEV : loss 1.5926176309585571 - score 0.8732\n",
            "Epoch    40: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2021-08-10 23:12:37,154 BAD EPOCHS (no improvement): 4\n",
            "2021-08-10 23:12:37,156 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:12:39,293 epoch 41 - iter 27/275 - loss 1.72244162 - samples/sec: 405.41 - lr: 0.012500\n",
            "2021-08-10 23:12:41,375 epoch 41 - iter 54/275 - loss 1.74178434 - samples/sec: 415.89 - lr: 0.012500\n",
            "2021-08-10 23:12:43,495 epoch 41 - iter 81/275 - loss 1.70538321 - samples/sec: 408.08 - lr: 0.012500\n",
            "2021-08-10 23:12:45,588 epoch 41 - iter 108/275 - loss 1.69178938 - samples/sec: 413.57 - lr: 0.012500\n",
            "2021-08-10 23:12:47,746 epoch 41 - iter 135/275 - loss 1.69183096 - samples/sec: 401.17 - lr: 0.012500\n",
            "2021-08-10 23:12:49,934 epoch 41 - iter 162/275 - loss 1.70352148 - samples/sec: 395.68 - lr: 0.012500\n",
            "2021-08-10 23:12:52,057 epoch 41 - iter 189/275 - loss 1.69413512 - samples/sec: 407.58 - lr: 0.012500\n",
            "2021-08-10 23:12:54,110 epoch 41 - iter 216/275 - loss 1.70494038 - samples/sec: 421.57 - lr: 0.012500\n",
            "2021-08-10 23:12:56,183 epoch 41 - iter 243/275 - loss 1.68764958 - samples/sec: 417.66 - lr: 0.012500\n",
            "2021-08-10 23:12:58,264 epoch 41 - iter 270/275 - loss 1.70095164 - samples/sec: 415.89 - lr: 0.012500\n",
            "2021-08-10 23:12:58,626 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:12:58,627 EPOCH 41 done: loss 1.7005 - lr 0.0125000\n",
            "2021-08-10 23:12:59,734 DEV : loss 1.5777183771133423 - score 0.872\n",
            "2021-08-10 23:12:59,763 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 23:12:59,765 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:13:01,755 epoch 42 - iter 27/275 - loss 1.79780821 - samples/sec: 435.30 - lr: 0.012500\n",
            "2021-08-10 23:13:03,740 epoch 42 - iter 54/275 - loss 1.75935309 - samples/sec: 436.14 - lr: 0.012500\n",
            "2021-08-10 23:13:05,781 epoch 42 - iter 81/275 - loss 1.78382957 - samples/sec: 424.10 - lr: 0.012500\n",
            "2021-08-10 23:13:07,781 epoch 42 - iter 108/275 - loss 1.74439190 - samples/sec: 432.88 - lr: 0.012500\n",
            "2021-08-10 23:13:09,731 epoch 42 - iter 135/275 - loss 1.72905141 - samples/sec: 443.98 - lr: 0.012500\n",
            "2021-08-10 23:13:11,752 epoch 42 - iter 162/275 - loss 1.74609071 - samples/sec: 428.26 - lr: 0.012500\n",
            "2021-08-10 23:13:13,821 epoch 42 - iter 189/275 - loss 1.72577238 - samples/sec: 418.27 - lr: 0.012500\n",
            "2021-08-10 23:13:15,856 epoch 42 - iter 216/275 - loss 1.72992092 - samples/sec: 425.40 - lr: 0.012500\n",
            "2021-08-10 23:13:17,793 epoch 42 - iter 243/275 - loss 1.71182783 - samples/sec: 447.00 - lr: 0.012500\n",
            "2021-08-10 23:13:19,846 epoch 42 - iter 270/275 - loss 1.71894685 - samples/sec: 421.55 - lr: 0.012500\n",
            "2021-08-10 23:13:20,204 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:13:20,206 EPOCH 42 done: loss 1.7155 - lr 0.0125000\n",
            "2021-08-10 23:13:21,340 DEV : loss 1.5826704502105713 - score 0.871\n",
            "2021-08-10 23:13:21,368 BAD EPOCHS (no improvement): 2\n",
            "2021-08-10 23:13:21,370 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:13:23,402 epoch 43 - iter 27/275 - loss 1.61610768 - samples/sec: 426.45 - lr: 0.012500\n",
            "2021-08-10 23:13:25,443 epoch 43 - iter 54/275 - loss 1.70110551 - samples/sec: 423.99 - lr: 0.012500\n",
            "2021-08-10 23:13:27,432 epoch 43 - iter 81/275 - loss 1.67680851 - samples/sec: 435.12 - lr: 0.012500\n",
            "2021-08-10 23:13:29,477 epoch 43 - iter 108/275 - loss 1.67713017 - samples/sec: 423.18 - lr: 0.012500\n",
            "2021-08-10 23:13:31,425 epoch 43 - iter 135/275 - loss 1.68884639 - samples/sec: 444.47 - lr: 0.012500\n",
            "2021-08-10 23:13:33,475 epoch 43 - iter 162/275 - loss 1.69590682 - samples/sec: 422.20 - lr: 0.012500\n",
            "2021-08-10 23:13:35,510 epoch 43 - iter 189/275 - loss 1.69047131 - samples/sec: 425.25 - lr: 0.012500\n",
            "2021-08-10 23:13:37,541 epoch 43 - iter 216/275 - loss 1.69848210 - samples/sec: 426.14 - lr: 0.012500\n",
            "2021-08-10 23:13:39,717 epoch 43 - iter 243/275 - loss 1.67907641 - samples/sec: 397.78 - lr: 0.012500\n",
            "2021-08-10 23:13:41,802 epoch 43 - iter 270/275 - loss 1.69174536 - samples/sec: 415.18 - lr: 0.012500\n",
            "2021-08-10 23:13:42,193 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:13:42,194 EPOCH 43 done: loss 1.6963 - lr 0.0125000\n",
            "2021-08-10 23:13:43,364 DEV : loss 1.5750762224197388 - score 0.8718\n",
            "2021-08-10 23:13:43,395 BAD EPOCHS (no improvement): 3\n",
            "2021-08-10 23:13:43,397 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:13:45,500 epoch 44 - iter 27/275 - loss 1.60559397 - samples/sec: 411.97 - lr: 0.012500\n",
            "2021-08-10 23:13:47,678 epoch 44 - iter 54/275 - loss 1.70382072 - samples/sec: 397.27 - lr: 0.012500\n",
            "2021-08-10 23:13:49,744 epoch 44 - iter 81/275 - loss 1.67271285 - samples/sec: 419.03 - lr: 0.012500\n",
            "2021-08-10 23:13:51,869 epoch 44 - iter 108/275 - loss 1.70182581 - samples/sec: 407.28 - lr: 0.012500\n",
            "2021-08-10 23:13:53,991 epoch 44 - iter 135/275 - loss 1.71562864 - samples/sec: 407.84 - lr: 0.012500\n",
            "2021-08-10 23:13:56,121 epoch 44 - iter 162/275 - loss 1.69432189 - samples/sec: 406.37 - lr: 0.012500\n",
            "2021-08-10 23:13:58,245 epoch 44 - iter 189/275 - loss 1.71456409 - samples/sec: 407.53 - lr: 0.012500\n",
            "2021-08-10 23:14:00,282 epoch 44 - iter 216/275 - loss 1.72111700 - samples/sec: 424.90 - lr: 0.012500\n",
            "2021-08-10 23:14:02,273 epoch 44 - iter 243/275 - loss 1.70054599 - samples/sec: 434.53 - lr: 0.012500\n",
            "2021-08-10 23:14:04,248 epoch 44 - iter 270/275 - loss 1.70897056 - samples/sec: 438.45 - lr: 0.012500\n",
            "2021-08-10 23:14:04,617 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:14:04,619 EPOCH 44 done: loss 1.7130 - lr 0.0125000\n",
            "2021-08-10 23:14:05,732 DEV : loss 1.5686516761779785 - score 0.8721\n",
            "Epoch    44: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2021-08-10 23:14:05,761 BAD EPOCHS (no improvement): 4\n",
            "2021-08-10 23:14:05,763 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:14:07,809 epoch 45 - iter 27/275 - loss 1.57774587 - samples/sec: 423.47 - lr: 0.006250\n",
            "2021-08-10 23:14:09,829 epoch 45 - iter 54/275 - loss 1.57046469 - samples/sec: 428.36 - lr: 0.006250\n",
            "2021-08-10 23:14:11,810 epoch 45 - iter 81/275 - loss 1.64113943 - samples/sec: 437.05 - lr: 0.006250\n",
            "2021-08-10 23:14:13,814 epoch 45 - iter 108/275 - loss 1.67427953 - samples/sec: 431.92 - lr: 0.006250\n",
            "2021-08-10 23:14:15,838 epoch 45 - iter 135/275 - loss 1.72796181 - samples/sec: 427.86 - lr: 0.006250\n",
            "2021-08-10 23:14:17,826 epoch 45 - iter 162/275 - loss 1.73317857 - samples/sec: 435.38 - lr: 0.006250\n",
            "2021-08-10 23:14:19,901 epoch 45 - iter 189/275 - loss 1.69818015 - samples/sec: 417.04 - lr: 0.006250\n",
            "2021-08-10 23:14:21,915 epoch 45 - iter 216/275 - loss 1.68321860 - samples/sec: 429.72 - lr: 0.006250\n",
            "2021-08-10 23:14:23,902 epoch 45 - iter 243/275 - loss 1.69625179 - samples/sec: 435.98 - lr: 0.006250\n",
            "2021-08-10 23:14:25,958 epoch 45 - iter 270/275 - loss 1.69550347 - samples/sec: 421.07 - lr: 0.006250\n",
            "2021-08-10 23:14:26,336 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:14:26,337 EPOCH 45 done: loss 1.7006 - lr 0.0062500\n",
            "2021-08-10 23:14:27,458 DEV : loss 1.574697494506836 - score 0.8726\n",
            "2021-08-10 23:14:27,486 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 23:14:27,488 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:14:29,508 epoch 46 - iter 27/275 - loss 1.71493520 - samples/sec: 429.06 - lr: 0.006250\n",
            "2021-08-10 23:14:31,466 epoch 46 - iter 54/275 - loss 1.74113169 - samples/sec: 442.02 - lr: 0.006250\n",
            "2021-08-10 23:14:33,502 epoch 46 - iter 81/275 - loss 1.70009639 - samples/sec: 425.13 - lr: 0.006250\n",
            "2021-08-10 23:14:35,512 epoch 46 - iter 108/275 - loss 1.74614515 - samples/sec: 430.77 - lr: 0.006250\n",
            "2021-08-10 23:14:37,564 epoch 46 - iter 135/275 - loss 1.72794080 - samples/sec: 421.79 - lr: 0.006250\n",
            "2021-08-10 23:14:39,567 epoch 46 - iter 162/275 - loss 1.72144292 - samples/sec: 432.17 - lr: 0.006250\n",
            "2021-08-10 23:14:41,650 epoch 46 - iter 189/275 - loss 1.71201402 - samples/sec: 415.56 - lr: 0.006250\n",
            "2021-08-10 23:14:43,780 epoch 46 - iter 216/275 - loss 1.70631273 - samples/sec: 406.32 - lr: 0.006250\n",
            "2021-08-10 23:14:45,941 epoch 46 - iter 243/275 - loss 1.70398684 - samples/sec: 400.56 - lr: 0.006250\n",
            "2021-08-10 23:14:48,094 epoch 46 - iter 270/275 - loss 1.70749627 - samples/sec: 402.03 - lr: 0.006250\n",
            "2021-08-10 23:14:48,495 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:14:48,497 EPOCH 46 done: loss 1.7050 - lr 0.0062500\n",
            "2021-08-10 23:14:49,674 DEV : loss 1.5830564498901367 - score 0.8724\n",
            "2021-08-10 23:14:49,704 BAD EPOCHS (no improvement): 2\n",
            "2021-08-10 23:14:49,706 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:14:51,860 epoch 47 - iter 27/275 - loss 1.74994426 - samples/sec: 402.34 - lr: 0.006250\n",
            "2021-08-10 23:14:54,019 epoch 47 - iter 54/275 - loss 1.73410009 - samples/sec: 400.76 - lr: 0.006250\n",
            "2021-08-10 23:14:56,109 epoch 47 - iter 81/275 - loss 1.72075171 - samples/sec: 414.11 - lr: 0.006250\n",
            "2021-08-10 23:14:58,213 epoch 47 - iter 108/275 - loss 1.71350928 - samples/sec: 411.45 - lr: 0.006250\n",
            "2021-08-10 23:15:00,359 epoch 47 - iter 135/275 - loss 1.69326170 - samples/sec: 403.60 - lr: 0.006250\n",
            "2021-08-10 23:15:02,487 epoch 47 - iter 162/275 - loss 1.68962971 - samples/sec: 406.67 - lr: 0.006250\n",
            "2021-08-10 23:15:04,609 epoch 47 - iter 189/275 - loss 1.69361403 - samples/sec: 408.01 - lr: 0.006250\n",
            "2021-08-10 23:15:06,600 epoch 47 - iter 216/275 - loss 1.69877944 - samples/sec: 434.60 - lr: 0.006250\n",
            "2021-08-10 23:15:08,654 epoch 47 - iter 243/275 - loss 1.69018289 - samples/sec: 421.45 - lr: 0.006250\n",
            "2021-08-10 23:15:10,640 epoch 47 - iter 270/275 - loss 1.68975459 - samples/sec: 435.82 - lr: 0.006250\n",
            "2021-08-10 23:15:11,020 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:15:11,022 EPOCH 47 done: loss 1.6906 - lr 0.0062500\n",
            "2021-08-10 23:15:12,160 DEV : loss 1.580507516860962 - score 0.8733\n",
            "2021-08-10 23:15:12,191 BAD EPOCHS (no improvement): 3\n",
            "2021-08-10 23:15:12,193 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:15:14,251 epoch 48 - iter 27/275 - loss 1.70022537 - samples/sec: 421.17 - lr: 0.006250\n",
            "2021-08-10 23:15:16,376 epoch 48 - iter 54/275 - loss 1.70119238 - samples/sec: 407.17 - lr: 0.006250\n",
            "2021-08-10 23:15:18,455 epoch 48 - iter 81/275 - loss 1.68490013 - samples/sec: 416.45 - lr: 0.006250\n",
            "2021-08-10 23:15:20,512 epoch 48 - iter 108/275 - loss 1.67400274 - samples/sec: 420.73 - lr: 0.006250\n",
            "2021-08-10 23:15:22,603 epoch 48 - iter 135/275 - loss 1.65855102 - samples/sec: 413.90 - lr: 0.006250\n",
            "2021-08-10 23:15:24,754 epoch 48 - iter 162/275 - loss 1.66219090 - samples/sec: 402.35 - lr: 0.006250\n",
            "2021-08-10 23:15:26,854 epoch 48 - iter 189/275 - loss 1.67522577 - samples/sec: 412.12 - lr: 0.006250\n",
            "2021-08-10 23:15:28,970 epoch 48 - iter 216/275 - loss 1.68822543 - samples/sec: 409.17 - lr: 0.006250\n",
            "2021-08-10 23:15:31,108 epoch 48 - iter 243/275 - loss 1.69833548 - samples/sec: 404.74 - lr: 0.006250\n",
            "2021-08-10 23:15:33,239 epoch 48 - iter 270/275 - loss 1.68415308 - samples/sec: 406.10 - lr: 0.006250\n",
            "2021-08-10 23:15:33,630 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:15:33,631 EPOCH 48 done: loss 1.6853 - lr 0.0062500\n",
            "2021-08-10 23:15:34,802 DEV : loss 1.5702424049377441 - score 0.8725\n",
            "Epoch    48: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2021-08-10 23:15:34,832 BAD EPOCHS (no improvement): 4\n",
            "2021-08-10 23:15:34,834 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:15:36,920 epoch 49 - iter 27/275 - loss 1.69877225 - samples/sec: 414.99 - lr: 0.003125\n",
            "2021-08-10 23:15:39,075 epoch 49 - iter 54/275 - loss 1.73889369 - samples/sec: 401.78 - lr: 0.003125\n",
            "2021-08-10 23:15:41,079 epoch 49 - iter 81/275 - loss 1.70185783 - samples/sec: 431.97 - lr: 0.003125\n",
            "2021-08-10 23:15:43,056 epoch 49 - iter 108/275 - loss 1.68147320 - samples/sec: 437.96 - lr: 0.003125\n",
            "2021-08-10 23:15:45,088 epoch 49 - iter 135/275 - loss 1.69037569 - samples/sec: 425.95 - lr: 0.003125\n",
            "2021-08-10 23:15:47,073 epoch 49 - iter 162/275 - loss 1.69369860 - samples/sec: 436.03 - lr: 0.003125\n",
            "2021-08-10 23:15:49,055 epoch 49 - iter 189/275 - loss 1.68466139 - samples/sec: 436.74 - lr: 0.003125\n",
            "2021-08-10 23:15:51,016 epoch 49 - iter 216/275 - loss 1.67177526 - samples/sec: 441.34 - lr: 0.003125\n",
            "2021-08-10 23:15:53,057 epoch 49 - iter 243/275 - loss 1.66746895 - samples/sec: 424.47 - lr: 0.003125\n",
            "2021-08-10 23:15:55,144 epoch 49 - iter 270/275 - loss 1.67072128 - samples/sec: 414.70 - lr: 0.003125\n",
            "2021-08-10 23:15:55,539 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:15:55,540 EPOCH 49 done: loss 1.6760 - lr 0.0031250\n",
            "2021-08-10 23:15:56,647 DEV : loss 1.5702348947525024 - score 0.8729\n",
            "2021-08-10 23:15:56,678 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 23:15:56,681 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:15:58,698 epoch 50 - iter 27/275 - loss 1.69097375 - samples/sec: 429.55 - lr: 0.003125\n",
            "2021-08-10 23:16:00,767 epoch 50 - iter 54/275 - loss 1.72085125 - samples/sec: 418.27 - lr: 0.003125\n",
            "2021-08-10 23:16:02,806 epoch 50 - iter 81/275 - loss 1.69468641 - samples/sec: 424.46 - lr: 0.003125\n",
            "2021-08-10 23:16:04,824 epoch 50 - iter 108/275 - loss 1.66227941 - samples/sec: 429.03 - lr: 0.003125\n",
            "2021-08-10 23:16:06,807 epoch 50 - iter 135/275 - loss 1.67473973 - samples/sec: 436.46 - lr: 0.003125\n",
            "2021-08-10 23:16:08,787 epoch 50 - iter 162/275 - loss 1.65823755 - samples/sec: 437.14 - lr: 0.003125\n",
            "2021-08-10 23:16:10,768 epoch 50 - iter 189/275 - loss 1.65514393 - samples/sec: 436.87 - lr: 0.003125\n",
            "2021-08-10 23:16:12,709 epoch 50 - iter 216/275 - loss 1.65898153 - samples/sec: 445.90 - lr: 0.003125\n",
            "2021-08-10 23:16:14,694 epoch 50 - iter 243/275 - loss 1.66560784 - samples/sec: 436.21 - lr: 0.003125\n",
            "2021-08-10 23:16:16,793 epoch 50 - iter 270/275 - loss 1.66718692 - samples/sec: 412.43 - lr: 0.003125\n",
            "2021-08-10 23:16:17,159 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:16:17,161 EPOCH 50 done: loss 1.6702 - lr 0.0031250\n",
            "2021-08-10 23:16:18,250 DEV : loss 1.570762038230896 - score 0.8719\n",
            "2021-08-10 23:16:18,279 BAD EPOCHS (no improvement): 2\n",
            "2021-08-10 23:16:18,280 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:16:20,241 epoch 51 - iter 27/275 - loss 1.50506236 - samples/sec: 441.94 - lr: 0.003125\n",
            "2021-08-10 23:16:22,351 epoch 51 - iter 54/275 - loss 1.56666450 - samples/sec: 410.19 - lr: 0.003125\n",
            "2021-08-10 23:16:24,465 epoch 51 - iter 81/275 - loss 1.62615398 - samples/sec: 409.70 - lr: 0.003125\n",
            "2021-08-10 23:16:26,656 epoch 51 - iter 108/275 - loss 1.61301753 - samples/sec: 394.85 - lr: 0.003125\n",
            "2021-08-10 23:16:28,752 epoch 51 - iter 135/275 - loss 1.60965690 - samples/sec: 413.02 - lr: 0.003125\n",
            "2021-08-10 23:16:30,886 epoch 51 - iter 162/275 - loss 1.62803650 - samples/sec: 405.64 - lr: 0.003125\n",
            "2021-08-10 23:16:32,985 epoch 51 - iter 189/275 - loss 1.64742602 - samples/sec: 412.30 - lr: 0.003125\n",
            "2021-08-10 23:16:35,066 epoch 51 - iter 216/275 - loss 1.65614145 - samples/sec: 415.94 - lr: 0.003125\n",
            "2021-08-10 23:16:37,156 epoch 51 - iter 243/275 - loss 1.65272165 - samples/sec: 414.12 - lr: 0.003125\n",
            "2021-08-10 23:16:39,265 epoch 51 - iter 270/275 - loss 1.65992406 - samples/sec: 410.29 - lr: 0.003125\n",
            "2021-08-10 23:16:39,653 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:16:39,655 EPOCH 51 done: loss 1.6662 - lr 0.0031250\n",
            "2021-08-10 23:16:40,841 DEV : loss 1.5574268102645874 - score 0.8727\n",
            "2021-08-10 23:16:40,871 BAD EPOCHS (no improvement): 3\n",
            "2021-08-10 23:16:40,873 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:16:42,966 epoch 52 - iter 27/275 - loss 1.62955893 - samples/sec: 413.86 - lr: 0.003125\n",
            "2021-08-10 23:16:45,004 epoch 52 - iter 54/275 - loss 1.63106929 - samples/sec: 424.82 - lr: 0.003125\n",
            "2021-08-10 23:16:47,014 epoch 52 - iter 81/275 - loss 1.61376290 - samples/sec: 430.76 - lr: 0.003125\n",
            "2021-08-10 23:16:49,061 epoch 52 - iter 108/275 - loss 1.61654077 - samples/sec: 422.71 - lr: 0.003125\n",
            "2021-08-10 23:16:51,107 epoch 52 - iter 135/275 - loss 1.63746133 - samples/sec: 423.10 - lr: 0.003125\n",
            "2021-08-10 23:16:53,092 epoch 52 - iter 162/275 - loss 1.61881442 - samples/sec: 436.13 - lr: 0.003125\n",
            "2021-08-10 23:16:55,088 epoch 52 - iter 189/275 - loss 1.64590024 - samples/sec: 433.66 - lr: 0.003125\n",
            "2021-08-10 23:16:57,060 epoch 52 - iter 216/275 - loss 1.64766230 - samples/sec: 438.91 - lr: 0.003125\n",
            "2021-08-10 23:16:59,057 epoch 52 - iter 243/275 - loss 1.65657427 - samples/sec: 433.39 - lr: 0.003125\n",
            "2021-08-10 23:17:01,069 epoch 52 - iter 270/275 - loss 1.66347341 - samples/sec: 430.20 - lr: 0.003125\n",
            "2021-08-10 23:17:01,435 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:17:01,436 EPOCH 52 done: loss 1.6652 - lr 0.0031250\n",
            "2021-08-10 23:17:02,555 DEV : loss 1.5667614936828613 - score 0.8727\n",
            "Epoch    52: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2021-08-10 23:17:02,585 BAD EPOCHS (no improvement): 4\n",
            "2021-08-10 23:17:02,586 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:17:04,618 epoch 53 - iter 27/275 - loss 1.72487105 - samples/sec: 426.07 - lr: 0.001563\n",
            "2021-08-10 23:17:06,669 epoch 53 - iter 54/275 - loss 1.65172616 - samples/sec: 422.04 - lr: 0.001563\n",
            "2021-08-10 23:17:08,660 epoch 53 - iter 81/275 - loss 1.66285182 - samples/sec: 434.87 - lr: 0.001563\n",
            "2021-08-10 23:17:10,652 epoch 53 - iter 108/275 - loss 1.62984579 - samples/sec: 434.42 - lr: 0.001563\n",
            "2021-08-10 23:17:12,619 epoch 53 - iter 135/275 - loss 1.62846017 - samples/sec: 440.53 - lr: 0.001563\n",
            "2021-08-10 23:17:14,576 epoch 53 - iter 162/275 - loss 1.64940951 - samples/sec: 442.38 - lr: 0.001563\n",
            "2021-08-10 23:17:16,635 epoch 53 - iter 189/275 - loss 1.65746719 - samples/sec: 420.29 - lr: 0.001563\n",
            "2021-08-10 23:17:18,615 epoch 53 - iter 216/275 - loss 1.66490958 - samples/sec: 437.16 - lr: 0.001563\n",
            "2021-08-10 23:17:20,610 epoch 53 - iter 243/275 - loss 1.65697056 - samples/sec: 433.85 - lr: 0.001563\n",
            "2021-08-10 23:17:22,653 epoch 53 - iter 270/275 - loss 1.65609460 - samples/sec: 423.65 - lr: 0.001563\n",
            "2021-08-10 23:17:23,011 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:17:23,012 EPOCH 53 done: loss 1.6594 - lr 0.0015625\n",
            "2021-08-10 23:17:24,776 DEV : loss 1.5666916370391846 - score 0.8724\n",
            "2021-08-10 23:17:24,806 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 23:17:24,808 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:17:26,815 epoch 54 - iter 27/275 - loss 1.56991059 - samples/sec: 431.52 - lr: 0.001563\n",
            "2021-08-10 23:17:28,933 epoch 54 - iter 54/275 - loss 1.60070005 - samples/sec: 408.60 - lr: 0.001563\n",
            "2021-08-10 23:17:31,119 epoch 54 - iter 81/275 - loss 1.60830726 - samples/sec: 395.88 - lr: 0.001563\n",
            "2021-08-10 23:17:33,207 epoch 54 - iter 108/275 - loss 1.63845973 - samples/sec: 414.63 - lr: 0.001563\n",
            "2021-08-10 23:17:35,273 epoch 54 - iter 135/275 - loss 1.62691095 - samples/sec: 418.97 - lr: 0.001563\n",
            "2021-08-10 23:17:37,387 epoch 54 - iter 162/275 - loss 1.63920817 - samples/sec: 409.44 - lr: 0.001563\n",
            "2021-08-10 23:17:39,513 epoch 54 - iter 189/275 - loss 1.67223264 - samples/sec: 406.98 - lr: 0.001563\n",
            "2021-08-10 23:17:41,636 epoch 54 - iter 216/275 - loss 1.68356591 - samples/sec: 407.86 - lr: 0.001563\n",
            "2021-08-10 23:17:43,760 epoch 54 - iter 243/275 - loss 1.66954454 - samples/sec: 407.47 - lr: 0.001563\n",
            "2021-08-10 23:17:45,874 epoch 54 - iter 270/275 - loss 1.67799095 - samples/sec: 409.40 - lr: 0.001563\n",
            "2021-08-10 23:17:46,273 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:17:46,275 EPOCH 54 done: loss 1.6813 - lr 0.0015625\n",
            "2021-08-10 23:17:47,440 DEV : loss 1.5644174814224243 - score 0.8729\n",
            "2021-08-10 23:17:47,473 BAD EPOCHS (no improvement): 2\n",
            "2021-08-10 23:17:47,475 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:17:49,670 epoch 55 - iter 27/275 - loss 1.59195558 - samples/sec: 394.66 - lr: 0.001563\n",
            "2021-08-10 23:17:51,772 epoch 55 - iter 54/275 - loss 1.66882340 - samples/sec: 411.71 - lr: 0.001563\n",
            "2021-08-10 23:17:53,867 epoch 55 - iter 81/275 - loss 1.67717744 - samples/sec: 413.03 - lr: 0.001563\n",
            "2021-08-10 23:17:55,815 epoch 55 - iter 108/275 - loss 1.65685079 - samples/sec: 444.74 - lr: 0.001563\n",
            "2021-08-10 23:17:57,801 epoch 55 - iter 135/275 - loss 1.65992049 - samples/sec: 435.74 - lr: 0.001563\n",
            "2021-08-10 23:17:59,827 epoch 55 - iter 162/275 - loss 1.67823572 - samples/sec: 427.12 - lr: 0.001563\n",
            "2021-08-10 23:18:01,798 epoch 55 - iter 189/275 - loss 1.68260329 - samples/sec: 439.21 - lr: 0.001563\n",
            "2021-08-10 23:18:03,831 epoch 55 - iter 216/275 - loss 1.66900952 - samples/sec: 426.04 - lr: 0.001563\n",
            "2021-08-10 23:18:05,807 epoch 55 - iter 243/275 - loss 1.67198677 - samples/sec: 438.10 - lr: 0.001563\n",
            "2021-08-10 23:18:07,806 epoch 55 - iter 270/275 - loss 1.68596551 - samples/sec: 433.05 - lr: 0.001563\n",
            "2021-08-10 23:18:08,233 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:18:08,234 EPOCH 55 done: loss 1.6863 - lr 0.0015625\n",
            "2021-08-10 23:18:09,384 DEV : loss 1.5638247728347778 - score 0.8725\n",
            "2021-08-10 23:18:09,413 BAD EPOCHS (no improvement): 3\n",
            "2021-08-10 23:18:09,415 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:18:11,397 epoch 56 - iter 27/275 - loss 1.67449914 - samples/sec: 437.02 - lr: 0.001563\n",
            "2021-08-10 23:18:13,414 epoch 56 - iter 54/275 - loss 1.65733490 - samples/sec: 429.19 - lr: 0.001563\n",
            "2021-08-10 23:18:15,446 epoch 56 - iter 81/275 - loss 1.69664910 - samples/sec: 426.21 - lr: 0.001563\n",
            "2021-08-10 23:18:17,486 epoch 56 - iter 108/275 - loss 1.69713037 - samples/sec: 424.26 - lr: 0.001563\n",
            "2021-08-10 23:18:19,513 epoch 56 - iter 135/275 - loss 1.70573137 - samples/sec: 426.97 - lr: 0.001563\n",
            "2021-08-10 23:18:21,562 epoch 56 - iter 162/275 - loss 1.69236229 - samples/sec: 422.42 - lr: 0.001563\n",
            "2021-08-10 23:18:23,704 epoch 56 - iter 189/275 - loss 1.68819729 - samples/sec: 404.01 - lr: 0.001563\n",
            "2021-08-10 23:18:25,768 epoch 56 - iter 216/275 - loss 1.68548764 - samples/sec: 419.40 - lr: 0.001563\n",
            "2021-08-10 23:18:27,882 epoch 56 - iter 243/275 - loss 1.68124013 - samples/sec: 409.41 - lr: 0.001563\n",
            "2021-08-10 23:18:29,958 epoch 56 - iter 270/275 - loss 1.66787169 - samples/sec: 416.93 - lr: 0.001563\n",
            "2021-08-10 23:18:30,337 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:18:30,339 EPOCH 56 done: loss 1.6646 - lr 0.0015625\n",
            "2021-08-10 23:18:31,448 DEV : loss 1.5668715238571167 - score 0.8727\n",
            "Epoch    56: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2021-08-10 23:18:31,476 BAD EPOCHS (no improvement): 4\n",
            "2021-08-10 23:18:31,478 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:18:33,547 epoch 57 - iter 27/275 - loss 1.55423640 - samples/sec: 418.83 - lr: 0.000781\n",
            "2021-08-10 23:18:35,763 epoch 57 - iter 54/275 - loss 1.53631294 - samples/sec: 390.77 - lr: 0.000781\n",
            "2021-08-10 23:18:37,977 epoch 57 - iter 81/275 - loss 1.56686846 - samples/sec: 390.80 - lr: 0.000781\n",
            "2021-08-10 23:18:40,176 epoch 57 - iter 108/275 - loss 1.60695402 - samples/sec: 393.67 - lr: 0.000781\n",
            "2021-08-10 23:18:42,325 epoch 57 - iter 135/275 - loss 1.61446705 - samples/sec: 402.59 - lr: 0.000781\n",
            "2021-08-10 23:18:44,480 epoch 57 - iter 162/275 - loss 1.62655997 - samples/sec: 401.63 - lr: 0.000781\n",
            "2021-08-10 23:18:46,617 epoch 57 - iter 189/275 - loss 1.62108932 - samples/sec: 404.99 - lr: 0.000781\n",
            "2021-08-10 23:18:48,825 epoch 57 - iter 216/275 - loss 1.62102097 - samples/sec: 391.92 - lr: 0.000781\n",
            "2021-08-10 23:18:51,008 epoch 57 - iter 243/275 - loss 1.62752949 - samples/sec: 396.51 - lr: 0.000781\n",
            "2021-08-10 23:18:53,161 epoch 57 - iter 270/275 - loss 1.65372969 - samples/sec: 402.13 - lr: 0.000781\n",
            "2021-08-10 23:18:53,565 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:18:53,567 EPOCH 57 done: loss 1.6536 - lr 0.0007813\n",
            "2021-08-10 23:18:54,769 DEV : loss 1.5654174089431763 - score 0.8736\n",
            "2021-08-10 23:18:54,800 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 23:18:54,803 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:18:56,956 epoch 58 - iter 27/275 - loss 1.81650447 - samples/sec: 402.22 - lr: 0.000781\n",
            "2021-08-10 23:18:59,094 epoch 58 - iter 54/275 - loss 1.67329763 - samples/sec: 404.97 - lr: 0.000781\n",
            "2021-08-10 23:19:01,169 epoch 58 - iter 81/275 - loss 1.66948785 - samples/sec: 417.18 - lr: 0.000781\n",
            "2021-08-10 23:19:03,283 epoch 58 - iter 108/275 - loss 1.66014560 - samples/sec: 409.56 - lr: 0.000781\n",
            "2021-08-10 23:19:05,402 epoch 58 - iter 135/275 - loss 1.63124043 - samples/sec: 408.39 - lr: 0.000781\n",
            "2021-08-10 23:19:07,627 epoch 58 - iter 162/275 - loss 1.63860386 - samples/sec: 389.01 - lr: 0.000781\n",
            "2021-08-10 23:19:09,796 epoch 58 - iter 189/275 - loss 1.63525835 - samples/sec: 399.02 - lr: 0.000781\n",
            "2021-08-10 23:19:11,925 epoch 58 - iter 216/275 - loss 1.63084936 - samples/sec: 406.51 - lr: 0.000781\n",
            "2021-08-10 23:19:14,097 epoch 58 - iter 243/275 - loss 1.64961753 - samples/sec: 398.46 - lr: 0.000781\n",
            "2021-08-10 23:19:16,276 epoch 58 - iter 270/275 - loss 1.65633970 - samples/sec: 397.23 - lr: 0.000781\n",
            "2021-08-10 23:19:16,718 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:19:16,719 EPOCH 58 done: loss 1.6512 - lr 0.0007813\n",
            "2021-08-10 23:19:17,887 DEV : loss 1.5659284591674805 - score 0.8736\n",
            "2021-08-10 23:19:17,919 BAD EPOCHS (no improvement): 2\n",
            "2021-08-10 23:19:17,920 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:19:20,014 epoch 59 - iter 27/275 - loss 1.68285904 - samples/sec: 413.93 - lr: 0.000781\n",
            "2021-08-10 23:19:22,158 epoch 59 - iter 54/275 - loss 1.66566580 - samples/sec: 403.55 - lr: 0.000781\n",
            "2021-08-10 23:19:24,393 epoch 59 - iter 81/275 - loss 1.63950603 - samples/sec: 387.26 - lr: 0.000781\n",
            "2021-08-10 23:19:26,502 epoch 59 - iter 108/275 - loss 1.64673168 - samples/sec: 410.52 - lr: 0.000781\n",
            "2021-08-10 23:19:28,662 epoch 59 - iter 135/275 - loss 1.65238592 - samples/sec: 400.83 - lr: 0.000781\n",
            "2021-08-10 23:19:30,759 epoch 59 - iter 162/275 - loss 1.67499342 - samples/sec: 412.79 - lr: 0.000781\n",
            "2021-08-10 23:19:32,900 epoch 59 - iter 189/275 - loss 1.66622257 - samples/sec: 404.32 - lr: 0.000781\n",
            "2021-08-10 23:19:34,979 epoch 59 - iter 216/275 - loss 1.64851468 - samples/sec: 416.34 - lr: 0.000781\n",
            "2021-08-10 23:19:37,022 epoch 59 - iter 243/275 - loss 1.66042950 - samples/sec: 423.83 - lr: 0.000781\n",
            "2021-08-10 23:19:39,151 epoch 59 - iter 270/275 - loss 1.66350352 - samples/sec: 406.45 - lr: 0.000781\n",
            "2021-08-10 23:19:39,533 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:19:39,535 EPOCH 59 done: loss 1.6588 - lr 0.0007813\n",
            "2021-08-10 23:19:40,724 DEV : loss 1.564049482345581 - score 0.8732\n",
            "2021-08-10 23:19:40,753 BAD EPOCHS (no improvement): 3\n",
            "2021-08-10 23:19:40,755 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:19:42,970 epoch 60 - iter 27/275 - loss 1.61680282 - samples/sec: 390.94 - lr: 0.000781\n",
            "2021-08-10 23:19:45,132 epoch 60 - iter 54/275 - loss 1.62109156 - samples/sec: 400.22 - lr: 0.000781\n",
            "2021-08-10 23:19:47,335 epoch 60 - iter 81/275 - loss 1.57007227 - samples/sec: 392.93 - lr: 0.000781\n",
            "2021-08-10 23:19:49,542 epoch 60 - iter 108/275 - loss 1.60858654 - samples/sec: 392.14 - lr: 0.000781\n",
            "2021-08-10 23:19:51,789 epoch 60 - iter 135/275 - loss 1.61264698 - samples/sec: 385.19 - lr: 0.000781\n",
            "2021-08-10 23:19:53,973 epoch 60 - iter 162/275 - loss 1.63540974 - samples/sec: 396.25 - lr: 0.000781\n",
            "2021-08-10 23:19:56,085 epoch 60 - iter 189/275 - loss 1.65683671 - samples/sec: 409.83 - lr: 0.000781\n",
            "2021-08-10 23:19:58,258 epoch 60 - iter 216/275 - loss 1.65453042 - samples/sec: 398.26 - lr: 0.000781\n",
            "2021-08-10 23:20:00,410 epoch 60 - iter 243/275 - loss 1.65356340 - samples/sec: 402.18 - lr: 0.000781\n",
            "2021-08-10 23:20:02,515 epoch 60 - iter 270/275 - loss 1.65488270 - samples/sec: 411.24 - lr: 0.000781\n",
            "2021-08-10 23:20:02,879 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:20:02,881 EPOCH 60 done: loss 1.6537 - lr 0.0007813\n",
            "2021-08-10 23:20:04,012 DEV : loss 1.5653631687164307 - score 0.8739\n",
            "Epoch    60: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2021-08-10 23:20:04,042 BAD EPOCHS (no improvement): 4\n",
            "2021-08-10 23:20:04,044 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:20:06,064 epoch 61 - iter 27/275 - loss 1.55430733 - samples/sec: 428.88 - lr: 0.000391\n",
            "2021-08-10 23:20:08,104 epoch 61 - iter 54/275 - loss 1.67291585 - samples/sec: 424.10 - lr: 0.000391\n",
            "2021-08-10 23:20:10,167 epoch 61 - iter 81/275 - loss 1.65260532 - samples/sec: 419.68 - lr: 0.000391\n",
            "2021-08-10 23:20:12,243 epoch 61 - iter 108/275 - loss 1.66928136 - samples/sec: 416.91 - lr: 0.000391\n",
            "2021-08-10 23:20:14,395 epoch 61 - iter 135/275 - loss 1.64190745 - samples/sec: 402.21 - lr: 0.000391\n",
            "2021-08-10 23:20:16,569 epoch 61 - iter 162/275 - loss 1.62842671 - samples/sec: 398.04 - lr: 0.000391\n",
            "2021-08-10 23:20:18,794 epoch 61 - iter 189/275 - loss 1.63609492 - samples/sec: 389.13 - lr: 0.000391\n",
            "2021-08-10 23:20:20,973 epoch 61 - iter 216/275 - loss 1.64398904 - samples/sec: 397.19 - lr: 0.000391\n",
            "2021-08-10 23:20:23,054 epoch 61 - iter 243/275 - loss 1.65689958 - samples/sec: 415.92 - lr: 0.000391\n",
            "2021-08-10 23:20:25,165 epoch 61 - iter 270/275 - loss 1.65842621 - samples/sec: 409.97 - lr: 0.000391\n",
            "2021-08-10 23:20:25,572 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:20:25,573 EPOCH 61 done: loss 1.6558 - lr 0.0003906\n",
            "2021-08-10 23:20:26,782 DEV : loss 1.5665150880813599 - score 0.8732\n",
            "2021-08-10 23:20:26,815 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 23:20:26,817 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:20:29,012 epoch 62 - iter 27/275 - loss 1.68469058 - samples/sec: 394.78 - lr: 0.000391\n",
            "2021-08-10 23:20:31,229 epoch 62 - iter 54/275 - loss 1.67386939 - samples/sec: 390.37 - lr: 0.000391\n",
            "2021-08-10 23:20:33,424 epoch 62 - iter 81/275 - loss 1.66571658 - samples/sec: 394.16 - lr: 0.000391\n",
            "2021-08-10 23:20:35,579 epoch 62 - iter 108/275 - loss 1.65685142 - samples/sec: 401.64 - lr: 0.000391\n",
            "2021-08-10 23:20:37,717 epoch 62 - iter 135/275 - loss 1.64690834 - samples/sec: 404.98 - lr: 0.000391\n",
            "2021-08-10 23:20:39,764 epoch 62 - iter 162/275 - loss 1.64770239 - samples/sec: 422.90 - lr: 0.000391\n",
            "2021-08-10 23:20:41,816 epoch 62 - iter 189/275 - loss 1.64701088 - samples/sec: 421.92 - lr: 0.000391\n",
            "2021-08-10 23:20:43,901 epoch 62 - iter 216/275 - loss 1.65823685 - samples/sec: 415.14 - lr: 0.000391\n",
            "2021-08-10 23:20:45,943 epoch 62 - iter 243/275 - loss 1.66455452 - samples/sec: 423.86 - lr: 0.000391\n",
            "2021-08-10 23:20:48,088 epoch 62 - iter 270/275 - loss 1.66241900 - samples/sec: 403.42 - lr: 0.000391\n",
            "2021-08-10 23:20:48,478 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:20:48,480 EPOCH 62 done: loss 1.6688 - lr 0.0003906\n",
            "2021-08-10 23:20:49,688 DEV : loss 1.5654324293136597 - score 0.8732\n",
            "2021-08-10 23:20:49,720 BAD EPOCHS (no improvement): 2\n",
            "2021-08-10 23:20:49,722 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:20:51,775 epoch 63 - iter 27/275 - loss 1.74591621 - samples/sec: 422.31 - lr: 0.000391\n",
            "2021-08-10 23:20:53,937 epoch 63 - iter 54/275 - loss 1.82291902 - samples/sec: 400.38 - lr: 0.000391\n",
            "2021-08-10 23:20:56,140 epoch 63 - iter 81/275 - loss 1.73310645 - samples/sec: 392.79 - lr: 0.000391\n",
            "2021-08-10 23:20:58,199 epoch 63 - iter 108/275 - loss 1.71020468 - samples/sec: 420.50 - lr: 0.000391\n",
            "2021-08-10 23:21:00,383 epoch 63 - iter 135/275 - loss 1.69000637 - samples/sec: 396.33 - lr: 0.000391\n",
            "2021-08-10 23:21:02,400 epoch 63 - iter 162/275 - loss 1.68029993 - samples/sec: 429.13 - lr: 0.000391\n",
            "2021-08-10 23:21:04,513 epoch 63 - iter 189/275 - loss 1.66647042 - samples/sec: 409.66 - lr: 0.000391\n",
            "2021-08-10 23:21:06,658 epoch 63 - iter 216/275 - loss 1.65518542 - samples/sec: 403.40 - lr: 0.000391\n",
            "2021-08-10 23:21:08,748 epoch 63 - iter 243/275 - loss 1.66488026 - samples/sec: 414.29 - lr: 0.000391\n",
            "2021-08-10 23:21:10,996 epoch 63 - iter 270/275 - loss 1.65597256 - samples/sec: 384.99 - lr: 0.000391\n",
            "2021-08-10 23:21:11,421 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:21:11,422 EPOCH 63 done: loss 1.6637 - lr 0.0003906\n",
            "2021-08-10 23:21:12,666 DEV : loss 1.565731406211853 - score 0.8732\n",
            "2021-08-10 23:21:12,699 BAD EPOCHS (no improvement): 3\n",
            "2021-08-10 23:21:12,701 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:21:14,815 epoch 64 - iter 27/275 - loss 1.59779035 - samples/sec: 409.83 - lr: 0.000391\n",
            "2021-08-10 23:21:17,043 epoch 64 - iter 54/275 - loss 1.62509774 - samples/sec: 388.45 - lr: 0.000391\n",
            "2021-08-10 23:21:19,280 epoch 64 - iter 81/275 - loss 1.64694499 - samples/sec: 386.81 - lr: 0.000391\n",
            "2021-08-10 23:21:21,510 epoch 64 - iter 108/275 - loss 1.69858476 - samples/sec: 388.23 - lr: 0.000391\n",
            "2021-08-10 23:21:23,735 epoch 64 - iter 135/275 - loss 1.67884819 - samples/sec: 389.00 - lr: 0.000391\n",
            "2021-08-10 23:21:25,977 epoch 64 - iter 162/275 - loss 1.65674374 - samples/sec: 385.99 - lr: 0.000391\n",
            "2021-08-10 23:21:28,170 epoch 64 - iter 189/275 - loss 1.67641749 - samples/sec: 394.60 - lr: 0.000391\n",
            "2021-08-10 23:21:30,386 epoch 64 - iter 216/275 - loss 1.67771419 - samples/sec: 390.59 - lr: 0.000391\n",
            "2021-08-10 23:21:32,593 epoch 64 - iter 243/275 - loss 1.66585515 - samples/sec: 392.24 - lr: 0.000391\n",
            "2021-08-10 23:21:34,779 epoch 64 - iter 270/275 - loss 1.65308154 - samples/sec: 395.87 - lr: 0.000391\n",
            "2021-08-10 23:21:35,176 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:21:35,178 EPOCH 64 done: loss 1.6509 - lr 0.0003906\n",
            "2021-08-10 23:21:36,414 DEV : loss 1.5652023553848267 - score 0.8725\n",
            "Epoch    64: reducing learning rate of group 0 to 1.9531e-04.\n",
            "2021-08-10 23:21:36,446 BAD EPOCHS (no improvement): 4\n",
            "2021-08-10 23:21:36,447 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:21:38,594 epoch 65 - iter 27/275 - loss 1.55055179 - samples/sec: 403.33 - lr: 0.000195\n",
            "2021-08-10 23:21:40,783 epoch 65 - iter 54/275 - loss 1.62202977 - samples/sec: 395.38 - lr: 0.000195\n",
            "2021-08-10 23:21:42,901 epoch 65 - iter 81/275 - loss 1.62141158 - samples/sec: 408.75 - lr: 0.000195\n",
            "2021-08-10 23:21:45,044 epoch 65 - iter 108/275 - loss 1.64487868 - samples/sec: 403.79 - lr: 0.000195\n",
            "2021-08-10 23:21:47,120 epoch 65 - iter 135/275 - loss 1.65775985 - samples/sec: 416.90 - lr: 0.000195\n",
            "2021-08-10 23:21:49,248 epoch 65 - iter 162/275 - loss 1.67192500 - samples/sec: 406.73 - lr: 0.000195\n",
            "2021-08-10 23:21:51,370 epoch 65 - iter 189/275 - loss 1.67341314 - samples/sec: 407.87 - lr: 0.000195\n",
            "2021-08-10 23:21:53,595 epoch 65 - iter 216/275 - loss 1.66963954 - samples/sec: 389.15 - lr: 0.000195\n",
            "2021-08-10 23:21:55,779 epoch 65 - iter 243/275 - loss 1.67945184 - samples/sec: 396.24 - lr: 0.000195\n",
            "2021-08-10 23:21:57,894 epoch 65 - iter 270/275 - loss 1.67046814 - samples/sec: 409.24 - lr: 0.000195\n",
            "2021-08-10 23:21:58,308 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:21:58,310 EPOCH 65 done: loss 1.6754 - lr 0.0001953\n",
            "2021-08-10 23:21:59,529 DEV : loss 1.5651743412017822 - score 0.8725\n",
            "2021-08-10 23:21:59,560 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 23:21:59,562 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:22:01,684 epoch 66 - iter 27/275 - loss 1.64277141 - samples/sec: 408.23 - lr: 0.000195\n",
            "2021-08-10 23:22:03,861 epoch 66 - iter 54/275 - loss 1.64466059 - samples/sec: 397.67 - lr: 0.000195\n",
            "2021-08-10 23:22:06,041 epoch 66 - iter 81/275 - loss 1.70001595 - samples/sec: 396.92 - lr: 0.000195\n",
            "2021-08-10 23:22:08,186 epoch 66 - iter 108/275 - loss 1.67247600 - samples/sec: 403.45 - lr: 0.000195\n",
            "2021-08-10 23:22:10,315 epoch 66 - iter 135/275 - loss 1.65369031 - samples/sec: 406.58 - lr: 0.000195\n",
            "2021-08-10 23:22:12,400 epoch 66 - iter 162/275 - loss 1.65705273 - samples/sec: 415.19 - lr: 0.000195\n",
            "2021-08-10 23:22:14,465 epoch 66 - iter 189/275 - loss 1.63696891 - samples/sec: 419.11 - lr: 0.000195\n",
            "2021-08-10 23:22:16,645 epoch 66 - iter 216/275 - loss 1.63738643 - samples/sec: 397.02 - lr: 0.000195\n",
            "2021-08-10 23:22:18,814 epoch 66 - iter 243/275 - loss 1.63572843 - samples/sec: 399.08 - lr: 0.000195\n",
            "2021-08-10 23:22:20,963 epoch 66 - iter 270/275 - loss 1.65598845 - samples/sec: 402.61 - lr: 0.000195\n",
            "2021-08-10 23:22:21,344 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:22:21,345 EPOCH 66 done: loss 1.6568 - lr 0.0001953\n",
            "2021-08-10 23:22:22,533 DEV : loss 1.5654360055923462 - score 0.8725\n",
            "2021-08-10 23:22:22,565 BAD EPOCHS (no improvement): 2\n",
            "2021-08-10 23:22:22,567 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:22:24,776 epoch 67 - iter 27/275 - loss 1.65941828 - samples/sec: 392.48 - lr: 0.000195\n",
            "2021-08-10 23:22:26,955 epoch 67 - iter 54/275 - loss 1.65694962 - samples/sec: 397.26 - lr: 0.000195\n",
            "2021-08-10 23:22:29,105 epoch 67 - iter 81/275 - loss 1.67975059 - samples/sec: 402.60 - lr: 0.000195\n",
            "2021-08-10 23:22:31,296 epoch 67 - iter 108/275 - loss 1.67495889 - samples/sec: 395.07 - lr: 0.000195\n",
            "2021-08-10 23:22:33,500 epoch 67 - iter 135/275 - loss 1.67799545 - samples/sec: 392.69 - lr: 0.000195\n",
            "2021-08-10 23:22:35,610 epoch 67 - iter 162/275 - loss 1.65789825 - samples/sec: 410.10 - lr: 0.000195\n",
            "2021-08-10 23:22:37,794 epoch 67 - iter 189/275 - loss 1.66240444 - samples/sec: 396.38 - lr: 0.000195\n",
            "2021-08-10 23:22:39,989 epoch 67 - iter 216/275 - loss 1.67087582 - samples/sec: 394.16 - lr: 0.000195\n",
            "2021-08-10 23:22:42,196 epoch 67 - iter 243/275 - loss 1.68279089 - samples/sec: 392.26 - lr: 0.000195\n",
            "2021-08-10 23:22:44,404 epoch 67 - iter 270/275 - loss 1.66715917 - samples/sec: 392.03 - lr: 0.000195\n",
            "2021-08-10 23:22:44,826 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:22:44,827 EPOCH 67 done: loss 1.6661 - lr 0.0001953\n",
            "2021-08-10 23:22:46,063 DEV : loss 1.565294861793518 - score 0.8725\n",
            "2021-08-10 23:22:46,095 BAD EPOCHS (no improvement): 3\n",
            "2021-08-10 23:22:46,097 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:22:48,281 epoch 68 - iter 27/275 - loss 1.65782934 - samples/sec: 396.54 - lr: 0.000195\n",
            "2021-08-10 23:22:50,479 epoch 68 - iter 54/275 - loss 1.66461546 - samples/sec: 393.74 - lr: 0.000195\n",
            "2021-08-10 23:22:52,559 epoch 68 - iter 81/275 - loss 1.67135699 - samples/sec: 416.25 - lr: 0.000195\n",
            "2021-08-10 23:22:54,599 epoch 68 - iter 108/275 - loss 1.64775415 - samples/sec: 424.27 - lr: 0.000195\n",
            "2021-08-10 23:22:56,664 epoch 68 - iter 135/275 - loss 1.62917008 - samples/sec: 419.25 - lr: 0.000195\n",
            "2021-08-10 23:22:58,755 epoch 68 - iter 162/275 - loss 1.63919013 - samples/sec: 413.78 - lr: 0.000195\n",
            "2021-08-10 23:23:00,815 epoch 68 - iter 189/275 - loss 1.63719437 - samples/sec: 420.23 - lr: 0.000195\n",
            "2021-08-10 23:23:02,864 epoch 68 - iter 216/275 - loss 1.63989627 - samples/sec: 422.31 - lr: 0.000195\n",
            "2021-08-10 23:23:04,948 epoch 68 - iter 243/275 - loss 1.64663721 - samples/sec: 415.43 - lr: 0.000195\n",
            "2021-08-10 23:23:07,034 epoch 68 - iter 270/275 - loss 1.64222262 - samples/sec: 414.82 - lr: 0.000195\n",
            "2021-08-10 23:23:07,406 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:23:07,407 EPOCH 68 done: loss 1.6451 - lr 0.0001953\n",
            "2021-08-10 23:23:08,554 DEV : loss 1.5646367073059082 - score 0.8725\n",
            "Epoch    68: reducing learning rate of group 0 to 9.7656e-05.\n",
            "2021-08-10 23:23:08,589 BAD EPOCHS (no improvement): 4\n",
            "2021-08-10 23:23:08,592 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:23:08,594 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:23:08,595 learning rate too small - quitting training!\n",
            "2021-08-10 23:23:08,596 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:23:11,165 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 23:23:11,166 Testing using best model ...\n",
            "2021-08-10 23:23:11,168 loading file resources/taggers/example-pos/best-model.pt\n",
            "2021-08-10 23:23:15,021 0.8735\t0.8655\t0.8695\n",
            "2021-08-10 23:23:15,022 \n",
            "Results:\n",
            "- F1-score (micro) 0.8695\n",
            "- F1-score (macro) 0.7603\n",
            "\n",
            "By class:\n",
            "ACTOR      tp: 761 - fp: 92 - fn: 51 - precision: 0.8921 - recall: 0.9372 - f1-score: 0.9141\n",
            "CHARACTER  tp: 55 - fp: 21 - fn: 35 - precision: 0.7237 - recall: 0.6111 - f1-score: 0.6627\n",
            "DIRECTOR   tp: 392 - fp: 25 - fn: 64 - precision: 0.9400 - recall: 0.8596 - f1-score: 0.8981\n",
            "GENRE      tp: 1046 - fp: 152 - fn: 71 - precision: 0.8731 - recall: 0.9364 - f1-score: 0.9037\n",
            "PLOT       tp: 329 - fp: 115 - fn: 162 - precision: 0.7410 - recall: 0.6701 - f1-score: 0.7037\n",
            "RATING     tp: 460 - fp: 41 - fn: 40 - precision: 0.9182 - recall: 0.9200 - f1-score: 0.9191\n",
            "RATINGS_AVERAGE tp: 387 - fp: 57 - fn: 64 - precision: 0.8716 - recall: 0.8581 - f1-score: 0.8648\n",
            "REVIEW     tp: 3 - fp: 2 - fn: 53 - precision: 0.6000 - recall: 0.0536 - f1-score: 0.0984\n",
            "SONG       tp: 27 - fp: 15 - fn: 27 - precision: 0.6429 - recall: 0.5000 - f1-score: 0.5625\n",
            "TITLE      tp: 457 - fp: 99 - fn: 105 - precision: 0.8219 - recall: 0.8132 - f1-score: 0.8175\n",
            "TRAILER    tp: 26 - fp: 6 - fn: 4 - precision: 0.8125 - recall: 0.8667 - f1-score: 0.8387\n",
            "YEAR       tp: 678 - fp: 44 - fn: 42 - precision: 0.9391 - recall: 0.9417 - f1-score: 0.9404\n",
            "2021-08-10 23:23:15,024 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [8.350046157836914,\n",
              "  3.6717288494110107,\n",
              "  3.112675189971924,\n",
              "  2.752936601638794,\n",
              "  2.6070942878723145,\n",
              "  2.447624683380127,\n",
              "  2.2388458251953125,\n",
              "  2.2438907623291016,\n",
              "  2.0877411365509033,\n",
              "  2.0780882835388184,\n",
              "  2.027496814727783,\n",
              "  1.8975800275802612,\n",
              "  1.8896929025650024,\n",
              "  1.883002758026123,\n",
              "  1.8897616863250732,\n",
              "  1.8667683601379395,\n",
              "  1.7645069360733032,\n",
              "  1.8393474817276,\n",
              "  1.7648714780807495,\n",
              "  1.78157377243042,\n",
              "  1.7588436603546143,\n",
              "  1.7639039754867554,\n",
              "  1.7452330589294434,\n",
              "  1.778531551361084,\n",
              "  1.763561725616455,\n",
              "  1.6823792457580566,\n",
              "  1.6573522090911865,\n",
              "  1.6564821004867554,\n",
              "  1.6109166145324707,\n",
              "  1.6081266403198242,\n",
              "  1.626693606376648,\n",
              "  1.5893868207931519,\n",
              "  1.6187775135040283,\n",
              "  1.6264700889587402,\n",
              "  1.6179977655410767,\n",
              "  1.6392091512680054,\n",
              "  1.6004177331924438,\n",
              "  1.5906106233596802,\n",
              "  1.5771229267120361,\n",
              "  1.5926176309585571,\n",
              "  1.5777183771133423,\n",
              "  1.5826704502105713,\n",
              "  1.5750762224197388,\n",
              "  1.5686516761779785,\n",
              "  1.574697494506836,\n",
              "  1.5830564498901367,\n",
              "  1.580507516860962,\n",
              "  1.5702424049377441,\n",
              "  1.5702348947525024,\n",
              "  1.570762038230896,\n",
              "  1.5574268102645874,\n",
              "  1.5667614936828613,\n",
              "  1.5666916370391846,\n",
              "  1.5644174814224243,\n",
              "  1.5638247728347778,\n",
              "  1.5668715238571167,\n",
              "  1.5654174089431763,\n",
              "  1.5659284591674805,\n",
              "  1.564049482345581,\n",
              "  1.5653631687164307,\n",
              "  1.5665150880813599,\n",
              "  1.5654324293136597,\n",
              "  1.565731406211853,\n",
              "  1.5652023553848267,\n",
              "  1.5651743412017822,\n",
              "  1.5654360055923462,\n",
              "  1.565294861793518,\n",
              "  1.5646367073059082],\n",
              " 'dev_score_history': [0.5311679006448532,\n",
              "  0.7208899876390605,\n",
              "  0.7575908412145346,\n",
              "  0.7781065088757396,\n",
              "  0.8024844720496894,\n",
              "  0.8052644406531806,\n",
              "  0.8231869997574581,\n",
              "  0.8272660640117274,\n",
              "  0.8340980439507365,\n",
              "  0.843757546486356,\n",
              "  0.8471044342137145,\n",
              "  0.8509708737864077,\n",
              "  0.8538350217076701,\n",
              "  0.8587979724837075,\n",
              "  0.8590799031476998,\n",
              "  0.8505802707930367,\n",
              "  0.8598220726136091,\n",
              "  0.8590701035894964,\n",
              "  0.8562514998800096,\n",
              "  0.8612578012481996,\n",
              "  0.8639768059917855,\n",
              "  0.8593523441275978,\n",
              "  0.863132530120482,\n",
              "  0.8629539951573849,\n",
              "  0.8639308855291578,\n",
              "  0.8688327316486161,\n",
              "  0.8678881388621023,\n",
              "  0.8613837682547282,\n",
              "  0.8684779995191152,\n",
              "  0.8688760806916427,\n",
              "  0.8706335822693326,\n",
              "  0.8756314649987973,\n",
              "  0.8719306692344728,\n",
              "  0.8713872832369942,\n",
              "  0.8711153938809926,\n",
              "  0.8677427125993737,\n",
              "  0.8687695641704791,\n",
              "  0.8704015388314499,\n",
              "  0.8712394705174489,\n",
              "  0.8731918997107039,\n",
              "  0.8719923002887393,\n",
              "  0.870967741935484,\n",
              "  0.8718072289156626,\n",
              "  0.8720790171043123,\n",
              "  0.8726483357452965,\n",
              "  0.8723506743737958,\n",
              "  0.8733140655105973,\n",
              "  0.8724735322425409,\n",
              "  0.8728935965334618,\n",
              "  0.871868978805395,\n",
              "  0.8726835138387485,\n",
              "  0.8726835138387485,\n",
              "  0.8724121328839674,\n",
              "  0.8728935965334618,\n",
              "  0.8724735322425409,\n",
              "  0.8727447678614385,\n",
              "  0.8736462093862816,\n",
              "  0.8736462093862816,\n",
              "  0.8731648616125149,\n",
              "  0.8738565238324506,\n",
              "  0.8731648616125149,\n",
              "  0.8731648616125149,\n",
              "  0.8731648616125149,\n",
              "  0.8724735322425409,\n",
              "  0.8724735322425409,\n",
              "  0.8724735322425409,\n",
              "  0.8724735322425409,\n",
              "  0.8724735322425409],\n",
              " 'test_score': 0.8695079499482548,\n",
              " 'train_loss_history': [11.353003725138578,\n",
              "  5.606176086772572,\n",
              "  4.395018853274259,\n",
              "  3.85033070824363,\n",
              "  3.4662438158555466,\n",
              "  3.2504312016747217,\n",
              "  3.089949318712408,\n",
              "  2.9241726220737805,\n",
              "  2.8012696834044024,\n",
              "  2.7407667948982932,\n",
              "  2.6517162453044545,\n",
              "  2.563871955871582,\n",
              "  2.5181815949353306,\n",
              "  2.402941749312661,\n",
              "  2.424770886247808,\n",
              "  2.3699678386341443,\n",
              "  2.293922343037345,\n",
              "  2.2656713169271296,\n",
              "  2.244120608243075,\n",
              "  2.2020806496793575,\n",
              "  2.1695856055346403,\n",
              "  2.142328211177479,\n",
              "  2.106565138426694,\n",
              "  2.0913497630032625,\n",
              "  2.0822944909876044,\n",
              "  1.9662838346307927,\n",
              "  1.947908923409202,\n",
              "  1.9091585298018021,\n",
              "  1.905959284955805,\n",
              "  1.8815680579705671,\n",
              "  1.8687103431875056,\n",
              "  1.8545716008273039,\n",
              "  1.8478679331866177,\n",
              "  1.8204169600660152,\n",
              "  1.8264753614772449,\n",
              "  1.8012103020061145,\n",
              "  1.7494290572946722,\n",
              "  1.7444929762320085,\n",
              "  1.7455538509108803,\n",
              "  1.7246678699146618,\n",
              "  1.7005149544369091,\n",
              "  1.715477705001831,\n",
              "  1.696341562054374,\n",
              "  1.713000814481215,\n",
              "  1.7005727770111778,\n",
              "  1.7050191866267812,\n",
              "  1.6906269925290889,\n",
              "  1.6852692918343977,\n",
              "  1.6759578297354958,\n",
              "  1.6701606319167397,\n",
              "  1.6661846163056113,\n",
              "  1.6652375477010553,\n",
              "  1.6593542935631491,\n",
              "  1.6813067189129915,\n",
              "  1.6862798725474963,\n",
              "  1.6646443624929947,\n",
              "  1.6535667328401045,\n",
              "  1.6511646988175133,\n",
              "  1.658797068379142,\n",
              "  1.6536800601265647,\n",
              "  1.655845860784704,\n",
              "  1.6687730498747393,\n",
              "  1.663747956536033,\n",
              "  1.6509429851445285,\n",
              "  1.6753819723562762,\n",
              "  1.656760265827179,\n",
              "  1.666055905385451,\n",
              "  1.645138574513522]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipSg0xiUX1NK"
      },
      "source": [
        "#### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr1ScKkIX4cU"
      },
      "source": [
        "# Individual class scores and overall scores, generated in the training.log file (at the very end).\n",
        "# https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin\n",
        "\"\"\"\n",
        "Results:\n",
        "- F1-score (micro) 0.8695\n",
        "- F1-score (macro) 0.7603\n",
        "\n",
        "By class:\n",
        "ACTOR      tp: 761 - fp: 92 - fn: 51 - precision: 0.8921 - recall: 0.9372 - f1-score: 0.9141\n",
        "CHARACTER  tp: 55 - fp: 21 - fn: 35 - precision: 0.7237 - recall: 0.6111 - f1-score: 0.6627\n",
        "DIRECTOR   tp: 392 - fp: 25 - fn: 64 - precision: 0.9400 - recall: 0.8596 - f1-score: 0.8981\n",
        "GENRE      tp: 1046 - fp: 152 - fn: 71 - precision: 0.8731 - recall: 0.9364 - f1-score: 0.9037\n",
        "PLOT       tp: 329 - fp: 115 - fn: 162 - precision: 0.7410 - recall: 0.6701 - f1-score: 0.7037\n",
        "RATING     tp: 460 - fp: 41 - fn: 40 - precision: 0.9182 - recall: 0.9200 - f1-score: 0.9191\n",
        "RATINGS_AVERAGE tp: 387 - fp: 57 - fn: 64 - precision: 0.8716 - recall: 0.8581 - f1-score: 0.8648\n",
        "REVIEW     tp: 3 - fp: 2 - fn: 53 - precision: 0.6000 - recall: 0.0536 - f1-score: 0.0984\n",
        "SONG       tp: 27 - fp: 15 - fn: 27 - precision: 0.6429 - recall: 0.5000 - f1-score: 0.5625\n",
        "TITLE      tp: 457 - fp: 99 - fn: 105 - precision: 0.8219 - recall: 0.8132 - f1-score: 0.8175\n",
        "TRAILER    tp: 26 - fp: 6 - fn: 4 - precision: 0.8125 - recall: 0.8667 - f1-score: 0.8387\n",
        "YEAR       tp: 678 - fp: 44 - fn: 42 - precision: 0.9391 - recall: 0.9417 - f1-score: 0.9404\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "02U7wib_X-8F",
        "outputId": "11431f66-03e9-4cca-a58d-2bdd9b5e1a57"
      },
      "source": [
        "# Read the loss.tsv\n",
        "import pandas as pd\n",
        "df = pd.read_csv('resources/taggers/example-pos/loss.tsv', sep='\\t', header=0)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EPOCH</th>\n",
              "      <th>TIMESTAMP</th>\n",
              "      <th>BAD_EPOCHS</th>\n",
              "      <th>LEARNING_RATE</th>\n",
              "      <th>TRAIN_LOSS</th>\n",
              "      <th>DEV_LOSS</th>\n",
              "      <th>DEV_PRECISION</th>\n",
              "      <th>DEV_RECALL</th>\n",
              "      <th>DEV_F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>22:57:15</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>11.353004</td>\n",
              "      <td>8.350046</td>\n",
              "      <td>0.5305</td>\n",
              "      <td>0.5318</td>\n",
              "      <td>0.5312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>22:57:40</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>5.606176</td>\n",
              "      <td>3.671729</td>\n",
              "      <td>0.7462</td>\n",
              "      <td>0.6973</td>\n",
              "      <td>0.7209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>22:58:05</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>4.395019</td>\n",
              "      <td>3.112675</td>\n",
              "      <td>0.7898</td>\n",
              "      <td>0.7279</td>\n",
              "      <td>0.7576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>22:58:31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>3.850331</td>\n",
              "      <td>2.752937</td>\n",
              "      <td>0.8031</td>\n",
              "      <td>0.7547</td>\n",
              "      <td>0.7781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>22:58:55</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>3.466244</td>\n",
              "      <td>2.607094</td>\n",
              "      <td>0.8351</td>\n",
              "      <td>0.7724</td>\n",
              "      <td>0.8025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>64</td>\n",
              "      <td>23:21:36</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>1.650943</td>\n",
              "      <td>1.565202</td>\n",
              "      <td>0.8780</td>\n",
              "      <td>0.8670</td>\n",
              "      <td>0.8725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>65</td>\n",
              "      <td>23:21:59</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>1.675382</td>\n",
              "      <td>1.565174</td>\n",
              "      <td>0.8780</td>\n",
              "      <td>0.8670</td>\n",
              "      <td>0.8725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>66</td>\n",
              "      <td>23:22:22</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>1.656760</td>\n",
              "      <td>1.565436</td>\n",
              "      <td>0.8780</td>\n",
              "      <td>0.8670</td>\n",
              "      <td>0.8725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>67</td>\n",
              "      <td>23:22:46</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>1.666056</td>\n",
              "      <td>1.565295</td>\n",
              "      <td>0.8780</td>\n",
              "      <td>0.8670</td>\n",
              "      <td>0.8725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>68</td>\n",
              "      <td>23:23:08</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>1.645139</td>\n",
              "      <td>1.564637</td>\n",
              "      <td>0.8780</td>\n",
              "      <td>0.8670</td>\n",
              "      <td>0.8725</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>68 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    EPOCH TIMESTAMP  BAD_EPOCHS  ...  DEV_PRECISION  DEV_RECALL  DEV_F1\n",
              "0       1  22:57:15           0  ...         0.5305      0.5318  0.5312\n",
              "1       2  22:57:40           0  ...         0.7462      0.6973  0.7209\n",
              "2       3  22:58:05           0  ...         0.7898      0.7279  0.7576\n",
              "3       4  22:58:31           0  ...         0.8031      0.7547  0.7781\n",
              "4       5  22:58:55           0  ...         0.8351      0.7724  0.8025\n",
              "..    ...       ...         ...  ...            ...         ...     ...\n",
              "63     64  23:21:36           4  ...         0.8780      0.8670  0.8725\n",
              "64     65  23:21:59           1  ...         0.8780      0.8670  0.8725\n",
              "65     66  23:22:22           2  ...         0.8780      0.8670  0.8725\n",
              "66     67  23:22:46           3  ...         0.8780      0.8670  0.8725\n",
              "67     68  23:23:08           4  ...         0.8780      0.8670  0.8725\n",
              "\n",
              "[68 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60SbisS-YDWU"
      },
      "source": [
        "* Final training loss : 1.645139\n",
        "* Final dev loss : 1.564637\n",
        "* Final dev precision : 0.8780\t\n",
        "* Final dev recall : 0.8670\n",
        "* Final dev F1 score : 0.8725"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "q3I7FAG9YNIM",
        "outputId": "5aa18fb5-0b5a-49fe-cf16-df21e6b2bc41"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "font = {'family':'serif','color':'darkred','size':15}\n",
        "fontHead = {'family':'serif','color':'blue','size':20}\n",
        "\n",
        "plt.plot(df[\"TRAIN_LOSS\"],color=\"orange\",label='Train loss')\n",
        "plt.plot(df[\"DEV_LOSS\"],label='Dev loss')\n",
        "plt.xlabel(\"Epoch\",fontdict = font)\n",
        "plt.ylabel(\"Loss\",fontdict = font)\n",
        "plt.title(\"Loss wrt epoch\",fontdict=fontHead)\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "ejW-Z1lyYST0",
        "outputId": "31ea78a7-a90d-4cb0-d77e-5804de1c2e13"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "font = {'family':'serif','color':'darkred','size':15}\n",
        "fontHead = {'family':'serif','color':'blue','size':20}\n",
        "\n",
        "plt.plot(df[\"DEV_PRECISION\"],color=\"orange\",label='Dev Precision')\n",
        "plt.plot(df[\"DEV_RECALL\"],label='Dev Recall')\n",
        "plt.plot(df[\"DEV_F1\"],color=\"red\",label='Dev F1')\n",
        "plt.xlabel(\"Epoch\",fontdict = font)\n",
        "plt.ylabel(\"Measure\",fontdict = font)\n",
        "plt.title(\"Dev Precision/Recall and F1 wrt epoch\",fontdict=fontHead)\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMXY0ARWYVZc"
      },
      "source": [
        "#### Few Prediction made by trained model on test set\n",
        "The predcitions can be viewed in the file generated test.tsv.\n",
        "It contains predictions as follows, wher first column is the word, second is the actual tag and third is the predicted tag:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIBhvfpfYqor"
      },
      "source": [
        "# First example of test file. all tags are correctly predicted except the year ones (Format: Word, Actual Tag, Predicted Tag)\n",
        "\"\"\"\n",
        "are O O\n",
        "there O O\n",
        "any O O\n",
        "good O O\n",
        "romantic B-GENRE B-GENRE\n",
        "comedies I-GENRE I-GENRE\n",
        "out O O\n",
        "right B-YEAR O\n",
        "now I-YEAR O\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Dw-wI78ZAsr"
      },
      "source": [
        "# Second example of test file, all tags correctly predicted\n",
        "\"\"\"\n",
        "show O O\n",
        "me O O\n",
        "a O O\n",
        "movie O O\n",
        "about O O\n",
        "cars B-PLOT B-PLOT\n",
        "that I-PLOT I-PLOT\n",
        "talk I-PLOT I-PLOT\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqIYJclSZCq5"
      },
      "source": [
        "#### Some prediction made by self made example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYrU3nl7ZDgd",
        "outputId": "77b14c84-cf63-47b1-9dfa-29b4bf58d68b"
      },
      "source": [
        "model = SequenceTagger.load('resources/taggers/example-pos/final-model.pt') # load the trained model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-10 23:29:24,283 loading file resources/taggers/example-pos/final-model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzRkBPDHZHIL",
        "outputId": "1d9234bd-e6fb-4a5e-a3db-cb48d9f6195f"
      },
      "source": [
        "sentence = Sentence('list the five star rated movies starring mel gibson')\n",
        "model.predict(sentence) # predict the tags\n",
        "print(sentence.to_tagged_string())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "list the five <B-RATINGS_AVERAGE> star <I-RATINGS_AVERAGE> rated movies starring mel <B-ACTOR> gibson <I-ACTOR>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWsOz3hNZNIM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e59f327-9fd1-47a2-f703-fca66fabc37b"
      },
      "source": [
        "sentence = Sentence('want to see an indian movie')\n",
        "model.predict(sentence) # predict the tags\n",
        "print(sentence.to_tagged_string())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "want to see an indian <B-GENRE> movie\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9_JPD7IZPSU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d13ee476-850c-44c9-c140-bee3c9e49d99"
      },
      "source": [
        "sentence = Sentence('which is the latest movie directed by Martin Scorsese')\n",
        "model.predict(sentence) # predict the tags\n",
        "print(sentence.to_tagged_string())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "which is the latest movie directed by Martin <B-DIRECTOR> Scorsese <I-DIRECTOR>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxg8HzpeZSIy"
      },
      "source": [
        "It works good!!"
      ]
    }
  ]
}