{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trivia10k13-Flair-Sequence-Tagging.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "887a0d9d333142cab55f8f9c9860a667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1740a327c1a74d21948ed31a84c78ec9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d355415d4593452abb8434644067cad9",
              "IPY_MODEL_25aead8666074ca09c7950a84a695862"
            ]
          }
        },
        "1740a327c1a74d21948ed31a84c78ec9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d355415d4593452abb8434644067cad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ef5ff10a40a0464290160624dcac597d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 432176557,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 432176557,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ddaf5e96e0224044b9c9a7352bb1b644"
          }
        },
        "25aead8666074ca09c7950a84a695862": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bcb749e699504a4e8098a84184c85b64",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 432M/432M [03:24&lt;00:00, 2.11MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e85d052b1334c64a69fe5c3be84891f"
          }
        },
        "ef5ff10a40a0464290160624dcac597d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ddaf5e96e0224044b9c9a7352bb1b644": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bcb749e699504a4e8098a84184c85b64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e85d052b1334c64a69fe5c3be84891f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na2UrGculDat"
      },
      "source": [
        "# Setup Notebook and GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vATLgYATkDTe",
        "outputId": "ede73a43-eb87-4553-d65b-9bea54b077db"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-3e119bbd-038d-ec98-1c1f-4a6c3b46a1e9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkK8nhT2lPDl",
        "outputId": "e1a633ff-8df4-40a7-f59f-c374b9e3ae2d"
      },
      "source": [
        "!lscpu |grep 'Model name'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPCGOyNWlQLd"
      },
      "source": [
        "# Sequence Tagging Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bKd4rPulcrE"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXvXsEMjlTiT",
        "outputId": "2820263b-19e5-4ddd-f7a1-bc8387671b1d"
      },
      "source": [
        "! pip install flair # https://github.com/flairNLP/flair"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flair\n",
            "  Downloading flair-0.8.0.post1-py3-none-any.whl (284 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 30 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 40 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 51 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |███████                         | 61 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 71 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 81 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 102 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 112 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 122 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 133 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 143 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 153 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 163 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 174 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 184 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 194 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 204 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 215 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 225 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 235 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 245 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 256 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 266 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 276 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 284 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 61.5 MB/s \n",
            "\u001b[?25hCollecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n",
            "Collecting torch<=1.7.1,>=1.5.0\n",
            "  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8 MB 9.4 kB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2019.12.20)\n",
            "Collecting gdown==3.12.2\n",
            "  Downloading gdown-3.12.2.tar.gz (8.2 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy<1.20.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.19.5)\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading Deprecated-1.2.12-py2.py3-none-any.whl (9.5 kB)\n",
            "Collecting bpemb>=0.3.2\n",
            "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n",
            "Collecting janome\n",
            "  Downloading Janome-0.4.1-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7 MB 13.1 MB/s \n",
            "\u001b[?25hCollecting mpld3==0.3\n",
            "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
            "\u001b[K     |████████████████████████████████| 788 kB 72.5 MB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 55.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.2)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting sqlitedict>=1.6.0\n",
            "  Downloading sqlitedict-1.7.0.tar.gz (28 kB)\n",
            "Requirement already satisfied: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading segtok-1.5.10.tar.gz (25 kB)\n",
            "Collecting transformers>=4.0.0\n",
            "  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 63.9 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.0.15-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.41.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (3.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (1.15.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (5.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (2.5.1)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (3.11.4)\n",
            "Collecting overrides<4.0.0,>=3.0.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "Collecting requests\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.0 MB/s \n",
            "\u001b[?25hCollecting importlib-metadata<4.0.0,>=3.7.0\n",
            "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.5.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.0.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2021.5.30)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (21.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 89.1 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 69.8 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 84.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->flair) (7.1.2)\n",
            "Building wheels for collected packages: gdown, mpld3, overrides, segtok, sqlitedict, ftfy, langdetect\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-3.12.2-py3-none-any.whl size=9705 sha256=c823ff3477e7c2297e3dd3df464edb6c0e3fd393bc583ea9eb70944ddbf639bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/e0/7e/726e872a53f7358b4b96a9975b04e98113b005cd8609a63abc\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116701 sha256=b0de29bc12f83c1f69816cebcdaae3646e9ed7920c895550ee91a6485cc7a9ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/70/6a/1c79e59951a41b4045497da187b2724f5659ca64033cf4548e\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10188 sha256=5ab871904dbc1bb3814123484dcead5c63ff0dab20ada2a9cca2255d3c39d13f\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-py3-none-any.whl size=25030 sha256=0a8424fb2c002729889dac906902be319b92a1e592a63fdd7afa8ff57ce7d240\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/b7/d0/a121106e61339eee5ed083bc230b1c8dc422c49a5a28c2addd\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-py3-none-any.whl size=14392 sha256=e398249bafc454065cd0e6673f260af1498c19d6df6040dbbe46e1544e128a21\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/94/06/18c0e83e9e227da8f3582810b51f319bbfd181e508676a56c8\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41934 sha256=8fa4f90a61f1825db3c1be3ef741bad9ccd409eaf835141e57d6129ffd2c4fd5\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993241 sha256=6eaf7066bed393f5bf662555ccbd31310ee8d97607e9e19a8898877f4ff85a50\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "Successfully built gdown mpld3 overrides segtok sqlitedict ftfy langdetect\n",
            "Installing collected packages: requests, importlib-metadata, tokenizers, sentencepiece, sacremoses, pyyaml, overrides, huggingface-hub, transformers, torch, sqlitedict, segtok, mpld3, langdetect, konoha, janome, gdown, ftfy, deprecated, bpemb, flair\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.6.1\n",
            "    Uninstalling importlib-metadata-4.6.1:\n",
            "      Successfully uninstalled importlib-metadata-4.6.1\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 3.6.4\n",
            "    Uninstalling gdown-3.6.4:\n",
            "      Successfully uninstalled gdown-3.6.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.10.0+cu102 requires torch==1.9.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.7.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed bpemb-0.3.3 deprecated-1.2.12 flair-0.8.0.post1 ftfy-6.0.3 gdown-3.12.2 huggingface-hub-0.0.12 importlib-metadata-3.10.1 janome-0.4.1 konoha-4.6.5 langdetect-1.0.9 mpld3-0.3 overrides-3.1.0 pyyaml-5.4.1 requests-2.26.0 sacremoses-0.0.45 segtok-1.5.10 sentencepiece-0.1.95 sqlitedict-1.7.0 tokenizers-0.10.3 torch-1.7.1 transformers-4.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ely9fyfjmHv8"
      },
      "source": [
        "Our aim to successfully train a custom NER/Sequence Tagging model. We are going to use Flair library (Link: https://github.com/flairNLP/flair), which is a powerful framework for Natural language processing build using PyTorch and even provides its own flair embeddings, assistance in number of NLP tasks like POS tagging, Named entity recognization, text classification. It even includes embeddings trained using powerful models like BERT and ELMO."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRsLV5D6nDB8"
      },
      "source": [
        "## Simple NER task performed using Flair"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237,
          "referenced_widgets": [
            "887a0d9d333142cab55f8f9c9860a667",
            "1740a327c1a74d21948ed31a84c78ec9",
            "d355415d4593452abb8434644067cad9",
            "25aead8666074ca09c7950a84a695862",
            "ef5ff10a40a0464290160624dcac597d",
            "ddaf5e96e0224044b9c9a7352bb1b644",
            "bcb749e699504a4e8098a84184c85b64",
            "8e85d052b1334c64a69fe5c3be84891f"
          ]
        },
        "id": "XH1CBYD1mHVU",
        "outputId": "027d15a4-9448-404d-82cd-9e8a65e100e3"
      },
      "source": [
        "from flair.data import Sentence                               # The sentence objects holds a sentence that we may want to embed or tag\n",
        "from flair.models import SequenceTagger\n",
        "\n",
        "tagger = SequenceTagger.load('ner')                           # Pre-trained Sequence tagger of Flair\n",
        "sentence = Sentence('George Washington went to Washington .') # Sentence holds a textual sentence and is essentially a list of Token\n",
        "tagger.predict(sentence)\n",
        "print(sentence.to_tagged_string())\n",
        "\n",
        "for entity in sentence.get_spans('ner'):\n",
        "  print(entity)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-10 19:52:07,850 --------------------------------------------------------------------------------\n",
            "2021-08-10 19:52:07,851 The model key 'ner' now maps to 'https://huggingface.co/flair/ner-english' on the HuggingFace ModelHub\n",
            "2021-08-10 19:52:07,852  - The most current version of the model is automatically downloaded from there.\n",
            "2021-08-10 19:52:07,854  - (you can alternatively manually download the original model at https://nlp.informatik.hu-berlin.de/resources/models/ner/en-ner-conll03-v0.4.pt)\n",
            "2021-08-10 19:52:07,855 --------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "887a0d9d333142cab55f8f9c9860a667",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=432176557.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "2021-08-10 19:55:33,493 loading file /root/.flair/models/ner-english/4f4cdab26f24cb98b732b389e6cebc646c36f54cfd6e0b7d3b90b25656e4262f.8baa8ae8795f4df80b28e7f7b61d788ecbb057d1dc85aacb316f1bd02837a4a4\n",
            "George <B-PER> Washington <E-PER> went to Washington <S-LOC> .\n",
            "Span [1,2]: \"George Washington\"   [− Labels: PER (0.9989)]\n",
            "Span [5]: \"Washington\"   [− Labels: LOC (0.9942)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7OEGY8ooVIj",
        "outputId": "22f883fc-27e6-455f-9be5-489290ace23b"
      },
      "source": [
        "print(sentence.to_dict(tag_type='ner')) # confidence score of each predicted state"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': 'George Washington went to Washington .', 'labels': [], 'entities': [{'text': 'George Washington', 'start_pos': 0, 'end_pos': 17, 'labels': [PER (0.9989)]}, {'text': 'Washington', 'start_pos': 26, 'end_pos': 36, 'labels': [LOC (0.9942)]}]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA35Oi9uok4z"
      },
      "source": [
        "## Learning on custom entities/ Sequence Tagging\n",
        "The task described in the given problem is generally defined as sequence tagging or sequence labelling in the literature. \n",
        "\n",
        "According to Wikipedia: In machine learning, sequence labeling is a type of pattern recognition task that involves the algorithmic assignment of a categorical label to each member of a sequence of observed values. A common example of a sequence labeling task is part of speech tagging, which seeks to assign a part of speech to each word in an input sentence or document. (Reference : https://en.wikipedia.org/wiki/Sequence_labeling)\n",
        "\n",
        "Chapter 9 of Book by Dan Jurafsky and James H. Martin, Speech and Language Processing goes in great depth by presenting deep learning models for sequence processing. (Reference: https://web.stanford.edu/~jurafsky/slp3/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-xTJkbLr3oD"
      },
      "source": [
        "#### Importing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox6sEOHaouG7",
        "outputId": "0e83d5e5-11ca-415b-ef96-678342cc8a77"
      },
      "source": [
        "from flair.data import Corpus # Corpus represents a dataset that you use to train a model. It consists of a list of train sentences, a list of dev sentences, and a list of test sentences, which correspond to the training, validation and testing split during model training\n",
        "from flair.datasets import ColumnCorpus # To read a dataset, column structure as a dictionary and instantiate a ColumnCorpus\n",
        "\n",
        "# define columns, our data is in a format where first column is tag and second is word\n",
        "columns = {0:'ner',1:'text'}\n",
        "data_folder = './'\n",
        "# init a corpus using column format, data folder and the names of the train and test files\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='trivia10k13train.txt',\n",
        "                              test_file='trivia10k13test.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-10 20:07:06,416 Reading data from .\n",
            "2021-08-10 20:07:06,417 Train: trivia10k13train.txt\n",
            "2021-08-10 20:07:06,418 Dev: None\n",
            "2021-08-10 20:07:06,419 Test: trivia10k13test.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ze3bXbensIDj"
      },
      "source": [
        "Note : the Column Corpus reads the data, in following format\n",
        "* Sentences in the corpus are separated by an empty line\n",
        "* Each row have two columns, the word and the tag that needs to be learned.\n",
        "\n",
        "Our input data was in desired format so no data preprocessing was required in this case. Otherwise an additional step of preprocessing for converting data in format that ColumnCorpus accepts would be necessary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AVASf7grxkz"
      },
      "source": [
        "#### Train/Test set size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGm0yw3uq0Kj",
        "outputId": "891529c2-7764-4fad-dbeb-999ab784f236"
      },
      "source": [
        "print(\"Length of Training set: \",len(corpus.train)) # Number of example in training set\n",
        "print(\"Length of Test set: \",len(corpus.test))      # Number of example in test set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Training set:  7034\n",
            "Length of Test set:  1953\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8RsfFXArfSr"
      },
      "source": [
        "#### Displaying an example from train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVnr7r8trYma",
        "outputId": "58cce278-d09d-42f3-d283-c763e6ad4167"
      },
      "source": [
        "print(corpus.train[0].to_tagged_string('ner')) # Displaying first example from train set\n",
        "\"\"\"\n",
        "B-Actor\tsteve\n",
        "I-Actor\tmcqueen\n",
        "O\tprovided\n",
        "O\ta\n",
        "B-Plot\tthrilling\n",
        "I-Plot\tmotorcycle\n",
        "I-Plot\tchase\n",
        "I-Plot\tin\n",
        "I-Plot\tthis\n",
        "B-Opinion\tgreatest\n",
        "I-Opinion\tof\n",
        "I-Opinion\tall\n",
        "B-Plot\tww\n",
        "I-Plot\t2\n",
        "I-Plot\tprison\n",
        "I-Plot\tescape\n",
        "I-Plot\tmovies\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "steve <B-Actor> mcqueen <I-Actor> provided a thrilling <B-Plot> motorcycle <I-Plot> chase <I-Plot> in <I-Plot> this <I-Plot> greatest <B-Opinion> of <I-Opinion> all <I-Opinion> ww <B-Plot> 2 <I-Plot> prison <I-Plot> escape <I-Plot> movies <I-Plot>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfm6dTtLtDU0"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mbu3KnwrtDHT"
      },
      "source": [
        "tag_type = 'ner' # tag to predict, column (we are predicting column 'ner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-Y0Jn2Dr64S",
        "outputId": "e4598bd9-36d7-40db-ec51-58445929f327"
      },
      "source": [
        "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type) # create a tag dictionary from the corpus\n",
        "print(tag_dictionary) # classes of tags from which predictions will belong"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dictionary with 28 tags: <unk>, O, B-Actor, I-Actor, B-Plot, I-Plot, B-Opinion, I-Opinion, B-Genre, B-Origin, I-Origin, B-Year, B-Director, I-Genre, I-Director, I-Year, B-Soundtrack, I-Soundtrack, B-Award, I-Award, B-Relationship, I-Relationship, B-Character_Name, I-Character_Name, B-Quote, I-Quote, <START>, <STOP>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWygUzAjtuzT"
      },
      "source": [
        "#### Word Embeddings\n",
        "Flair provides a number of pre-trained model for embedding creation such as BERT, ELMO. (Reference : https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_3_WORD_EMBEDDING.md). We will be using glove embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gsvMBJNtr17",
        "outputId": "02077ee0-77a9-4240-da62-280915f9cd69"
      },
      "source": [
        "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings \n",
        "# StackedEmbeddings : combine different embeddings together, for instance if you want to use both traditional embeddings together with contextual string embeddings.\n",
        "from typing import List\n",
        "embedding_types : List[TokenEmbeddings] = [\n",
        "        WordEmbeddings('glove'), # GloVe embeddings are PyTorch vectors of dimensionality 100.\n",
        "        ## other embeddings\n",
        "        ]\n",
        "embeddings : StackedEmbeddings = StackedEmbeddings(\n",
        "                                 embeddings=embedding_types)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-10 20:22:38,408 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmpy1gs7eac\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 160000128/160000128 [00:16<00:00, 9462231.56B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-08-10 20:22:56,174 copying /tmp/tmpy1gs7eac to cache at /root/.flair/embeddings/glove.gensim.vectors.npy\n",
            "2021-08-10 20:22:56,319 removing temp file /tmp/tmpy1gs7eac\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-08-10 20:22:58,278 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim not found in cache, downloading to /tmp/tmp88oluhgd\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 21494764/21494764 [00:03<00:00, 5511226.81B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-08-10 20:23:03,596 copying /tmp/tmp88oluhgd to cache at /root/.flair/embeddings/glove.gensim\n",
            "2021-08-10 20:23:03,617 removing temp file /tmp/tmp88oluhgd\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYbP4bKHu_bb"
      },
      "source": [
        "#### Training a Sequence Tagger\n",
        "Sequence Tagger used here is a bi-directional LSTM (Reference : https://en.wikipedia.org/wiki/Bidirectional_recurrent_neural_networks) for better generalization and capturing of relationship and sequencing among different tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxKtMEFBu9SL",
        "outputId": "e7e6fb46-9998-4e92-d1ed-af1e7a8769b8"
      },
      "source": [
        "from flair.models import SequenceTagger # initialize sequence tagger\n",
        "\n",
        "# Sequence tagger model source code : https://github.com/flairNLP/flair/blob/master/flair/models/sequence_tagger_model.py\n",
        "tagger: SequenceTagger = SequenceTagger(hidden_size=256,                # number of hidden states in RNN\n",
        "                                        embeddings=embeddings,          # word embeddings used in tagger\n",
        "                                        tag_dictionary=tag_dictionary,  # dictionary of tags you want to predict\n",
        "                                        tag_type=tag_type,              # string identifier for tag type\n",
        "                                        use_crf=True)                   # if True use CRF decoder, else project directly to tag space\n",
        "print(tagger)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings('glove')\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (rnn): LSTM(100, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=28, bias=True)\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyul9ARLwVLr",
        "outputId": "272d31a6-48b2-42e3-aec7-a4eab63a3ff5"
      },
      "source": [
        "from flair.trainers import ModelTrainer # Initialize trainer\n",
        "\n",
        "# ModelTrainer source code : https://github.com/flairNLP/flair/blob/master/flair/trainers/trainer.py\n",
        "trainer: ModelTrainer = ModelTrainer(tagger, corpus) # corpus : The dataset used to train the model, should be of type Corpus and tagger : Sequence Tagger model\n",
        "# training process\n",
        "trainer.train('resources/taggers/example-pos',\n",
        "              learning_rate=0.1,                     # Initial learning rate\n",
        "              mini_batch_size=32,                    # Size of mini-batches during training\n",
        "              max_epochs=150)                        # Maximum number of epochs to train. Terminates training if this number is surpassed."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-10 20:32:23,013 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:32:23,015 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings('glove')\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (rnn): LSTM(100, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=28, bias=True)\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2021-08-10 20:32:23,016 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:32:23,019 Corpus: \"Corpus: 7034 train + 782 dev + 1953 test sentences\"\n",
            "2021-08-10 20:32:23,020 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:32:23,022 Parameters:\n",
            "2021-08-10 20:32:23,023  - learning_rate: \"0.1\"\n",
            "2021-08-10 20:32:23,025  - mini_batch_size: \"32\"\n",
            "2021-08-10 20:32:23,026  - patience: \"3\"\n",
            "2021-08-10 20:32:23,027  - anneal_factor: \"0.5\"\n",
            "2021-08-10 20:32:23,028  - max_epochs: \"150\"\n",
            "2021-08-10 20:32:23,030  - shuffle: \"True\"\n",
            "2021-08-10 20:32:23,031  - train_with_dev: \"False\"\n",
            "2021-08-10 20:32:23,033  - batch_growth_annealing: \"False\"\n",
            "2021-08-10 20:32:23,034 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:32:23,035 Model training base path: \"resources/taggers/example-pos\"\n",
            "2021-08-10 20:32:23,037 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:32:23,038 Device: cuda:0\n",
            "2021-08-10 20:32:23,039 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:32:23,041 Embeddings storage mode: cpu\n",
            "2021-08-10 20:32:23,042 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:32:25,687 epoch 1 - iter 22/220 - loss 44.05575249 - samples/sec: 266.54 - lr: 0.100000\n",
            "2021-08-10 20:32:28,097 epoch 1 - iter 44/220 - loss 38.41257321 - samples/sec: 292.41 - lr: 0.100000\n",
            "2021-08-10 20:32:30,646 epoch 1 - iter 66/220 - loss 35.33335986 - samples/sec: 276.39 - lr: 0.100000\n",
            "2021-08-10 20:32:33,302 epoch 1 - iter 88/220 - loss 33.88625689 - samples/sec: 265.35 - lr: 0.100000\n",
            "2021-08-10 20:32:35,634 epoch 1 - iter 110/220 - loss 32.19412046 - samples/sec: 302.11 - lr: 0.100000\n",
            "2021-08-10 20:32:37,992 epoch 1 - iter 132/220 - loss 29.84367338 - samples/sec: 298.90 - lr: 0.100000\n",
            "2021-08-10 20:32:40,408 epoch 1 - iter 154/220 - loss 28.03129522 - samples/sec: 291.71 - lr: 0.100000\n",
            "2021-08-10 20:32:43,106 epoch 1 - iter 176/220 - loss 26.69261109 - samples/sec: 261.18 - lr: 0.100000\n",
            "2021-08-10 20:32:46,377 epoch 1 - iter 198/220 - loss 25.55205928 - samples/sec: 215.38 - lr: 0.100000\n",
            "2021-08-10 20:32:48,782 epoch 1 - iter 220/220 - loss 24.51417724 - samples/sec: 292.97 - lr: 0.100000\n",
            "2021-08-10 20:32:48,783 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:32:48,784 EPOCH 1 done: loss 24.5142 - lr 0.1000000\n",
            "2021-08-10 20:32:50,426 DEV : loss 11.056137084960938 - score 0.4601\n",
            "2021-08-10 20:32:50,464 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 20:32:53,066 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:32:55,372 epoch 2 - iter 22/220 - loss 14.01291739 - samples/sec: 305.86 - lr: 0.100000\n",
            "2021-08-10 20:32:57,617 epoch 2 - iter 44/220 - loss 13.37011509 - samples/sec: 313.86 - lr: 0.100000\n",
            "2021-08-10 20:32:59,833 epoch 2 - iter 66/220 - loss 12.83642990 - samples/sec: 318.12 - lr: 0.100000\n",
            "2021-08-10 20:33:02,175 epoch 2 - iter 88/220 - loss 12.30954888 - samples/sec: 300.96 - lr: 0.100000\n",
            "2021-08-10 20:33:04,434 epoch 2 - iter 110/220 - loss 12.13307016 - samples/sec: 311.99 - lr: 0.100000\n",
            "2021-08-10 20:33:06,657 epoch 2 - iter 132/220 - loss 11.87728716 - samples/sec: 317.14 - lr: 0.100000\n",
            "2021-08-10 20:33:08,850 epoch 2 - iter 154/220 - loss 11.64182036 - samples/sec: 321.38 - lr: 0.100000\n",
            "2021-08-10 20:33:11,036 epoch 2 - iter 176/220 - loss 11.48279742 - samples/sec: 322.45 - lr: 0.100000\n",
            "2021-08-10 20:33:13,173 epoch 2 - iter 198/220 - loss 11.32827200 - samples/sec: 329.77 - lr: 0.100000\n",
            "2021-08-10 20:33:15,308 epoch 2 - iter 220/220 - loss 11.19698974 - samples/sec: 330.15 - lr: 0.100000\n",
            "2021-08-10 20:33:15,310 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:33:15,311 EPOCH 2 done: loss 11.1970 - lr 0.1000000\n",
            "2021-08-10 20:33:16,551 DEV : loss 6.994250297546387 - score 0.5715\n",
            "2021-08-10 20:33:16,590 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 20:33:18,974 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:33:21,334 epoch 3 - iter 22/220 - loss 9.18119296 - samples/sec: 298.94 - lr: 0.100000\n",
            "2021-08-10 20:33:23,530 epoch 3 - iter 44/220 - loss 9.14346253 - samples/sec: 321.02 - lr: 0.100000\n",
            "2021-08-10 20:33:25,746 epoch 3 - iter 66/220 - loss 9.07066373 - samples/sec: 318.02 - lr: 0.100000\n",
            "2021-08-10 20:33:27,949 epoch 3 - iter 88/220 - loss 8.92465243 - samples/sec: 320.00 - lr: 0.100000\n",
            "2021-08-10 20:33:30,202 epoch 3 - iter 110/220 - loss 8.82011647 - samples/sec: 312.88 - lr: 0.100000\n",
            "2021-08-10 20:33:32,374 epoch 3 - iter 132/220 - loss 8.85791940 - samples/sec: 324.41 - lr: 0.100000\n",
            "2021-08-10 20:33:34,564 epoch 3 - iter 154/220 - loss 8.70835305 - samples/sec: 321.98 - lr: 0.100000\n",
            "2021-08-10 20:33:36,788 epoch 3 - iter 176/220 - loss 8.68382586 - samples/sec: 316.92 - lr: 0.100000\n",
            "2021-08-10 20:33:38,995 epoch 3 - iter 198/220 - loss 8.61966577 - samples/sec: 319.30 - lr: 0.100000\n",
            "2021-08-10 20:33:41,153 epoch 3 - iter 220/220 - loss 8.51277856 - samples/sec: 326.71 - lr: 0.100000\n",
            "2021-08-10 20:33:41,154 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:33:41,155 EPOCH 3 done: loss 8.5128 - lr 0.1000000\n",
            "2021-08-10 20:33:42,399 DEV : loss 6.255899429321289 - score 0.5663\n",
            "2021-08-10 20:33:42,438 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 20:33:42,440 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:33:44,627 epoch 4 - iter 22/220 - loss 7.69009933 - samples/sec: 322.29 - lr: 0.100000\n",
            "2021-08-10 20:33:46,789 epoch 4 - iter 44/220 - loss 8.00452355 - samples/sec: 326.09 - lr: 0.100000\n",
            "2021-08-10 20:33:49,001 epoch 4 - iter 66/220 - loss 7.89205917 - samples/sec: 318.59 - lr: 0.100000\n",
            "2021-08-10 20:33:51,247 epoch 4 - iter 88/220 - loss 7.79711073 - samples/sec: 313.88 - lr: 0.100000\n",
            "2021-08-10 20:33:53,432 epoch 4 - iter 110/220 - loss 7.71082184 - samples/sec: 322.65 - lr: 0.100000\n",
            "2021-08-10 20:33:55,728 epoch 4 - iter 132/220 - loss 7.68740278 - samples/sec: 306.94 - lr: 0.100000\n",
            "2021-08-10 20:33:57,943 epoch 4 - iter 154/220 - loss 7.63917574 - samples/sec: 318.29 - lr: 0.100000\n",
            "2021-08-10 20:34:00,174 epoch 4 - iter 176/220 - loss 7.59963559 - samples/sec: 315.95 - lr: 0.100000\n",
            "2021-08-10 20:34:02,381 epoch 4 - iter 198/220 - loss 7.55778991 - samples/sec: 319.43 - lr: 0.100000\n",
            "2021-08-10 20:34:04,643 epoch 4 - iter 220/220 - loss 7.49940011 - samples/sec: 311.63 - lr: 0.100000\n",
            "2021-08-10 20:34:04,644 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:34:04,646 EPOCH 4 done: loss 7.4994 - lr 0.1000000\n",
            "2021-08-10 20:34:05,913 DEV : loss 5.731180191040039 - score 0.6099\n",
            "2021-08-10 20:34:05,950 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 20:34:08,349 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:34:10,534 epoch 5 - iter 22/220 - loss 7.18548491 - samples/sec: 322.84 - lr: 0.100000\n",
            "2021-08-10 20:34:12,653 epoch 5 - iter 44/220 - loss 7.07697520 - samples/sec: 332.75 - lr: 0.100000\n",
            "2021-08-10 20:34:14,883 epoch 5 - iter 66/220 - loss 7.10400810 - samples/sec: 315.97 - lr: 0.100000\n",
            "2021-08-10 20:34:17,082 epoch 5 - iter 88/220 - loss 7.03844320 - samples/sec: 320.53 - lr: 0.100000\n",
            "2021-08-10 20:34:19,449 epoch 5 - iter 110/220 - loss 7.10796838 - samples/sec: 297.80 - lr: 0.100000\n",
            "2021-08-10 20:34:21,748 epoch 5 - iter 132/220 - loss 7.06763674 - samples/sec: 306.60 - lr: 0.100000\n",
            "2021-08-10 20:34:23,889 epoch 5 - iter 154/220 - loss 6.97836678 - samples/sec: 329.14 - lr: 0.100000\n",
            "2021-08-10 20:34:26,108 epoch 5 - iter 176/220 - loss 6.93237993 - samples/sec: 317.62 - lr: 0.100000\n",
            "2021-08-10 20:34:28,244 epoch 5 - iter 198/220 - loss 6.90769743 - samples/sec: 330.05 - lr: 0.100000\n",
            "2021-08-10 20:34:30,454 epoch 5 - iter 220/220 - loss 6.86095903 - samples/sec: 318.90 - lr: 0.100000\n",
            "2021-08-10 20:34:30,455 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:34:30,457 EPOCH 5 done: loss 6.8610 - lr 0.1000000\n",
            "2021-08-10 20:34:31,732 DEV : loss 4.86782169342041 - score 0.6447\n",
            "2021-08-10 20:34:31,773 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 20:34:34,177 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:34:36,472 epoch 6 - iter 22/220 - loss 6.50713795 - samples/sec: 307.34 - lr: 0.100000\n",
            "2021-08-10 20:34:38,751 epoch 6 - iter 44/220 - loss 6.72958754 - samples/sec: 309.30 - lr: 0.100000\n",
            "2021-08-10 20:34:41,044 epoch 6 - iter 66/220 - loss 6.59841938 - samples/sec: 307.38 - lr: 0.100000\n",
            "2021-08-10 20:34:43,141 epoch 6 - iter 88/220 - loss 6.62391596 - samples/sec: 336.09 - lr: 0.100000\n",
            "2021-08-10 20:34:45,324 epoch 6 - iter 110/220 - loss 6.60416951 - samples/sec: 322.94 - lr: 0.100000\n",
            "2021-08-10 20:34:47,575 epoch 6 - iter 132/220 - loss 6.53321679 - samples/sec: 313.13 - lr: 0.100000\n",
            "2021-08-10 20:34:49,792 epoch 6 - iter 154/220 - loss 6.55533744 - samples/sec: 317.91 - lr: 0.100000\n",
            "2021-08-10 20:34:51,901 epoch 6 - iter 176/220 - loss 6.54458536 - samples/sec: 334.22 - lr: 0.100000\n",
            "2021-08-10 20:34:54,151 epoch 6 - iter 198/220 - loss 6.48823050 - samples/sec: 313.26 - lr: 0.100000\n",
            "2021-08-10 20:34:56,365 epoch 6 - iter 220/220 - loss 6.43930427 - samples/sec: 318.43 - lr: 0.100000\n",
            "2021-08-10 20:34:56,366 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:34:56,367 EPOCH 6 done: loss 6.4393 - lr 0.1000000\n",
            "2021-08-10 20:34:57,621 DEV : loss 4.831173419952393 - score 0.6527\n",
            "2021-08-10 20:34:57,659 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 20:35:00,051 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:35:02,249 epoch 7 - iter 22/220 - loss 6.04630834 - samples/sec: 320.91 - lr: 0.100000\n",
            "2021-08-10 20:35:04,494 epoch 7 - iter 44/220 - loss 6.18621578 - samples/sec: 314.21 - lr: 0.100000\n",
            "2021-08-10 20:35:06,744 epoch 7 - iter 66/220 - loss 6.16853510 - samples/sec: 313.20 - lr: 0.100000\n",
            "2021-08-10 20:35:08,985 epoch 7 - iter 88/220 - loss 6.24075779 - samples/sec: 314.48 - lr: 0.100000\n",
            "2021-08-10 20:35:11,233 epoch 7 - iter 110/220 - loss 6.23086332 - samples/sec: 313.62 - lr: 0.100000\n",
            "2021-08-10 20:35:13,398 epoch 7 - iter 132/220 - loss 6.16231341 - samples/sec: 325.49 - lr: 0.100000\n",
            "2021-08-10 20:35:15,611 epoch 7 - iter 154/220 - loss 6.14265524 - samples/sec: 318.54 - lr: 0.100000\n",
            "2021-08-10 20:35:17,763 epoch 7 - iter 176/220 - loss 6.13082410 - samples/sec: 327.55 - lr: 0.100000\n",
            "2021-08-10 20:35:20,080 epoch 7 - iter 198/220 - loss 6.10280551 - samples/sec: 304.21 - lr: 0.100000\n",
            "2021-08-10 20:35:22,300 epoch 7 - iter 220/220 - loss 6.11960090 - samples/sec: 317.50 - lr: 0.100000\n",
            "2021-08-10 20:35:22,301 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:35:22,303 EPOCH 7 done: loss 6.1196 - lr 0.1000000\n",
            "2021-08-10 20:35:23,554 DEV : loss 4.531966686248779 - score 0.6645\n",
            "2021-08-10 20:35:23,592 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 20:35:25,978 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:35:28,188 epoch 8 - iter 22/220 - loss 6.14814146 - samples/sec: 319.06 - lr: 0.100000\n",
            "2021-08-10 20:35:30,494 epoch 8 - iter 44/220 - loss 5.84368014 - samples/sec: 305.65 - lr: 0.100000\n",
            "2021-08-10 20:35:32,811 epoch 8 - iter 66/220 - loss 5.87132083 - samples/sec: 304.28 - lr: 0.100000\n",
            "2021-08-10 20:35:35,076 epoch 8 - iter 88/220 - loss 5.90111648 - samples/sec: 311.14 - lr: 0.100000\n",
            "2021-08-10 20:35:37,302 epoch 8 - iter 110/220 - loss 5.88998071 - samples/sec: 316.74 - lr: 0.100000\n",
            "2021-08-10 20:35:39,444 epoch 8 - iter 132/220 - loss 5.89441022 - samples/sec: 328.98 - lr: 0.100000\n",
            "2021-08-10 20:35:41,721 epoch 8 - iter 154/220 - loss 5.93660190 - samples/sec: 309.58 - lr: 0.100000\n",
            "2021-08-10 20:35:43,976 epoch 8 - iter 176/220 - loss 5.88742091 - samples/sec: 312.63 - lr: 0.100000\n",
            "2021-08-10 20:35:46,248 epoch 8 - iter 198/220 - loss 5.88752694 - samples/sec: 310.18 - lr: 0.100000\n",
            "2021-08-10 20:35:48,467 epoch 8 - iter 220/220 - loss 5.87156865 - samples/sec: 317.62 - lr: 0.100000\n",
            "2021-08-10 20:35:48,469 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:35:48,470 EPOCH 8 done: loss 5.8716 - lr 0.1000000\n",
            "2021-08-10 20:35:49,739 DEV : loss 4.474660396575928 - score 0.6568\n",
            "2021-08-10 20:35:49,777 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 20:35:49,778 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:35:51,994 epoch 9 - iter 22/220 - loss 5.76458701 - samples/sec: 318.27 - lr: 0.100000\n",
            "2021-08-10 20:35:54,272 epoch 9 - iter 44/220 - loss 5.70598137 - samples/sec: 309.39 - lr: 0.100000\n",
            "2021-08-10 20:35:56,440 epoch 9 - iter 66/220 - loss 5.62555889 - samples/sec: 325.15 - lr: 0.100000\n",
            "2021-08-10 20:35:58,687 epoch 9 - iter 88/220 - loss 5.59960963 - samples/sec: 313.67 - lr: 0.100000\n",
            "2021-08-10 20:36:00,816 epoch 9 - iter 110/220 - loss 5.62242778 - samples/sec: 331.19 - lr: 0.100000\n",
            "2021-08-10 20:36:03,041 epoch 9 - iter 132/220 - loss 5.61466644 - samples/sec: 316.78 - lr: 0.100000\n",
            "2021-08-10 20:36:05,223 epoch 9 - iter 154/220 - loss 5.57978873 - samples/sec: 322.96 - lr: 0.100000\n",
            "2021-08-10 20:36:07,326 epoch 9 - iter 176/220 - loss 5.59653095 - samples/sec: 335.19 - lr: 0.100000\n",
            "2021-08-10 20:36:09,609 epoch 9 - iter 198/220 - loss 5.58039355 - samples/sec: 308.81 - lr: 0.100000\n",
            "2021-08-10 20:36:11,776 epoch 9 - iter 220/220 - loss 5.61037397 - samples/sec: 325.19 - lr: 0.100000\n",
            "2021-08-10 20:36:11,778 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:36:11,779 EPOCH 9 done: loss 5.6104 - lr 0.1000000\n",
            "2021-08-10 20:36:13,042 DEV : loss 4.210536956787109 - score 0.6589\n",
            "2021-08-10 20:36:13,079 BAD EPOCHS (no improvement): 2\n",
            "2021-08-10 20:36:13,081 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:36:15,246 epoch 10 - iter 22/220 - loss 5.54828269 - samples/sec: 325.64 - lr: 0.100000\n",
            "2021-08-10 20:36:17,363 epoch 10 - iter 44/220 - loss 5.42823014 - samples/sec: 333.06 - lr: 0.100000\n",
            "2021-08-10 20:36:19,541 epoch 10 - iter 66/220 - loss 5.44426402 - samples/sec: 323.63 - lr: 0.100000\n",
            "2021-08-10 20:36:21,884 epoch 10 - iter 88/220 - loss 5.46982906 - samples/sec: 300.91 - lr: 0.100000\n",
            "2021-08-10 20:36:24,327 epoch 10 - iter 110/220 - loss 5.50588938 - samples/sec: 288.57 - lr: 0.100000\n",
            "2021-08-10 20:36:26,527 epoch 10 - iter 132/220 - loss 5.52533624 - samples/sec: 320.29 - lr: 0.100000\n",
            "2021-08-10 20:36:28,739 epoch 10 - iter 154/220 - loss 5.55925538 - samples/sec: 318.65 - lr: 0.100000\n",
            "2021-08-10 20:36:30,890 epoch 10 - iter 176/220 - loss 5.52973633 - samples/sec: 327.66 - lr: 0.100000\n",
            "2021-08-10 20:36:33,032 epoch 10 - iter 198/220 - loss 5.53038289 - samples/sec: 329.20 - lr: 0.100000\n",
            "2021-08-10 20:36:35,157 epoch 10 - iter 220/220 - loss 5.53974023 - samples/sec: 331.84 - lr: 0.100000\n",
            "2021-08-10 20:36:35,158 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:36:35,160 EPOCH 10 done: loss 5.5397 - lr 0.1000000\n",
            "2021-08-10 20:36:37,199 DEV : loss 4.048767566680908 - score 0.6714\n",
            "2021-08-10 20:36:37,235 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 20:36:39,608 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:36:41,832 epoch 11 - iter 22/220 - loss 5.56400878 - samples/sec: 317.19 - lr: 0.100000\n",
            "2021-08-10 20:36:44,007 epoch 11 - iter 44/220 - loss 5.37252187 - samples/sec: 324.09 - lr: 0.100000\n",
            "2021-08-10 20:36:46,332 epoch 11 - iter 66/220 - loss 5.39874469 - samples/sec: 303.11 - lr: 0.100000\n",
            "2021-08-10 20:36:48,541 epoch 11 - iter 88/220 - loss 5.38047591 - samples/sec: 319.22 - lr: 0.100000\n",
            "2021-08-10 20:36:50,717 epoch 11 - iter 110/220 - loss 5.36893348 - samples/sec: 323.90 - lr: 0.100000\n",
            "2021-08-10 20:36:52,895 epoch 11 - iter 132/220 - loss 5.36470152 - samples/sec: 323.55 - lr: 0.100000\n",
            "2021-08-10 20:36:55,102 epoch 11 - iter 154/220 - loss 5.39949024 - samples/sec: 319.48 - lr: 0.100000\n",
            "2021-08-10 20:36:57,339 epoch 11 - iter 176/220 - loss 5.38966092 - samples/sec: 315.00 - lr: 0.100000\n",
            "2021-08-10 20:36:59,510 epoch 11 - iter 198/220 - loss 5.36905588 - samples/sec: 324.64 - lr: 0.100000\n",
            "2021-08-10 20:37:01,680 epoch 11 - iter 220/220 - loss 5.35204812 - samples/sec: 324.95 - lr: 0.100000\n",
            "2021-08-10 20:37:01,681 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:37:01,682 EPOCH 11 done: loss 5.3520 - lr 0.1000000\n",
            "2021-08-10 20:37:02,926 DEV : loss 3.975076913833618 - score 0.6728\n",
            "2021-08-10 20:37:02,964 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 20:37:05,364 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:37:07,526 epoch 12 - iter 22/220 - loss 5.43786008 - samples/sec: 326.38 - lr: 0.100000\n",
            "2021-08-10 20:37:09,778 epoch 12 - iter 44/220 - loss 5.26330958 - samples/sec: 312.99 - lr: 0.100000\n",
            "2021-08-10 20:37:12,045 epoch 12 - iter 66/220 - loss 5.24170205 - samples/sec: 310.87 - lr: 0.100000\n",
            "2021-08-10 20:37:14,298 epoch 12 - iter 88/220 - loss 5.33676490 - samples/sec: 312.87 - lr: 0.100000\n",
            "2021-08-10 20:37:16,552 epoch 12 - iter 110/220 - loss 5.33779796 - samples/sec: 312.68 - lr: 0.100000\n",
            "2021-08-10 20:37:18,912 epoch 12 - iter 132/220 - loss 5.29826874 - samples/sec: 298.58 - lr: 0.100000\n",
            "2021-08-10 20:37:21,150 epoch 12 - iter 154/220 - loss 5.24761792 - samples/sec: 315.00 - lr: 0.100000\n",
            "2021-08-10 20:37:23,371 epoch 12 - iter 176/220 - loss 5.23450451 - samples/sec: 317.30 - lr: 0.100000\n",
            "2021-08-10 20:37:25,624 epoch 12 - iter 198/220 - loss 5.27977078 - samples/sec: 312.92 - lr: 0.100000\n",
            "2021-08-10 20:37:27,849 epoch 12 - iter 220/220 - loss 5.27900123 - samples/sec: 316.86 - lr: 0.100000\n",
            "2021-08-10 20:37:27,850 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:37:27,851 EPOCH 12 done: loss 5.2790 - lr 0.1000000\n",
            "2021-08-10 20:37:29,116 DEV : loss 4.236865997314453 - score 0.6647\n",
            "2021-08-10 20:37:29,154 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 20:37:29,156 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:37:31,351 epoch 13 - iter 22/220 - loss 5.04648624 - samples/sec: 321.26 - lr: 0.100000\n",
            "2021-08-10 20:37:33,517 epoch 13 - iter 44/220 - loss 4.89888718 - samples/sec: 325.41 - lr: 0.100000\n",
            "2021-08-10 20:37:35,684 epoch 13 - iter 66/220 - loss 4.92280251 - samples/sec: 325.40 - lr: 0.100000\n",
            "2021-08-10 20:37:37,864 epoch 13 - iter 88/220 - loss 4.99211288 - samples/sec: 323.32 - lr: 0.100000\n",
            "2021-08-10 20:37:40,066 epoch 13 - iter 110/220 - loss 5.01754868 - samples/sec: 319.99 - lr: 0.100000\n",
            "2021-08-10 20:37:42,206 epoch 13 - iter 132/220 - loss 5.00486447 - samples/sec: 329.42 - lr: 0.100000\n",
            "2021-08-10 20:37:44,392 epoch 13 - iter 154/220 - loss 5.08886695 - samples/sec: 322.43 - lr: 0.100000\n",
            "2021-08-10 20:37:46,610 epoch 13 - iter 176/220 - loss 5.11770394 - samples/sec: 317.74 - lr: 0.100000\n",
            "2021-08-10 20:37:48,810 epoch 13 - iter 198/220 - loss 5.13360888 - samples/sec: 320.39 - lr: 0.100000\n",
            "2021-08-10 20:37:50,968 epoch 13 - iter 220/220 - loss 5.15591678 - samples/sec: 326.70 - lr: 0.100000\n",
            "2021-08-10 20:37:50,969 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:37:50,970 EPOCH 13 done: loss 5.1559 - lr 0.1000000\n",
            "2021-08-10 20:37:52,221 DEV : loss 3.994971752166748 - score 0.6889\n",
            "2021-08-10 20:37:52,258 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 20:37:54,691 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:37:56,915 epoch 14 - iter 22/220 - loss 4.97250096 - samples/sec: 317.09 - lr: 0.100000\n",
            "2021-08-10 20:37:59,194 epoch 14 - iter 44/220 - loss 5.00211977 - samples/sec: 309.34 - lr: 0.100000\n",
            "2021-08-10 20:38:01,431 epoch 14 - iter 66/220 - loss 5.10783436 - samples/sec: 315.03 - lr: 0.100000\n",
            "2021-08-10 20:38:03,635 epoch 14 - iter 88/220 - loss 5.03855847 - samples/sec: 319.86 - lr: 0.100000\n",
            "2021-08-10 20:38:05,808 epoch 14 - iter 110/220 - loss 5.04471449 - samples/sec: 324.32 - lr: 0.100000\n",
            "2021-08-10 20:38:08,055 epoch 14 - iter 132/220 - loss 5.05758348 - samples/sec: 313.71 - lr: 0.100000\n",
            "2021-08-10 20:38:10,194 epoch 14 - iter 154/220 - loss 5.06836701 - samples/sec: 329.49 - lr: 0.100000\n",
            "2021-08-10 20:38:12,424 epoch 14 - iter 176/220 - loss 5.07877274 - samples/sec: 316.05 - lr: 0.100000\n",
            "2021-08-10 20:38:14,563 epoch 14 - iter 198/220 - loss 5.05333509 - samples/sec: 329.51 - lr: 0.100000\n",
            "2021-08-10 20:38:16,770 epoch 14 - iter 220/220 - loss 5.05362133 - samples/sec: 319.44 - lr: 0.100000\n",
            "2021-08-10 20:38:16,771 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:38:16,773 EPOCH 14 done: loss 5.0536 - lr 0.1000000\n",
            "2021-08-10 20:38:18,038 DEV : loss 3.789268732070923 - score 0.6873\n",
            "2021-08-10 20:38:18,078 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 20:38:18,080 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:38:20,259 epoch 15 - iter 22/220 - loss 5.31088527 - samples/sec: 323.57 - lr: 0.100000\n",
            "2021-08-10 20:38:22,428 epoch 15 - iter 44/220 - loss 5.08251270 - samples/sec: 324.97 - lr: 0.100000\n",
            "2021-08-10 20:38:24,612 epoch 15 - iter 66/220 - loss 4.97558837 - samples/sec: 322.76 - lr: 0.100000\n",
            "2021-08-10 20:38:26,852 epoch 15 - iter 88/220 - loss 4.98809675 - samples/sec: 314.65 - lr: 0.100000\n",
            "2021-08-10 20:38:29,144 epoch 15 - iter 110/220 - loss 5.00359264 - samples/sec: 307.45 - lr: 0.100000\n",
            "2021-08-10 20:38:31,380 epoch 15 - iter 132/220 - loss 5.04758579 - samples/sec: 315.31 - lr: 0.100000\n",
            "2021-08-10 20:38:33,675 epoch 15 - iter 154/220 - loss 5.04218714 - samples/sec: 307.02 - lr: 0.100000\n",
            "2021-08-10 20:38:35,876 epoch 15 - iter 176/220 - loss 5.01906387 - samples/sec: 320.23 - lr: 0.100000\n",
            "2021-08-10 20:38:38,135 epoch 15 - iter 198/220 - loss 5.01066445 - samples/sec: 312.01 - lr: 0.100000\n",
            "2021-08-10 20:38:40,246 epoch 15 - iter 220/220 - loss 5.02466555 - samples/sec: 334.01 - lr: 0.100000\n",
            "2021-08-10 20:38:40,247 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:38:40,249 EPOCH 15 done: loss 5.0247 - lr 0.1000000\n",
            "2021-08-10 20:38:41,505 DEV : loss 3.8494579792022705 - score 0.6812\n",
            "2021-08-10 20:38:41,543 BAD EPOCHS (no improvement): 2\n",
            "2021-08-10 20:38:41,546 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:38:43,725 epoch 16 - iter 22/220 - loss 4.75176417 - samples/sec: 323.71 - lr: 0.100000\n",
            "2021-08-10 20:38:45,932 epoch 16 - iter 44/220 - loss 4.98368455 - samples/sec: 319.34 - lr: 0.100000\n",
            "2021-08-10 20:38:48,078 epoch 16 - iter 66/220 - loss 5.01578060 - samples/sec: 328.50 - lr: 0.100000\n",
            "2021-08-10 20:38:50,255 epoch 16 - iter 88/220 - loss 4.96355851 - samples/sec: 323.91 - lr: 0.100000\n",
            "2021-08-10 20:38:52,387 epoch 16 - iter 110/220 - loss 4.91455777 - samples/sec: 330.50 - lr: 0.100000\n",
            "2021-08-10 20:38:54,515 epoch 16 - iter 132/220 - loss 4.90410728 - samples/sec: 331.42 - lr: 0.100000\n",
            "2021-08-10 20:38:56,794 epoch 16 - iter 154/220 - loss 4.90599408 - samples/sec: 309.20 - lr: 0.100000\n",
            "2021-08-10 20:38:58,986 epoch 16 - iter 176/220 - loss 4.88470791 - samples/sec: 321.58 - lr: 0.100000\n",
            "2021-08-10 20:39:01,216 epoch 16 - iter 198/220 - loss 4.91990957 - samples/sec: 316.02 - lr: 0.100000\n",
            "2021-08-10 20:39:03,434 epoch 16 - iter 220/220 - loss 4.91898378 - samples/sec: 317.85 - lr: 0.100000\n",
            "2021-08-10 20:39:03,435 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:39:03,436 EPOCH 16 done: loss 4.9190 - lr 0.1000000\n",
            "2021-08-10 20:39:04,701 DEV : loss 3.8864622116088867 - score 0.685\n",
            "2021-08-10 20:39:04,738 BAD EPOCHS (no improvement): 3\n",
            "2021-08-10 20:39:04,739 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:39:06,988 epoch 17 - iter 22/220 - loss 5.19836188 - samples/sec: 313.84 - lr: 0.100000\n",
            "2021-08-10 20:39:09,240 epoch 17 - iter 44/220 - loss 4.96101107 - samples/sec: 312.91 - lr: 0.100000\n",
            "2021-08-10 20:39:11,405 epoch 17 - iter 66/220 - loss 4.87268813 - samples/sec: 325.64 - lr: 0.100000\n",
            "2021-08-10 20:39:13,627 epoch 17 - iter 88/220 - loss 4.92183151 - samples/sec: 317.20 - lr: 0.100000\n",
            "2021-08-10 20:39:15,808 epoch 17 - iter 110/220 - loss 4.94484051 - samples/sec: 323.19 - lr: 0.100000\n",
            "2021-08-10 20:39:17,948 epoch 17 - iter 132/220 - loss 4.91371397 - samples/sec: 329.26 - lr: 0.100000\n",
            "2021-08-10 20:39:20,272 epoch 17 - iter 154/220 - loss 4.90782539 - samples/sec: 303.37 - lr: 0.100000\n",
            "2021-08-10 20:39:22,424 epoch 17 - iter 176/220 - loss 4.88869057 - samples/sec: 327.52 - lr: 0.100000\n",
            "2021-08-10 20:39:24,608 epoch 17 - iter 198/220 - loss 4.87485263 - samples/sec: 322.66 - lr: 0.100000\n",
            "2021-08-10 20:39:26,719 epoch 17 - iter 220/220 - loss 4.84665320 - samples/sec: 333.96 - lr: 0.100000\n",
            "2021-08-10 20:39:26,720 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:39:26,721 EPOCH 17 done: loss 4.8467 - lr 0.1000000\n",
            "2021-08-10 20:39:27,972 DEV : loss 3.9349114894866943 - score 0.6811\n",
            "Epoch    17: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2021-08-10 20:39:28,011 BAD EPOCHS (no improvement): 4\n",
            "2021-08-10 20:39:28,013 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:39:30,219 epoch 18 - iter 22/220 - loss 4.66145674 - samples/sec: 319.69 - lr: 0.050000\n",
            "2021-08-10 20:39:32,474 epoch 18 - iter 44/220 - loss 4.68874832 - samples/sec: 312.51 - lr: 0.050000\n",
            "2021-08-10 20:39:34,850 epoch 18 - iter 66/220 - loss 4.69581907 - samples/sec: 296.63 - lr: 0.050000\n",
            "2021-08-10 20:39:37,071 epoch 18 - iter 88/220 - loss 4.74427154 - samples/sec: 317.32 - lr: 0.050000\n",
            "2021-08-10 20:39:39,295 epoch 18 - iter 110/220 - loss 4.75797117 - samples/sec: 317.03 - lr: 0.050000\n",
            "2021-08-10 20:39:41,557 epoch 18 - iter 132/220 - loss 4.71682370 - samples/sec: 311.47 - lr: 0.050000\n",
            "2021-08-10 20:39:43,800 epoch 18 - iter 154/220 - loss 4.66398639 - samples/sec: 314.30 - lr: 0.050000\n",
            "2021-08-10 20:39:45,923 epoch 18 - iter 176/220 - loss 4.63031171 - samples/sec: 331.98 - lr: 0.050000\n",
            "2021-08-10 20:39:48,013 epoch 18 - iter 198/220 - loss 4.59243794 - samples/sec: 337.31 - lr: 0.050000\n",
            "2021-08-10 20:39:50,172 epoch 18 - iter 220/220 - loss 4.56399215 - samples/sec: 326.49 - lr: 0.050000\n",
            "2021-08-10 20:39:50,173 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:39:50,174 EPOCH 18 done: loss 4.5640 - lr 0.0500000\n",
            "2021-08-10 20:39:51,434 DEV : loss 3.640432357788086 - score 0.6947\n",
            "2021-08-10 20:39:51,471 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 20:39:53,857 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:39:56,019 epoch 19 - iter 22/220 - loss 4.69697346 - samples/sec: 326.34 - lr: 0.050000\n",
            "2021-08-10 20:39:58,260 epoch 19 - iter 44/220 - loss 4.52091658 - samples/sec: 314.49 - lr: 0.050000\n",
            "2021-08-10 20:40:00,583 epoch 19 - iter 66/220 - loss 4.56301592 - samples/sec: 303.49 - lr: 0.050000\n",
            "2021-08-10 20:40:02,772 epoch 19 - iter 88/220 - loss 4.56123667 - samples/sec: 322.06 - lr: 0.050000\n",
            "2021-08-10 20:40:04,925 epoch 19 - iter 110/220 - loss 4.54201059 - samples/sec: 327.27 - lr: 0.050000\n",
            "2021-08-10 20:40:07,112 epoch 19 - iter 132/220 - loss 4.51157976 - samples/sec: 322.34 - lr: 0.050000\n",
            "2021-08-10 20:40:09,377 epoch 19 - iter 154/220 - loss 4.49985673 - samples/sec: 311.14 - lr: 0.050000\n",
            "2021-08-10 20:40:11,532 epoch 19 - iter 176/220 - loss 4.48115694 - samples/sec: 327.05 - lr: 0.050000\n",
            "2021-08-10 20:40:13,683 epoch 19 - iter 198/220 - loss 4.48102649 - samples/sec: 327.69 - lr: 0.050000\n",
            "2021-08-10 20:40:15,876 epoch 19 - iter 220/220 - loss 4.47521596 - samples/sec: 321.48 - lr: 0.050000\n",
            "2021-08-10 20:40:15,877 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:40:15,878 EPOCH 19 done: loss 4.4752 - lr 0.0500000\n",
            "2021-08-10 20:40:17,169 DEV : loss 3.753237009048462 - score 0.6967\n",
            "2021-08-10 20:40:17,206 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 20:40:19,592 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:40:21,921 epoch 20 - iter 22/220 - loss 4.40625180 - samples/sec: 302.80 - lr: 0.050000\n",
            "2021-08-10 20:40:24,160 epoch 20 - iter 44/220 - loss 4.56457197 - samples/sec: 314.86 - lr: 0.050000\n",
            "2021-08-10 20:40:26,360 epoch 20 - iter 66/220 - loss 4.47613001 - samples/sec: 320.44 - lr: 0.050000\n",
            "2021-08-10 20:40:28,486 epoch 20 - iter 88/220 - loss 4.37689371 - samples/sec: 331.43 - lr: 0.050000\n",
            "2021-08-10 20:40:30,676 epoch 20 - iter 110/220 - loss 4.37247473 - samples/sec: 321.84 - lr: 0.050000\n",
            "2021-08-10 20:40:32,799 epoch 20 - iter 132/220 - loss 4.41511043 - samples/sec: 332.19 - lr: 0.050000\n",
            "2021-08-10 20:40:35,004 epoch 20 - iter 154/220 - loss 4.41235345 - samples/sec: 319.60 - lr: 0.050000\n",
            "2021-08-10 20:40:37,273 epoch 20 - iter 176/220 - loss 4.44360227 - samples/sec: 310.57 - lr: 0.050000\n",
            "2021-08-10 20:40:39,480 epoch 20 - iter 198/220 - loss 4.44013555 - samples/sec: 319.45 - lr: 0.050000\n",
            "2021-08-10 20:40:41,668 epoch 20 - iter 220/220 - loss 4.43492957 - samples/sec: 322.11 - lr: 0.050000\n",
            "2021-08-10 20:40:41,669 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:40:41,670 EPOCH 20 done: loss 4.4349 - lr 0.0500000\n",
            "2021-08-10 20:40:42,941 DEV : loss 3.5540337562561035 - score 0.7052\n",
            "2021-08-10 20:40:42,980 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 20:40:45,381 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:40:47,608 epoch 21 - iter 22/220 - loss 4.13447300 - samples/sec: 316.86 - lr: 0.050000\n",
            "2021-08-10 20:40:49,779 epoch 21 - iter 44/220 - loss 4.23226127 - samples/sec: 324.57 - lr: 0.050000\n",
            "2021-08-10 20:40:51,950 epoch 21 - iter 66/220 - loss 4.24493383 - samples/sec: 324.71 - lr: 0.050000\n",
            "2021-08-10 20:40:54,169 epoch 21 - iter 88/220 - loss 4.32236521 - samples/sec: 317.73 - lr: 0.050000\n",
            "2021-08-10 20:40:56,392 epoch 21 - iter 110/220 - loss 4.35688687 - samples/sec: 317.06 - lr: 0.050000\n",
            "2021-08-10 20:40:58,525 epoch 21 - iter 132/220 - loss 4.35636827 - samples/sec: 330.40 - lr: 0.050000\n",
            "2021-08-10 20:41:00,798 epoch 21 - iter 154/220 - loss 4.38413336 - samples/sec: 310.15 - lr: 0.050000\n",
            "2021-08-10 20:41:02,977 epoch 21 - iter 176/220 - loss 4.38526439 - samples/sec: 323.50 - lr: 0.050000\n",
            "2021-08-10 20:41:05,267 epoch 21 - iter 198/220 - loss 4.38505570 - samples/sec: 307.71 - lr: 0.050000\n",
            "2021-08-10 20:41:07,490 epoch 21 - iter 220/220 - loss 4.39405392 - samples/sec: 317.01 - lr: 0.050000\n",
            "2021-08-10 20:41:07,492 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:41:07,493 EPOCH 21 done: loss 4.3941 - lr 0.0500000\n",
            "2021-08-10 20:41:08,766 DEV : loss 3.592362403869629 - score 0.6947\n",
            "2021-08-10 20:41:08,804 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 20:41:08,805 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:41:11,057 epoch 22 - iter 22/220 - loss 4.18635508 - samples/sec: 313.30 - lr: 0.050000\n",
            "2021-08-10 20:41:13,287 epoch 22 - iter 44/220 - loss 4.33921473 - samples/sec: 316.11 - lr: 0.050000\n",
            "2021-08-10 20:41:15,471 epoch 22 - iter 66/220 - loss 4.30562844 - samples/sec: 322.72 - lr: 0.050000\n",
            "2021-08-10 20:41:17,659 epoch 22 - iter 88/220 - loss 4.27219515 - samples/sec: 322.11 - lr: 0.050000\n",
            "2021-08-10 20:41:19,841 epoch 22 - iter 110/220 - loss 4.30423480 - samples/sec: 322.97 - lr: 0.050000\n",
            "2021-08-10 20:41:21,992 epoch 22 - iter 132/220 - loss 4.29498805 - samples/sec: 327.82 - lr: 0.050000\n",
            "2021-08-10 20:41:24,226 epoch 22 - iter 154/220 - loss 4.33320940 - samples/sec: 315.46 - lr: 0.050000\n",
            "2021-08-10 20:41:26,392 epoch 22 - iter 176/220 - loss 4.30643935 - samples/sec: 325.35 - lr: 0.050000\n",
            "2021-08-10 20:41:28,646 epoch 22 - iter 198/220 - loss 4.32905059 - samples/sec: 312.69 - lr: 0.050000\n",
            "2021-08-10 20:41:30,959 epoch 22 - iter 220/220 - loss 4.34233250 - samples/sec: 304.81 - lr: 0.050000\n",
            "2021-08-10 20:41:30,960 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:41:30,961 EPOCH 22 done: loss 4.3423 - lr 0.0500000\n",
            "2021-08-10 20:41:32,213 DEV : loss 3.474743604660034 - score 0.7083\n",
            "2021-08-10 20:41:32,251 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 20:41:34,633 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:41:36,855 epoch 23 - iter 22/220 - loss 4.02050745 - samples/sec: 317.40 - lr: 0.050000\n",
            "2021-08-10 20:41:39,056 epoch 23 - iter 44/220 - loss 4.23494124 - samples/sec: 320.30 - lr: 0.050000\n",
            "2021-08-10 20:41:41,296 epoch 23 - iter 66/220 - loss 4.15224136 - samples/sec: 314.59 - lr: 0.050000\n",
            "2021-08-10 20:41:43,513 epoch 23 - iter 88/220 - loss 4.20473204 - samples/sec: 317.87 - lr: 0.050000\n",
            "2021-08-10 20:41:45,850 epoch 23 - iter 110/220 - loss 4.25622144 - samples/sec: 301.69 - lr: 0.050000\n",
            "2021-08-10 20:41:47,979 epoch 23 - iter 132/220 - loss 4.26395291 - samples/sec: 330.97 - lr: 0.050000\n",
            "2021-08-10 20:41:50,119 epoch 23 - iter 154/220 - loss 4.29591593 - samples/sec: 329.50 - lr: 0.050000\n",
            "2021-08-10 20:41:52,396 epoch 23 - iter 176/220 - loss 4.27750969 - samples/sec: 309.44 - lr: 0.050000\n",
            "2021-08-10 20:41:54,544 epoch 23 - iter 198/220 - loss 4.30844830 - samples/sec: 328.27 - lr: 0.050000\n",
            "2021-08-10 20:41:56,684 epoch 23 - iter 220/220 - loss 4.31619521 - samples/sec: 329.58 - lr: 0.050000\n",
            "2021-08-10 20:41:56,685 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:41:56,686 EPOCH 23 done: loss 4.3162 - lr 0.0500000\n",
            "2021-08-10 20:41:58,726 DEV : loss 3.4817867279052734 - score 0.6958\n",
            "2021-08-10 20:41:58,766 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 20:41:58,768 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:42:00,907 epoch 24 - iter 22/220 - loss 4.21028414 - samples/sec: 329.62 - lr: 0.050000\n",
            "2021-08-10 20:42:03,104 epoch 24 - iter 44/220 - loss 4.27685715 - samples/sec: 320.88 - lr: 0.050000\n",
            "2021-08-10 20:42:05,216 epoch 24 - iter 66/220 - loss 4.32666779 - samples/sec: 333.69 - lr: 0.050000\n",
            "2021-08-10 20:42:07,383 epoch 24 - iter 88/220 - loss 4.36965914 - samples/sec: 325.22 - lr: 0.050000\n",
            "2021-08-10 20:42:09,608 epoch 24 - iter 110/220 - loss 4.32796413 - samples/sec: 316.87 - lr: 0.050000\n",
            "2021-08-10 20:42:11,814 epoch 24 - iter 132/220 - loss 4.33292941 - samples/sec: 319.43 - lr: 0.050000\n",
            "2021-08-10 20:42:13,924 epoch 24 - iter 154/220 - loss 4.35503474 - samples/sec: 334.05 - lr: 0.050000\n",
            "2021-08-10 20:42:16,229 epoch 24 - iter 176/220 - loss 4.34030962 - samples/sec: 305.86 - lr: 0.050000\n",
            "2021-08-10 20:42:18,525 epoch 24 - iter 198/220 - loss 4.33381737 - samples/sec: 307.00 - lr: 0.050000\n",
            "2021-08-10 20:42:20,874 epoch 24 - iter 220/220 - loss 4.33282679 - samples/sec: 300.07 - lr: 0.050000\n",
            "2021-08-10 20:42:20,876 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:42:20,878 EPOCH 24 done: loss 4.3328 - lr 0.0500000\n",
            "2021-08-10 20:42:22,169 DEV : loss 3.464876890182495 - score 0.7124\n",
            "2021-08-10 20:42:22,207 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 20:42:24,680 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:42:27,009 epoch 25 - iter 22/220 - loss 4.27950936 - samples/sec: 302.76 - lr: 0.050000\n",
            "2021-08-10 20:42:29,338 epoch 25 - iter 44/220 - loss 4.36654219 - samples/sec: 302.72 - lr: 0.050000\n",
            "2021-08-10 20:42:31,610 epoch 25 - iter 66/220 - loss 4.31297631 - samples/sec: 310.14 - lr: 0.050000\n",
            "2021-08-10 20:42:33,939 epoch 25 - iter 88/220 - loss 4.34857569 - samples/sec: 302.73 - lr: 0.050000\n",
            "2021-08-10 20:42:36,125 epoch 25 - iter 110/220 - loss 4.35370738 - samples/sec: 322.42 - lr: 0.050000\n",
            "2021-08-10 20:42:38,366 epoch 25 - iter 132/220 - loss 4.34121133 - samples/sec: 314.57 - lr: 0.050000\n",
            "2021-08-10 20:42:40,539 epoch 25 - iter 154/220 - loss 4.33015860 - samples/sec: 324.39 - lr: 0.050000\n",
            "2021-08-10 20:42:42,725 epoch 25 - iter 176/220 - loss 4.31790090 - samples/sec: 322.44 - lr: 0.050000\n",
            "2021-08-10 20:42:44,892 epoch 25 - iter 198/220 - loss 4.30271409 - samples/sec: 325.21 - lr: 0.050000\n",
            "2021-08-10 20:42:47,054 epoch 25 - iter 220/220 - loss 4.29256774 - samples/sec: 326.03 - lr: 0.050000\n",
            "2021-08-10 20:42:47,055 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:42:47,057 EPOCH 25 done: loss 4.2926 - lr 0.0500000\n",
            "2021-08-10 20:42:48,322 DEV : loss 3.5183303356170654 - score 0.6967\n",
            "2021-08-10 20:42:48,359 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 20:42:48,361 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:42:50,532 epoch 26 - iter 22/220 - loss 4.27193961 - samples/sec: 324.90 - lr: 0.050000\n",
            "2021-08-10 20:42:52,670 epoch 26 - iter 44/220 - loss 4.14499255 - samples/sec: 329.60 - lr: 0.050000\n",
            "2021-08-10 20:42:55,047 epoch 26 - iter 66/220 - loss 4.22666878 - samples/sec: 296.62 - lr: 0.050000\n",
            "2021-08-10 20:42:57,346 epoch 26 - iter 88/220 - loss 4.21413909 - samples/sec: 306.54 - lr: 0.050000\n",
            "2021-08-10 20:42:59,488 epoch 26 - iter 110/220 - loss 4.21365208 - samples/sec: 329.11 - lr: 0.050000\n",
            "2021-08-10 20:43:01,690 epoch 26 - iter 132/220 - loss 4.25560477 - samples/sec: 320.08 - lr: 0.050000\n",
            "2021-08-10 20:43:03,853 epoch 26 - iter 154/220 - loss 4.30151030 - samples/sec: 325.77 - lr: 0.050000\n",
            "2021-08-10 20:43:06,041 epoch 26 - iter 176/220 - loss 4.30015740 - samples/sec: 322.17 - lr: 0.050000\n",
            "2021-08-10 20:43:08,273 epoch 26 - iter 198/220 - loss 4.28001303 - samples/sec: 315.84 - lr: 0.050000\n",
            "2021-08-10 20:43:10,407 epoch 26 - iter 220/220 - loss 4.25237445 - samples/sec: 330.20 - lr: 0.050000\n",
            "2021-08-10 20:43:10,409 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:43:10,410 EPOCH 26 done: loss 4.2524 - lr 0.0500000\n",
            "2021-08-10 20:43:11,662 DEV : loss 3.506711721420288 - score 0.6979\n",
            "2021-08-10 20:43:11,700 BAD EPOCHS (no improvement): 2\n",
            "2021-08-10 20:43:11,702 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:43:13,894 epoch 27 - iter 22/220 - loss 4.06952285 - samples/sec: 321.70 - lr: 0.050000\n",
            "2021-08-10 20:43:16,044 epoch 27 - iter 44/220 - loss 4.21580637 - samples/sec: 327.84 - lr: 0.050000\n",
            "2021-08-10 20:43:18,229 epoch 27 - iter 66/220 - loss 4.17145651 - samples/sec: 322.65 - lr: 0.050000\n",
            "2021-08-10 20:43:20,524 epoch 27 - iter 88/220 - loss 4.16335073 - samples/sec: 307.12 - lr: 0.050000\n",
            "2021-08-10 20:43:22,745 epoch 27 - iter 110/220 - loss 4.18103826 - samples/sec: 317.31 - lr: 0.050000\n",
            "2021-08-10 20:43:25,102 epoch 27 - iter 132/220 - loss 4.26790261 - samples/sec: 299.03 - lr: 0.050000\n",
            "2021-08-10 20:43:27,238 epoch 27 - iter 154/220 - loss 4.23382942 - samples/sec: 329.91 - lr: 0.050000\n",
            "2021-08-10 20:43:29,448 epoch 27 - iter 176/220 - loss 4.24952331 - samples/sec: 318.97 - lr: 0.050000\n",
            "2021-08-10 20:43:31,644 epoch 27 - iter 198/220 - loss 4.21882550 - samples/sec: 321.03 - lr: 0.050000\n",
            "2021-08-10 20:43:33,743 epoch 27 - iter 220/220 - loss 4.22875800 - samples/sec: 335.86 - lr: 0.050000\n",
            "2021-08-10 20:43:33,745 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:43:33,746 EPOCH 27 done: loss 4.2288 - lr 0.0500000\n",
            "2021-08-10 20:43:34,996 DEV : loss 3.4504611492156982 - score 0.7154\n",
            "2021-08-10 20:43:35,034 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 20:43:37,417 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:43:39,699 epoch 28 - iter 22/220 - loss 4.20051277 - samples/sec: 309.10 - lr: 0.050000\n",
            "2021-08-10 20:43:41,971 epoch 28 - iter 44/220 - loss 4.16590338 - samples/sec: 310.25 - lr: 0.050000\n",
            "2021-08-10 20:43:44,166 epoch 28 - iter 66/220 - loss 4.22741588 - samples/sec: 321.09 - lr: 0.050000\n",
            "2021-08-10 20:43:46,408 epoch 28 - iter 88/220 - loss 4.22005649 - samples/sec: 314.40 - lr: 0.050000\n",
            "2021-08-10 20:43:48,587 epoch 28 - iter 110/220 - loss 4.19076209 - samples/sec: 323.34 - lr: 0.050000\n",
            "2021-08-10 20:43:50,707 epoch 28 - iter 132/220 - loss 4.19581188 - samples/sec: 332.58 - lr: 0.050000\n",
            "2021-08-10 20:43:52,872 epoch 28 - iter 154/220 - loss 4.19739725 - samples/sec: 325.47 - lr: 0.050000\n",
            "2021-08-10 20:43:55,050 epoch 28 - iter 176/220 - loss 4.19679772 - samples/sec: 323.70 - lr: 0.050000\n",
            "2021-08-10 20:43:57,263 epoch 28 - iter 198/220 - loss 4.19738626 - samples/sec: 318.54 - lr: 0.050000\n",
            "2021-08-10 20:43:59,531 epoch 28 - iter 220/220 - loss 4.21932637 - samples/sec: 310.72 - lr: 0.050000\n",
            "2021-08-10 20:43:59,532 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:43:59,533 EPOCH 28 done: loss 4.2193 - lr 0.0500000\n",
            "2021-08-10 20:44:00,806 DEV : loss 3.484105110168457 - score 0.7031\n",
            "2021-08-10 20:44:00,849 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 20:44:00,851 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:44:02,948 epoch 29 - iter 22/220 - loss 4.14414714 - samples/sec: 336.43 - lr: 0.050000\n",
            "2021-08-10 20:44:05,069 epoch 29 - iter 44/220 - loss 4.21160407 - samples/sec: 332.39 - lr: 0.050000\n",
            "2021-08-10 20:44:07,276 epoch 29 - iter 66/220 - loss 4.12307234 - samples/sec: 319.36 - lr: 0.050000\n",
            "2021-08-10 20:44:09,576 epoch 29 - iter 88/220 - loss 4.12741512 - samples/sec: 306.50 - lr: 0.050000\n",
            "2021-08-10 20:44:11,821 epoch 29 - iter 110/220 - loss 4.17054898 - samples/sec: 313.95 - lr: 0.050000\n",
            "2021-08-10 20:44:14,070 epoch 29 - iter 132/220 - loss 4.18034137 - samples/sec: 313.40 - lr: 0.050000\n",
            "2021-08-10 20:44:16,217 epoch 29 - iter 154/220 - loss 4.15627936 - samples/sec: 328.39 - lr: 0.050000\n",
            "2021-08-10 20:44:18,404 epoch 29 - iter 176/220 - loss 4.12936325 - samples/sec: 322.17 - lr: 0.050000\n",
            "2021-08-10 20:44:20,633 epoch 29 - iter 198/220 - loss 4.13696322 - samples/sec: 316.30 - lr: 0.050000\n",
            "2021-08-10 20:44:22,837 epoch 29 - iter 220/220 - loss 4.16548532 - samples/sec: 319.73 - lr: 0.050000\n",
            "2021-08-10 20:44:22,839 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:44:22,840 EPOCH 29 done: loss 4.1655 - lr 0.0500000\n",
            "2021-08-10 20:44:24,109 DEV : loss 3.4307191371917725 - score 0.6999\n",
            "2021-08-10 20:44:24,147 BAD EPOCHS (no improvement): 2\n",
            "2021-08-10 20:44:24,149 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:44:26,357 epoch 30 - iter 22/220 - loss 3.98529365 - samples/sec: 319.49 - lr: 0.050000\n",
            "2021-08-10 20:44:28,457 epoch 30 - iter 44/220 - loss 4.05827998 - samples/sec: 335.75 - lr: 0.050000\n",
            "2021-08-10 20:44:30,688 epoch 30 - iter 66/220 - loss 4.04491900 - samples/sec: 315.94 - lr: 0.050000\n",
            "2021-08-10 20:44:32,974 epoch 30 - iter 88/220 - loss 4.10461052 - samples/sec: 308.25 - lr: 0.050000\n",
            "2021-08-10 20:44:35,167 epoch 30 - iter 110/220 - loss 4.12111152 - samples/sec: 321.59 - lr: 0.050000\n",
            "2021-08-10 20:44:37,388 epoch 30 - iter 132/220 - loss 4.13898741 - samples/sec: 317.30 - lr: 0.050000\n",
            "2021-08-10 20:44:39,609 epoch 30 - iter 154/220 - loss 4.13271907 - samples/sec: 317.33 - lr: 0.050000\n",
            "2021-08-10 20:44:41,798 epoch 30 - iter 176/220 - loss 4.09865887 - samples/sec: 322.06 - lr: 0.050000\n",
            "2021-08-10 20:44:44,032 epoch 30 - iter 198/220 - loss 4.13166833 - samples/sec: 315.37 - lr: 0.050000\n",
            "2021-08-10 20:44:46,184 epoch 30 - iter 220/220 - loss 4.16536573 - samples/sec: 327.65 - lr: 0.050000\n",
            "2021-08-10 20:44:46,185 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:44:46,186 EPOCH 30 done: loss 4.1654 - lr 0.0500000\n",
            "2021-08-10 20:44:47,432 DEV : loss 3.440380811691284 - score 0.7047\n",
            "2021-08-10 20:44:47,469 BAD EPOCHS (no improvement): 3\n",
            "2021-08-10 20:44:47,470 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:44:49,717 epoch 31 - iter 22/220 - loss 4.11299761 - samples/sec: 313.84 - lr: 0.050000\n",
            "2021-08-10 20:44:51,888 epoch 31 - iter 44/220 - loss 4.19027015 - samples/sec: 324.76 - lr: 0.050000\n",
            "2021-08-10 20:44:54,089 epoch 31 - iter 66/220 - loss 4.11826751 - samples/sec: 320.18 - lr: 0.050000\n",
            "2021-08-10 20:44:56,250 epoch 31 - iter 88/220 - loss 4.10827326 - samples/sec: 326.15 - lr: 0.050000\n",
            "2021-08-10 20:44:58,412 epoch 31 - iter 110/220 - loss 4.12121722 - samples/sec: 326.06 - lr: 0.050000\n",
            "2021-08-10 20:45:00,533 epoch 31 - iter 132/220 - loss 4.10636763 - samples/sec: 332.35 - lr: 0.050000\n",
            "2021-08-10 20:45:02,792 epoch 31 - iter 154/220 - loss 4.14792786 - samples/sec: 312.02 - lr: 0.050000\n",
            "2021-08-10 20:45:04,994 epoch 31 - iter 176/220 - loss 4.16089460 - samples/sec: 320.11 - lr: 0.050000\n",
            "2021-08-10 20:45:07,252 epoch 31 - iter 198/220 - loss 4.13471952 - samples/sec: 312.03 - lr: 0.050000\n",
            "2021-08-10 20:45:09,396 epoch 31 - iter 220/220 - loss 4.12905244 - samples/sec: 328.82 - lr: 0.050000\n",
            "2021-08-10 20:45:09,398 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:45:09,399 EPOCH 31 done: loss 4.1291 - lr 0.0500000\n",
            "2021-08-10 20:45:10,661 DEV : loss 3.3953638076782227 - score 0.7082\n",
            "Epoch    31: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2021-08-10 20:45:10,700 BAD EPOCHS (no improvement): 4\n",
            "2021-08-10 20:45:10,702 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:45:12,904 epoch 32 - iter 22/220 - loss 4.21211028 - samples/sec: 320.26 - lr: 0.025000\n",
            "2021-08-10 20:45:15,190 epoch 32 - iter 44/220 - loss 3.95467820 - samples/sec: 308.34 - lr: 0.025000\n",
            "2021-08-10 20:45:17,489 epoch 32 - iter 66/220 - loss 4.10723811 - samples/sec: 306.48 - lr: 0.025000\n",
            "2021-08-10 20:45:19,640 epoch 32 - iter 88/220 - loss 4.03287287 - samples/sec: 327.69 - lr: 0.025000\n",
            "2021-08-10 20:45:21,945 epoch 32 - iter 110/220 - loss 4.05317037 - samples/sec: 305.80 - lr: 0.025000\n",
            "2021-08-10 20:45:24,079 epoch 32 - iter 132/220 - loss 4.06018153 - samples/sec: 330.33 - lr: 0.025000\n",
            "2021-08-10 20:45:26,336 epoch 32 - iter 154/220 - loss 4.08219124 - samples/sec: 312.27 - lr: 0.025000\n",
            "2021-08-10 20:45:28,442 epoch 32 - iter 176/220 - loss 4.06723817 - samples/sec: 334.80 - lr: 0.025000\n",
            "2021-08-10 20:45:30,619 epoch 32 - iter 198/220 - loss 4.05268818 - samples/sec: 323.85 - lr: 0.025000\n",
            "2021-08-10 20:45:32,747 epoch 32 - iter 220/220 - loss 4.03787758 - samples/sec: 331.22 - lr: 0.025000\n",
            "2021-08-10 20:45:32,748 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:45:32,749 EPOCH 32 done: loss 4.0379 - lr 0.0250000\n",
            "2021-08-10 20:45:33,993 DEV : loss 3.4269495010375977 - score 0.7088\n",
            "2021-08-10 20:45:34,032 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 20:45:34,034 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:45:36,224 epoch 33 - iter 22/220 - loss 4.20949492 - samples/sec: 321.95 - lr: 0.025000\n",
            "2021-08-10 20:45:38,415 epoch 33 - iter 44/220 - loss 4.11136073 - samples/sec: 321.77 - lr: 0.025000\n",
            "2021-08-10 20:45:40,578 epoch 33 - iter 66/220 - loss 4.03831907 - samples/sec: 325.86 - lr: 0.025000\n",
            "2021-08-10 20:45:42,879 epoch 33 - iter 88/220 - loss 4.07131968 - samples/sec: 306.40 - lr: 0.025000\n",
            "2021-08-10 20:45:45,174 epoch 33 - iter 110/220 - loss 4.04810022 - samples/sec: 307.10 - lr: 0.025000\n",
            "2021-08-10 20:45:47,358 epoch 33 - iter 132/220 - loss 4.05535975 - samples/sec: 322.82 - lr: 0.025000\n",
            "2021-08-10 20:45:49,461 epoch 33 - iter 154/220 - loss 4.06366082 - samples/sec: 335.18 - lr: 0.025000\n",
            "2021-08-10 20:45:51,603 epoch 33 - iter 176/220 - loss 4.03508785 - samples/sec: 329.00 - lr: 0.025000\n",
            "2021-08-10 20:45:53,758 epoch 33 - iter 198/220 - loss 4.02778866 - samples/sec: 327.15 - lr: 0.025000\n",
            "2021-08-10 20:45:55,934 epoch 33 - iter 220/220 - loss 4.01601533 - samples/sec: 323.86 - lr: 0.025000\n",
            "2021-08-10 20:45:55,936 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:45:55,937 EPOCH 33 done: loss 4.0160 - lr 0.0250000\n",
            "2021-08-10 20:45:57,202 DEV : loss 3.4015071392059326 - score 0.7155\n",
            "2021-08-10 20:45:57,239 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-08-10 20:45:59,615 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:46:01,791 epoch 34 - iter 22/220 - loss 4.00096351 - samples/sec: 324.13 - lr: 0.025000\n",
            "2021-08-10 20:46:04,002 epoch 34 - iter 44/220 - loss 4.06128765 - samples/sec: 318.77 - lr: 0.025000\n",
            "2021-08-10 20:46:06,234 epoch 34 - iter 66/220 - loss 4.09947127 - samples/sec: 315.82 - lr: 0.025000\n",
            "2021-08-10 20:46:08,478 epoch 34 - iter 88/220 - loss 4.08963602 - samples/sec: 314.26 - lr: 0.025000\n",
            "2021-08-10 20:46:10,691 epoch 34 - iter 110/220 - loss 4.09911879 - samples/sec: 318.51 - lr: 0.025000\n",
            "2021-08-10 20:46:12,924 epoch 34 - iter 132/220 - loss 4.06675567 - samples/sec: 315.59 - lr: 0.025000\n",
            "2021-08-10 20:46:15,210 epoch 34 - iter 154/220 - loss 4.00507596 - samples/sec: 308.40 - lr: 0.025000\n",
            "2021-08-10 20:46:17,298 epoch 34 - iter 176/220 - loss 3.98685313 - samples/sec: 337.66 - lr: 0.025000\n",
            "2021-08-10 20:46:19,437 epoch 34 - iter 198/220 - loss 3.97536888 - samples/sec: 329.47 - lr: 0.025000\n",
            "2021-08-10 20:46:21,627 epoch 34 - iter 220/220 - loss 3.97432437 - samples/sec: 321.82 - lr: 0.025000\n",
            "2021-08-10 20:46:21,628 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:46:21,629 EPOCH 34 done: loss 3.9743 - lr 0.0250000\n",
            "2021-08-10 20:46:22,911 DEV : loss 3.366137981414795 - score 0.7051\n",
            "2021-08-10 20:46:22,948 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 20:46:22,950 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:46:25,191 epoch 35 - iter 22/220 - loss 4.16876580 - samples/sec: 314.58 - lr: 0.025000\n",
            "2021-08-10 20:46:27,399 epoch 35 - iter 44/220 - loss 4.07508449 - samples/sec: 319.25 - lr: 0.025000\n",
            "2021-08-10 20:46:29,559 epoch 35 - iter 66/220 - loss 3.92121122 - samples/sec: 326.28 - lr: 0.025000\n",
            "2021-08-10 20:46:31,659 epoch 35 - iter 88/220 - loss 3.96507236 - samples/sec: 335.61 - lr: 0.025000\n",
            "2021-08-10 20:46:33,847 epoch 35 - iter 110/220 - loss 3.94873604 - samples/sec: 322.24 - lr: 0.025000\n",
            "2021-08-10 20:46:35,962 epoch 35 - iter 132/220 - loss 3.97238385 - samples/sec: 333.22 - lr: 0.025000\n",
            "2021-08-10 20:46:38,137 epoch 35 - iter 154/220 - loss 3.97133741 - samples/sec: 324.14 - lr: 0.025000\n",
            "2021-08-10 20:46:40,272 epoch 35 - iter 176/220 - loss 3.97055154 - samples/sec: 330.09 - lr: 0.025000\n",
            "2021-08-10 20:46:42,583 epoch 35 - iter 198/220 - loss 3.98999470 - samples/sec: 305.09 - lr: 0.025000\n",
            "2021-08-10 20:46:44,868 epoch 35 - iter 220/220 - loss 3.98436192 - samples/sec: 308.40 - lr: 0.025000\n",
            "2021-08-10 20:46:44,869 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:46:44,871 EPOCH 35 done: loss 3.9844 - lr 0.0250000\n",
            "2021-08-10 20:46:46,950 DEV : loss 3.335923194885254 - score 0.7117\n",
            "2021-08-10 20:46:46,987 BAD EPOCHS (no improvement): 2\n",
            "2021-08-10 20:46:46,989 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:46:49,248 epoch 36 - iter 22/220 - loss 3.88346231 - samples/sec: 312.20 - lr: 0.025000\n",
            "2021-08-10 20:46:51,510 epoch 36 - iter 44/220 - loss 3.91634928 - samples/sec: 311.49 - lr: 0.025000\n",
            "2021-08-10 20:46:53,674 epoch 36 - iter 66/220 - loss 3.97478463 - samples/sec: 325.71 - lr: 0.025000\n",
            "2021-08-10 20:46:55,839 epoch 36 - iter 88/220 - loss 3.95987324 - samples/sec: 325.67 - lr: 0.025000\n",
            "2021-08-10 20:46:58,032 epoch 36 - iter 110/220 - loss 3.97753455 - samples/sec: 321.33 - lr: 0.025000\n",
            "2021-08-10 20:47:00,212 epoch 36 - iter 132/220 - loss 3.99929525 - samples/sec: 323.37 - lr: 0.025000\n",
            "2021-08-10 20:47:02,428 epoch 36 - iter 154/220 - loss 3.97775133 - samples/sec: 317.97 - lr: 0.025000\n",
            "2021-08-10 20:47:04,697 epoch 36 - iter 176/220 - loss 3.96919025 - samples/sec: 310.73 - lr: 0.025000\n",
            "2021-08-10 20:47:06,872 epoch 36 - iter 198/220 - loss 3.96220181 - samples/sec: 324.06 - lr: 0.025000\n",
            "2021-08-10 20:47:09,008 epoch 36 - iter 220/220 - loss 3.97649124 - samples/sec: 330.00 - lr: 0.025000\n",
            "2021-08-10 20:47:09,009 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:47:09,011 EPOCH 36 done: loss 3.9765 - lr 0.0250000\n",
            "2021-08-10 20:47:10,267 DEV : loss 3.3983073234558105 - score 0.7054\n",
            "2021-08-10 20:47:10,306 BAD EPOCHS (no improvement): 3\n",
            "2021-08-10 20:47:10,308 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:47:12,495 epoch 37 - iter 22/220 - loss 3.73746590 - samples/sec: 322.40 - lr: 0.025000\n",
            "2021-08-10 20:47:14,723 epoch 37 - iter 44/220 - loss 3.82918426 - samples/sec: 316.43 - lr: 0.025000\n",
            "2021-08-10 20:47:16,850 epoch 37 - iter 66/220 - loss 3.77323715 - samples/sec: 331.36 - lr: 0.025000\n",
            "2021-08-10 20:47:19,111 epoch 37 - iter 88/220 - loss 3.75280605 - samples/sec: 311.69 - lr: 0.025000\n",
            "2021-08-10 20:47:21,323 epoch 37 - iter 110/220 - loss 3.80794341 - samples/sec: 318.69 - lr: 0.025000\n",
            "2021-08-10 20:47:23,462 epoch 37 - iter 132/220 - loss 3.86244474 - samples/sec: 329.42 - lr: 0.025000\n",
            "2021-08-10 20:47:25,663 epoch 37 - iter 154/220 - loss 3.87023060 - samples/sec: 320.29 - lr: 0.025000\n",
            "2021-08-10 20:47:27,938 epoch 37 - iter 176/220 - loss 3.89311906 - samples/sec: 309.83 - lr: 0.025000\n",
            "2021-08-10 20:47:30,146 epoch 37 - iter 198/220 - loss 3.88925159 - samples/sec: 319.25 - lr: 0.025000\n",
            "2021-08-10 20:47:32,376 epoch 37 - iter 220/220 - loss 3.92507795 - samples/sec: 316.15 - lr: 0.025000\n",
            "2021-08-10 20:47:32,377 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:47:32,378 EPOCH 37 done: loss 3.9251 - lr 0.0250000\n",
            "2021-08-10 20:47:33,668 DEV : loss 3.3886404037475586 - score 0.7055\n",
            "Epoch    37: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2021-08-10 20:47:33,707 BAD EPOCHS (no improvement): 4\n",
            "2021-08-10 20:47:33,708 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:47:35,938 epoch 38 - iter 22/220 - loss 3.90130429 - samples/sec: 316.34 - lr: 0.012500\n",
            "2021-08-10 20:47:38,125 epoch 38 - iter 44/220 - loss 4.01487245 - samples/sec: 322.22 - lr: 0.012500\n",
            "2021-08-10 20:47:40,321 epoch 38 - iter 66/220 - loss 3.92935446 - samples/sec: 320.97 - lr: 0.012500\n",
            "2021-08-10 20:47:42,505 epoch 38 - iter 88/220 - loss 3.90740130 - samples/sec: 322.82 - lr: 0.012500\n",
            "2021-08-10 20:47:44,656 epoch 38 - iter 110/220 - loss 3.89373970 - samples/sec: 327.74 - lr: 0.012500\n",
            "2021-08-10 20:47:46,867 epoch 38 - iter 132/220 - loss 3.89145132 - samples/sec: 318.76 - lr: 0.012500\n",
            "2021-08-10 20:47:49,145 epoch 38 - iter 154/220 - loss 3.92957361 - samples/sec: 309.40 - lr: 0.012500\n",
            "2021-08-10 20:47:51,364 epoch 38 - iter 176/220 - loss 3.93775232 - samples/sec: 317.68 - lr: 0.012500\n",
            "2021-08-10 20:47:53,569 epoch 38 - iter 198/220 - loss 3.94781111 - samples/sec: 319.64 - lr: 0.012500\n",
            "2021-08-10 20:47:55,692 epoch 38 - iter 220/220 - loss 3.95098671 - samples/sec: 332.13 - lr: 0.012500\n",
            "2021-08-10 20:47:55,693 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:47:55,695 EPOCH 38 done: loss 3.9510 - lr 0.0125000\n",
            "2021-08-10 20:47:56,964 DEV : loss 3.3519036769866943 - score 0.7101\n",
            "2021-08-10 20:47:57,002 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 20:47:57,004 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:47:59,229 epoch 39 - iter 22/220 - loss 3.88237005 - samples/sec: 317.02 - lr: 0.012500\n",
            "2021-08-10 20:48:01,416 epoch 39 - iter 44/220 - loss 3.79905466 - samples/sec: 322.25 - lr: 0.012500\n",
            "2021-08-10 20:48:03,578 epoch 39 - iter 66/220 - loss 3.79223411 - samples/sec: 326.06 - lr: 0.012500\n",
            "2021-08-10 20:48:05,716 epoch 39 - iter 88/220 - loss 3.88231070 - samples/sec: 329.60 - lr: 0.012500\n",
            "2021-08-10 20:48:07,922 epoch 39 - iter 110/220 - loss 3.92037109 - samples/sec: 319.56 - lr: 0.012500\n",
            "2021-08-10 20:48:10,057 epoch 39 - iter 132/220 - loss 3.87371559 - samples/sec: 330.11 - lr: 0.012500\n",
            "2021-08-10 20:48:12,299 epoch 39 - iter 154/220 - loss 3.85381517 - samples/sec: 314.39 - lr: 0.012500\n",
            "2021-08-10 20:48:14,514 epoch 39 - iter 176/220 - loss 3.88757705 - samples/sec: 318.19 - lr: 0.012500\n",
            "2021-08-10 20:48:16,797 epoch 39 - iter 198/220 - loss 3.88168978 - samples/sec: 308.76 - lr: 0.012500\n",
            "2021-08-10 20:48:19,114 epoch 39 - iter 220/220 - loss 3.89030073 - samples/sec: 304.21 - lr: 0.012500\n",
            "2021-08-10 20:48:19,116 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:48:19,117 EPOCH 39 done: loss 3.8903 - lr 0.0125000\n",
            "2021-08-10 20:48:20,439 DEV : loss 3.3473570346832275 - score 0.7087\n",
            "2021-08-10 20:48:20,476 BAD EPOCHS (no improvement): 2\n",
            "2021-08-10 20:48:20,477 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:48:22,696 epoch 40 - iter 22/220 - loss 3.78108000 - samples/sec: 317.88 - lr: 0.012500\n",
            "2021-08-10 20:48:24,910 epoch 40 - iter 44/220 - loss 3.86036456 - samples/sec: 318.48 - lr: 0.012500\n",
            "2021-08-10 20:48:27,226 epoch 40 - iter 66/220 - loss 3.99842433 - samples/sec: 304.25 - lr: 0.012500\n",
            "2021-08-10 20:48:29,417 epoch 40 - iter 88/220 - loss 3.95411177 - samples/sec: 321.82 - lr: 0.012500\n",
            "2021-08-10 20:48:31,561 epoch 40 - iter 110/220 - loss 3.91276801 - samples/sec: 328.71 - lr: 0.012500\n",
            "2021-08-10 20:48:33,763 epoch 40 - iter 132/220 - loss 3.91452493 - samples/sec: 320.15 - lr: 0.012500\n",
            "2021-08-10 20:48:35,857 epoch 40 - iter 154/220 - loss 3.88681270 - samples/sec: 336.60 - lr: 0.012500\n",
            "2021-08-10 20:48:38,085 epoch 40 - iter 176/220 - loss 3.90099369 - samples/sec: 316.43 - lr: 0.012500\n",
            "2021-08-10 20:48:40,305 epoch 40 - iter 198/220 - loss 3.89710170 - samples/sec: 317.44 - lr: 0.012500\n",
            "2021-08-10 20:48:42,541 epoch 40 - iter 220/220 - loss 3.90163268 - samples/sec: 315.18 - lr: 0.012500\n",
            "2021-08-10 20:48:42,542 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:48:42,545 EPOCH 40 done: loss 3.9016 - lr 0.0125000\n",
            "2021-08-10 20:48:43,803 DEV : loss 3.3135433197021484 - score 0.7063\n",
            "2021-08-10 20:48:43,840 BAD EPOCHS (no improvement): 3\n",
            "2021-08-10 20:48:43,841 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:48:46,035 epoch 41 - iter 22/220 - loss 3.97135416 - samples/sec: 321.60 - lr: 0.012500\n",
            "2021-08-10 20:48:48,159 epoch 41 - iter 44/220 - loss 3.95955882 - samples/sec: 331.82 - lr: 0.012500\n",
            "2021-08-10 20:48:50,359 epoch 41 - iter 66/220 - loss 3.95922532 - samples/sec: 320.48 - lr: 0.012500\n",
            "2021-08-10 20:48:52,496 epoch 41 - iter 88/220 - loss 3.99346555 - samples/sec: 329.76 - lr: 0.012500\n",
            "2021-08-10 20:48:54,758 epoch 41 - iter 110/220 - loss 3.94487889 - samples/sec: 311.59 - lr: 0.012500\n",
            "2021-08-10 20:48:56,998 epoch 41 - iter 132/220 - loss 3.95078897 - samples/sec: 314.74 - lr: 0.012500\n",
            "2021-08-10 20:48:59,202 epoch 41 - iter 154/220 - loss 3.91062965 - samples/sec: 319.72 - lr: 0.012500\n",
            "2021-08-10 20:49:01,430 epoch 41 - iter 176/220 - loss 3.89757863 - samples/sec: 316.40 - lr: 0.012500\n",
            "2021-08-10 20:49:03,579 epoch 41 - iter 198/220 - loss 3.90320616 - samples/sec: 327.97 - lr: 0.012500\n",
            "2021-08-10 20:49:05,847 epoch 41 - iter 220/220 - loss 3.89122884 - samples/sec: 310.89 - lr: 0.012500\n",
            "2021-08-10 20:49:05,848 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:49:05,849 EPOCH 41 done: loss 3.8912 - lr 0.0125000\n",
            "2021-08-10 20:49:07,119 DEV : loss 3.3447988033294678 - score 0.7058\n",
            "Epoch    41: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2021-08-10 20:49:07,159 BAD EPOCHS (no improvement): 4\n",
            "2021-08-10 20:49:07,161 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:49:09,466 epoch 42 - iter 22/220 - loss 3.86821373 - samples/sec: 305.93 - lr: 0.006250\n",
            "2021-08-10 20:49:11,644 epoch 42 - iter 44/220 - loss 3.85600742 - samples/sec: 323.64 - lr: 0.006250\n",
            "2021-08-10 20:49:13,874 epoch 42 - iter 66/220 - loss 3.77728515 - samples/sec: 316.21 - lr: 0.006250\n",
            "2021-08-10 20:49:16,041 epoch 42 - iter 88/220 - loss 3.80981824 - samples/sec: 325.14 - lr: 0.006250\n",
            "2021-08-10 20:49:18,318 epoch 42 - iter 110/220 - loss 3.87477531 - samples/sec: 309.54 - lr: 0.006250\n",
            "2021-08-10 20:49:20,522 epoch 42 - iter 132/220 - loss 3.82236666 - samples/sec: 319.87 - lr: 0.006250\n",
            "2021-08-10 20:49:22,631 epoch 42 - iter 154/220 - loss 3.82623692 - samples/sec: 334.23 - lr: 0.006250\n",
            "2021-08-10 20:49:24,875 epoch 42 - iter 176/220 - loss 3.83125017 - samples/sec: 314.12 - lr: 0.006250\n",
            "2021-08-10 20:49:27,166 epoch 42 - iter 198/220 - loss 3.85788678 - samples/sec: 307.53 - lr: 0.006250\n",
            "2021-08-10 20:49:29,397 epoch 42 - iter 220/220 - loss 3.84896252 - samples/sec: 315.99 - lr: 0.006250\n",
            "2021-08-10 20:49:29,398 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:49:29,399 EPOCH 42 done: loss 3.8490 - lr 0.0062500\n",
            "2021-08-10 20:49:30,690 DEV : loss 3.3290343284606934 - score 0.7129\n",
            "2021-08-10 20:49:30,728 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 20:49:30,730 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:49:33,035 epoch 43 - iter 22/220 - loss 4.12135119 - samples/sec: 305.77 - lr: 0.006250\n",
            "2021-08-10 20:49:35,145 epoch 43 - iter 44/220 - loss 4.02070137 - samples/sec: 334.11 - lr: 0.006250\n",
            "2021-08-10 20:49:37,295 epoch 43 - iter 66/220 - loss 3.95803336 - samples/sec: 327.81 - lr: 0.006250\n",
            "2021-08-10 20:49:39,456 epoch 43 - iter 88/220 - loss 3.92799099 - samples/sec: 326.31 - lr: 0.006250\n",
            "2021-08-10 20:49:41,610 epoch 43 - iter 110/220 - loss 3.88627196 - samples/sec: 327.19 - lr: 0.006250\n",
            "2021-08-10 20:49:43,823 epoch 43 - iter 132/220 - loss 3.85835268 - samples/sec: 318.56 - lr: 0.006250\n",
            "2021-08-10 20:49:46,029 epoch 43 - iter 154/220 - loss 3.86762541 - samples/sec: 319.52 - lr: 0.006250\n",
            "2021-08-10 20:49:48,230 epoch 43 - iter 176/220 - loss 3.86398623 - samples/sec: 320.17 - lr: 0.006250\n",
            "2021-08-10 20:49:50,401 epoch 43 - iter 198/220 - loss 3.86412736 - samples/sec: 324.59 - lr: 0.006250\n",
            "2021-08-10 20:49:52,569 epoch 43 - iter 220/220 - loss 3.85000267 - samples/sec: 325.19 - lr: 0.006250\n",
            "2021-08-10 20:49:52,570 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:49:52,571 EPOCH 43 done: loss 3.8500 - lr 0.0062500\n",
            "2021-08-10 20:49:53,836 DEV : loss 3.330641984939575 - score 0.7105\n",
            "2021-08-10 20:49:53,875 BAD EPOCHS (no improvement): 2\n",
            "2021-08-10 20:49:53,877 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:49:56,056 epoch 44 - iter 22/220 - loss 4.04066465 - samples/sec: 323.59 - lr: 0.006250\n",
            "2021-08-10 20:49:58,157 epoch 44 - iter 44/220 - loss 3.97403949 - samples/sec: 335.47 - lr: 0.006250\n",
            "2021-08-10 20:50:00,415 epoch 44 - iter 66/220 - loss 3.90222739 - samples/sec: 312.25 - lr: 0.006250\n",
            "2021-08-10 20:50:02,549 epoch 44 - iter 88/220 - loss 3.86985108 - samples/sec: 330.22 - lr: 0.006250\n",
            "2021-08-10 20:50:04,627 epoch 44 - iter 110/220 - loss 3.86951849 - samples/sec: 339.22 - lr: 0.006250\n",
            "2021-08-10 20:50:06,869 epoch 44 - iter 132/220 - loss 3.83643350 - samples/sec: 314.43 - lr: 0.006250\n",
            "2021-08-10 20:50:09,075 epoch 44 - iter 154/220 - loss 3.85039534 - samples/sec: 319.47 - lr: 0.006250\n",
            "2021-08-10 20:50:11,328 epoch 44 - iter 176/220 - loss 3.84034915 - samples/sec: 312.80 - lr: 0.006250\n",
            "2021-08-10 20:50:13,569 epoch 44 - iter 198/220 - loss 3.85104397 - samples/sec: 314.63 - lr: 0.006250\n",
            "2021-08-10 20:50:15,877 epoch 44 - iter 220/220 - loss 3.83420959 - samples/sec: 305.37 - lr: 0.006250\n",
            "2021-08-10 20:50:15,878 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:50:15,879 EPOCH 44 done: loss 3.8342 - lr 0.0062500\n",
            "2021-08-10 20:50:17,176 DEV : loss 3.321019172668457 - score 0.7086\n",
            "2021-08-10 20:50:17,212 BAD EPOCHS (no improvement): 3\n",
            "2021-08-10 20:50:17,215 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:50:19,394 epoch 45 - iter 22/220 - loss 3.83908665 - samples/sec: 323.88 - lr: 0.006250\n",
            "2021-08-10 20:50:21,609 epoch 45 - iter 44/220 - loss 3.84001434 - samples/sec: 318.20 - lr: 0.006250\n",
            "2021-08-10 20:50:23,762 epoch 45 - iter 66/220 - loss 3.90071098 - samples/sec: 327.41 - lr: 0.006250\n",
            "2021-08-10 20:50:25,980 epoch 45 - iter 88/220 - loss 3.87077345 - samples/sec: 317.75 - lr: 0.006250\n",
            "2021-08-10 20:50:28,249 epoch 45 - iter 110/220 - loss 3.92369427 - samples/sec: 310.56 - lr: 0.006250\n",
            "2021-08-10 20:50:30,395 epoch 45 - iter 132/220 - loss 3.87968343 - samples/sec: 328.50 - lr: 0.006250\n",
            "2021-08-10 20:50:32,752 epoch 45 - iter 154/220 - loss 3.87860912 - samples/sec: 299.08 - lr: 0.006250\n",
            "2021-08-10 20:50:34,936 epoch 45 - iter 176/220 - loss 3.87495530 - samples/sec: 322.73 - lr: 0.006250\n",
            "2021-08-10 20:50:37,168 epoch 45 - iter 198/220 - loss 3.87800770 - samples/sec: 315.75 - lr: 0.006250\n",
            "2021-08-10 20:50:39,379 epoch 45 - iter 220/220 - loss 3.85237622 - samples/sec: 318.77 - lr: 0.006250\n",
            "2021-08-10 20:50:39,381 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:50:39,382 EPOCH 45 done: loss 3.8524 - lr 0.0062500\n",
            "2021-08-10 20:50:40,649 DEV : loss 3.3188891410827637 - score 0.7122\n",
            "Epoch    45: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2021-08-10 20:50:40,687 BAD EPOCHS (no improvement): 4\n",
            "2021-08-10 20:50:40,688 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:50:42,898 epoch 46 - iter 22/220 - loss 3.71377073 - samples/sec: 319.18 - lr: 0.003125\n",
            "2021-08-10 20:50:45,032 epoch 46 - iter 44/220 - loss 3.79721526 - samples/sec: 330.19 - lr: 0.003125\n",
            "2021-08-10 20:50:47,159 epoch 46 - iter 66/220 - loss 3.71703145 - samples/sec: 331.40 - lr: 0.003125\n",
            "2021-08-10 20:50:49,383 epoch 46 - iter 88/220 - loss 3.77193855 - samples/sec: 316.92 - lr: 0.003125\n",
            "2021-08-10 20:50:51,576 epoch 46 - iter 110/220 - loss 3.76864737 - samples/sec: 321.35 - lr: 0.003125\n",
            "2021-08-10 20:50:53,870 epoch 46 - iter 132/220 - loss 3.77971607 - samples/sec: 307.29 - lr: 0.003125\n",
            "2021-08-10 20:50:56,136 epoch 46 - iter 154/220 - loss 3.80590556 - samples/sec: 311.06 - lr: 0.003125\n",
            "2021-08-10 20:50:58,361 epoch 46 - iter 176/220 - loss 3.83361092 - samples/sec: 316.71 - lr: 0.003125\n",
            "2021-08-10 20:51:00,513 epoch 46 - iter 198/220 - loss 3.83931205 - samples/sec: 327.68 - lr: 0.003125\n",
            "2021-08-10 20:51:02,676 epoch 46 - iter 220/220 - loss 3.81852342 - samples/sec: 325.90 - lr: 0.003125\n",
            "2021-08-10 20:51:02,678 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:51:02,679 EPOCH 46 done: loss 3.8185 - lr 0.0031250\n",
            "2021-08-10 20:51:03,933 DEV : loss 3.305068016052246 - score 0.7108\n",
            "2021-08-10 20:51:03,971 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 20:51:03,974 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:51:06,285 epoch 47 - iter 22/220 - loss 3.71043002 - samples/sec: 305.06 - lr: 0.003125\n",
            "2021-08-10 20:51:08,561 epoch 47 - iter 44/220 - loss 3.80405326 - samples/sec: 309.69 - lr: 0.003125\n",
            "2021-08-10 20:51:10,743 epoch 47 - iter 66/220 - loss 3.74131689 - samples/sec: 323.07 - lr: 0.003125\n",
            "2021-08-10 20:51:12,939 epoch 47 - iter 88/220 - loss 3.76460240 - samples/sec: 321.10 - lr: 0.003125\n",
            "2021-08-10 20:51:15,095 epoch 47 - iter 110/220 - loss 3.77958931 - samples/sec: 326.86 - lr: 0.003125\n",
            "2021-08-10 20:51:17,232 epoch 47 - iter 132/220 - loss 3.77739041 - samples/sec: 329.87 - lr: 0.003125\n",
            "2021-08-10 20:51:19,441 epoch 47 - iter 154/220 - loss 3.75031266 - samples/sec: 319.04 - lr: 0.003125\n",
            "2021-08-10 20:51:21,648 epoch 47 - iter 176/220 - loss 3.79048653 - samples/sec: 319.45 - lr: 0.003125\n",
            "2021-08-10 20:51:23,888 epoch 47 - iter 198/220 - loss 3.79398201 - samples/sec: 314.64 - lr: 0.003125\n",
            "2021-08-10 20:51:26,062 epoch 47 - iter 220/220 - loss 3.80549431 - samples/sec: 324.36 - lr: 0.003125\n",
            "2021-08-10 20:51:26,063 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:51:26,064 EPOCH 47 done: loss 3.8055 - lr 0.0031250\n",
            "2021-08-10 20:51:27,327 DEV : loss 3.3102598190307617 - score 0.7108\n",
            "2021-08-10 20:51:27,363 BAD EPOCHS (no improvement): 2\n",
            "2021-08-10 20:51:27,364 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:51:29,562 epoch 48 - iter 22/220 - loss 3.89027078 - samples/sec: 321.01 - lr: 0.003125\n",
            "2021-08-10 20:51:31,688 epoch 48 - iter 44/220 - loss 3.81555424 - samples/sec: 331.57 - lr: 0.003125\n",
            "2021-08-10 20:51:33,925 epoch 48 - iter 66/220 - loss 3.86772687 - samples/sec: 315.08 - lr: 0.003125\n",
            "2021-08-10 20:51:36,161 epoch 48 - iter 88/220 - loss 3.80492976 - samples/sec: 315.10 - lr: 0.003125\n",
            "2021-08-10 20:51:38,477 epoch 48 - iter 110/220 - loss 3.77948790 - samples/sec: 304.32 - lr: 0.003125\n",
            "2021-08-10 20:51:40,674 epoch 48 - iter 132/220 - loss 3.77064949 - samples/sec: 321.00 - lr: 0.003125\n",
            "2021-08-10 20:51:42,759 epoch 48 - iter 154/220 - loss 3.76355141 - samples/sec: 337.96 - lr: 0.003125\n",
            "2021-08-10 20:51:44,939 epoch 48 - iter 176/220 - loss 3.76389422 - samples/sec: 323.32 - lr: 0.003125\n",
            "2021-08-10 20:51:47,153 epoch 48 - iter 198/220 - loss 3.77332941 - samples/sec: 318.33 - lr: 0.003125\n",
            "2021-08-10 20:51:49,320 epoch 48 - iter 220/220 - loss 3.80634750 - samples/sec: 325.36 - lr: 0.003125\n",
            "2021-08-10 20:51:49,322 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:51:49,324 EPOCH 48 done: loss 3.8063 - lr 0.0031250\n",
            "2021-08-10 20:51:51,392 DEV : loss 3.318877696990967 - score 0.7106\n",
            "2021-08-10 20:51:51,429 BAD EPOCHS (no improvement): 3\n",
            "2021-08-10 20:51:51,431 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:51:53,713 epoch 49 - iter 22/220 - loss 3.68535689 - samples/sec: 309.09 - lr: 0.003125\n",
            "2021-08-10 20:51:55,873 epoch 49 - iter 44/220 - loss 3.74950623 - samples/sec: 326.24 - lr: 0.003125\n",
            "2021-08-10 20:51:57,997 epoch 49 - iter 66/220 - loss 3.85545774 - samples/sec: 331.83 - lr: 0.003125\n",
            "2021-08-10 20:52:00,215 epoch 49 - iter 88/220 - loss 3.87214056 - samples/sec: 317.84 - lr: 0.003125\n",
            "2021-08-10 20:52:02,417 epoch 49 - iter 110/220 - loss 3.88020227 - samples/sec: 320.05 - lr: 0.003125\n",
            "2021-08-10 20:52:04,705 epoch 49 - iter 132/220 - loss 3.86217177 - samples/sec: 308.03 - lr: 0.003125\n",
            "2021-08-10 20:52:06,947 epoch 49 - iter 154/220 - loss 3.85340625 - samples/sec: 314.34 - lr: 0.003125\n",
            "2021-08-10 20:52:09,106 epoch 49 - iter 176/220 - loss 3.86525104 - samples/sec: 326.38 - lr: 0.003125\n",
            "2021-08-10 20:52:11,385 epoch 49 - iter 198/220 - loss 3.85301437 - samples/sec: 309.32 - lr: 0.003125\n",
            "2021-08-10 20:52:13,537 epoch 49 - iter 220/220 - loss 3.81477879 - samples/sec: 327.47 - lr: 0.003125\n",
            "2021-08-10 20:52:13,539 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:52:13,540 EPOCH 49 done: loss 3.8148 - lr 0.0031250\n",
            "2021-08-10 20:52:14,816 DEV : loss 3.312084913253784 - score 0.7095\n",
            "Epoch    49: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2021-08-10 20:52:14,855 BAD EPOCHS (no improvement): 4\n",
            "2021-08-10 20:52:14,856 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:52:17,058 epoch 50 - iter 22/220 - loss 3.76574021 - samples/sec: 320.18 - lr: 0.001563\n",
            "2021-08-10 20:52:19,225 epoch 50 - iter 44/220 - loss 3.81921549 - samples/sec: 325.23 - lr: 0.001563\n",
            "2021-08-10 20:52:21,409 epoch 50 - iter 66/220 - loss 3.78746882 - samples/sec: 322.76 - lr: 0.001563\n",
            "2021-08-10 20:52:23,696 epoch 50 - iter 88/220 - loss 3.77765406 - samples/sec: 308.17 - lr: 0.001563\n",
            "2021-08-10 20:52:25,928 epoch 50 - iter 110/220 - loss 3.76242953 - samples/sec: 315.74 - lr: 0.001563\n",
            "2021-08-10 20:52:28,179 epoch 50 - iter 132/220 - loss 3.77081045 - samples/sec: 313.16 - lr: 0.001563\n",
            "2021-08-10 20:52:30,351 epoch 50 - iter 154/220 - loss 3.77634241 - samples/sec: 324.46 - lr: 0.001563\n",
            "2021-08-10 20:52:32,619 epoch 50 - iter 176/220 - loss 3.80016373 - samples/sec: 310.73 - lr: 0.001563\n",
            "2021-08-10 20:52:34,738 epoch 50 - iter 198/220 - loss 3.78459009 - samples/sec: 332.66 - lr: 0.001563\n",
            "2021-08-10 20:52:36,915 epoch 50 - iter 220/220 - loss 3.80277290 - samples/sec: 323.80 - lr: 0.001563\n",
            "2021-08-10 20:52:36,916 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:52:36,917 EPOCH 50 done: loss 3.8028 - lr 0.0015625\n",
            "2021-08-10 20:52:38,176 DEV : loss 3.3115923404693604 - score 0.7097\n",
            "2021-08-10 20:52:38,213 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 20:52:38,214 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:52:40,486 epoch 51 - iter 22/220 - loss 3.92412148 - samples/sec: 310.57 - lr: 0.001563\n",
            "2021-08-10 20:52:42,707 epoch 51 - iter 44/220 - loss 3.79311686 - samples/sec: 317.29 - lr: 0.001563\n",
            "2021-08-10 20:52:44,976 epoch 51 - iter 66/220 - loss 3.68632409 - samples/sec: 310.67 - lr: 0.001563\n",
            "2021-08-10 20:52:47,272 epoch 51 - iter 88/220 - loss 3.63054011 - samples/sec: 307.10 - lr: 0.001563\n",
            "2021-08-10 20:52:49,500 epoch 51 - iter 110/220 - loss 3.67232240 - samples/sec: 316.31 - lr: 0.001563\n",
            "2021-08-10 20:52:51,704 epoch 51 - iter 132/220 - loss 3.72155425 - samples/sec: 319.84 - lr: 0.001563\n",
            "2021-08-10 20:52:53,842 epoch 51 - iter 154/220 - loss 3.77267184 - samples/sec: 329.65 - lr: 0.001563\n",
            "2021-08-10 20:52:55,965 epoch 51 - iter 176/220 - loss 3.76014531 - samples/sec: 332.04 - lr: 0.001563\n",
            "2021-08-10 20:52:58,178 epoch 51 - iter 198/220 - loss 3.75818625 - samples/sec: 318.51 - lr: 0.001563\n",
            "2021-08-10 20:53:00,410 epoch 51 - iter 220/220 - loss 3.77677248 - samples/sec: 315.72 - lr: 0.001563\n",
            "2021-08-10 20:53:00,412 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:53:00,414 EPOCH 51 done: loss 3.7768 - lr 0.0015625\n",
            "2021-08-10 20:53:01,677 DEV : loss 3.312028169631958 - score 0.7088\n",
            "2021-08-10 20:53:01,714 BAD EPOCHS (no improvement): 2\n",
            "2021-08-10 20:53:01,716 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:53:03,924 epoch 52 - iter 22/220 - loss 3.67709358 - samples/sec: 319.36 - lr: 0.001563\n",
            "2021-08-10 20:53:06,145 epoch 52 - iter 44/220 - loss 3.69361875 - samples/sec: 317.47 - lr: 0.001563\n",
            "2021-08-10 20:53:08,338 epoch 52 - iter 66/220 - loss 3.74932916 - samples/sec: 321.35 - lr: 0.001563\n",
            "2021-08-10 20:53:10,557 epoch 52 - iter 88/220 - loss 3.77998427 - samples/sec: 317.71 - lr: 0.001563\n",
            "2021-08-10 20:53:12,695 epoch 52 - iter 110/220 - loss 3.81363997 - samples/sec: 329.62 - lr: 0.001563\n",
            "2021-08-10 20:53:14,883 epoch 52 - iter 132/220 - loss 3.84993362 - samples/sec: 322.20 - lr: 0.001563\n",
            "2021-08-10 20:53:17,137 epoch 52 - iter 154/220 - loss 3.82584506 - samples/sec: 312.77 - lr: 0.001563\n",
            "2021-08-10 20:53:19,320 epoch 52 - iter 176/220 - loss 3.80463957 - samples/sec: 322.89 - lr: 0.001563\n",
            "2021-08-10 20:53:21,613 epoch 52 - iter 198/220 - loss 3.79750122 - samples/sec: 307.37 - lr: 0.001563\n",
            "2021-08-10 20:53:23,838 epoch 52 - iter 220/220 - loss 3.80210751 - samples/sec: 316.78 - lr: 0.001563\n",
            "2021-08-10 20:53:23,839 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:53:23,841 EPOCH 52 done: loss 3.8021 - lr 0.0015625\n",
            "2021-08-10 20:53:25,113 DEV : loss 3.305349349975586 - score 0.7092\n",
            "2021-08-10 20:53:25,150 BAD EPOCHS (no improvement): 3\n",
            "2021-08-10 20:53:25,151 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:53:27,540 epoch 53 - iter 22/220 - loss 3.51368323 - samples/sec: 295.25 - lr: 0.001563\n",
            "2021-08-10 20:53:30,023 epoch 53 - iter 44/220 - loss 3.66356698 - samples/sec: 283.93 - lr: 0.001563\n",
            "2021-08-10 20:53:32,409 epoch 53 - iter 66/220 - loss 3.78208377 - samples/sec: 295.44 - lr: 0.001563\n",
            "2021-08-10 20:53:34,702 epoch 53 - iter 88/220 - loss 3.68931656 - samples/sec: 307.27 - lr: 0.001563\n",
            "2021-08-10 20:53:36,961 epoch 53 - iter 110/220 - loss 3.69765208 - samples/sec: 311.97 - lr: 0.001563\n",
            "2021-08-10 20:53:39,206 epoch 53 - iter 132/220 - loss 3.76147500 - samples/sec: 313.99 - lr: 0.001563\n",
            "2021-08-10 20:53:41,498 epoch 53 - iter 154/220 - loss 3.74539316 - samples/sec: 307.62 - lr: 0.001563\n",
            "2021-08-10 20:53:43,724 epoch 53 - iter 176/220 - loss 3.77101327 - samples/sec: 316.69 - lr: 0.001563\n",
            "2021-08-10 20:53:46,110 epoch 53 - iter 198/220 - loss 3.78671249 - samples/sec: 295.28 - lr: 0.001563\n",
            "2021-08-10 20:53:48,345 epoch 53 - iter 220/220 - loss 3.78662667 - samples/sec: 315.48 - lr: 0.001563\n",
            "2021-08-10 20:53:48,346 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:53:48,347 EPOCH 53 done: loss 3.7866 - lr 0.0015625\n",
            "2021-08-10 20:53:49,680 DEV : loss 3.3058133125305176 - score 0.7092\n",
            "Epoch    53: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2021-08-10 20:53:49,720 BAD EPOCHS (no improvement): 4\n",
            "2021-08-10 20:53:49,722 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:53:52,096 epoch 54 - iter 22/220 - loss 3.92022829 - samples/sec: 297.09 - lr: 0.000781\n",
            "2021-08-10 20:53:54,505 epoch 54 - iter 44/220 - loss 3.92925548 - samples/sec: 292.60 - lr: 0.000781\n",
            "2021-08-10 20:53:57,000 epoch 54 - iter 66/220 - loss 3.93472711 - samples/sec: 282.46 - lr: 0.000781\n",
            "2021-08-10 20:53:59,449 epoch 54 - iter 88/220 - loss 3.82207576 - samples/sec: 287.81 - lr: 0.000781\n",
            "2021-08-10 20:54:01,726 epoch 54 - iter 110/220 - loss 3.82765900 - samples/sec: 309.64 - lr: 0.000781\n",
            "2021-08-10 20:54:03,940 epoch 54 - iter 132/220 - loss 3.82862935 - samples/sec: 318.35 - lr: 0.000781\n",
            "2021-08-10 20:54:06,069 epoch 54 - iter 154/220 - loss 3.83834729 - samples/sec: 331.03 - lr: 0.000781\n",
            "2021-08-10 20:54:08,301 epoch 54 - iter 176/220 - loss 3.83123675 - samples/sec: 315.81 - lr: 0.000781\n",
            "2021-08-10 20:54:10,498 epoch 54 - iter 198/220 - loss 3.81482376 - samples/sec: 320.97 - lr: 0.000781\n",
            "2021-08-10 20:54:12,732 epoch 54 - iter 220/220 - loss 3.81462940 - samples/sec: 315.43 - lr: 0.000781\n",
            "2021-08-10 20:54:12,733 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:54:12,735 EPOCH 54 done: loss 3.8146 - lr 0.0007813\n",
            "2021-08-10 20:54:13,993 DEV : loss 3.3085503578186035 - score 0.7098\n",
            "2021-08-10 20:54:14,030 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 20:54:14,032 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:54:16,250 epoch 55 - iter 22/220 - loss 3.75684087 - samples/sec: 317.98 - lr: 0.000781\n",
            "2021-08-10 20:54:18,463 epoch 55 - iter 44/220 - loss 3.72620980 - samples/sec: 318.60 - lr: 0.000781\n",
            "2021-08-10 20:54:20,736 epoch 55 - iter 66/220 - loss 3.79999798 - samples/sec: 309.96 - lr: 0.000781\n",
            "2021-08-10 20:54:22,952 epoch 55 - iter 88/220 - loss 3.84516543 - samples/sec: 318.11 - lr: 0.000781\n",
            "2021-08-10 20:54:25,205 epoch 55 - iter 110/220 - loss 3.87815302 - samples/sec: 312.91 - lr: 0.000781\n",
            "2021-08-10 20:54:27,547 epoch 55 - iter 132/220 - loss 3.88615525 - samples/sec: 300.94 - lr: 0.000781\n",
            "2021-08-10 20:54:29,751 epoch 55 - iter 154/220 - loss 3.85604808 - samples/sec: 319.80 - lr: 0.000781\n",
            "2021-08-10 20:54:31,970 epoch 55 - iter 176/220 - loss 3.83395964 - samples/sec: 317.53 - lr: 0.000781\n",
            "2021-08-10 20:54:34,136 epoch 55 - iter 198/220 - loss 3.82276049 - samples/sec: 325.42 - lr: 0.000781\n",
            "2021-08-10 20:54:36,261 epoch 55 - iter 220/220 - loss 3.82380391 - samples/sec: 331.66 - lr: 0.000781\n",
            "2021-08-10 20:54:36,263 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:54:36,264 EPOCH 55 done: loss 3.8238 - lr 0.0007813\n",
            "2021-08-10 20:54:37,554 DEV : loss 3.306532621383667 - score 0.7083\n",
            "2021-08-10 20:54:37,592 BAD EPOCHS (no improvement): 2\n",
            "2021-08-10 20:54:37,594 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:54:39,908 epoch 56 - iter 22/220 - loss 3.75431346 - samples/sec: 304.82 - lr: 0.000781\n",
            "2021-08-10 20:54:42,037 epoch 56 - iter 44/220 - loss 3.98913398 - samples/sec: 331.03 - lr: 0.000781\n",
            "2021-08-10 20:54:44,247 epoch 56 - iter 66/220 - loss 3.93833257 - samples/sec: 318.98 - lr: 0.000781\n",
            "2021-08-10 20:54:46,369 epoch 56 - iter 88/220 - loss 3.90332288 - samples/sec: 332.12 - lr: 0.000781\n",
            "2021-08-10 20:54:48,594 epoch 56 - iter 110/220 - loss 3.87530234 - samples/sec: 316.80 - lr: 0.000781\n",
            "2021-08-10 20:54:50,915 epoch 56 - iter 132/220 - loss 3.86165185 - samples/sec: 303.65 - lr: 0.000781\n",
            "2021-08-10 20:54:53,086 epoch 56 - iter 154/220 - loss 3.81808849 - samples/sec: 324.72 - lr: 0.000781\n",
            "2021-08-10 20:54:55,298 epoch 56 - iter 176/220 - loss 3.79626895 - samples/sec: 318.72 - lr: 0.000781\n",
            "2021-08-10 20:54:57,496 epoch 56 - iter 198/220 - loss 3.78074741 - samples/sec: 320.61 - lr: 0.000781\n",
            "2021-08-10 20:54:59,722 epoch 56 - iter 220/220 - loss 3.78469036 - samples/sec: 316.63 - lr: 0.000781\n",
            "2021-08-10 20:54:59,724 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:54:59,725 EPOCH 56 done: loss 3.7847 - lr 0.0007813\n",
            "2021-08-10 20:55:01,011 DEV : loss 3.305368185043335 - score 0.7086\n",
            "2021-08-10 20:55:01,049 BAD EPOCHS (no improvement): 3\n",
            "2021-08-10 20:55:01,051 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:55:03,399 epoch 57 - iter 22/220 - loss 4.09494163 - samples/sec: 300.26 - lr: 0.000781\n",
            "2021-08-10 20:55:05,541 epoch 57 - iter 44/220 - loss 3.92069035 - samples/sec: 329.00 - lr: 0.000781\n",
            "2021-08-10 20:55:07,768 epoch 57 - iter 66/220 - loss 3.87787319 - samples/sec: 316.54 - lr: 0.000781\n",
            "2021-08-10 20:55:09,960 epoch 57 - iter 88/220 - loss 3.83808891 - samples/sec: 321.45 - lr: 0.000781\n",
            "2021-08-10 20:55:12,138 epoch 57 - iter 110/220 - loss 3.80292630 - samples/sec: 323.76 - lr: 0.000781\n",
            "2021-08-10 20:55:14,268 epoch 57 - iter 132/220 - loss 3.79719343 - samples/sec: 330.86 - lr: 0.000781\n",
            "2021-08-10 20:55:16,551 epoch 57 - iter 154/220 - loss 3.83099363 - samples/sec: 308.70 - lr: 0.000781\n",
            "2021-08-10 20:55:18,677 epoch 57 - iter 176/220 - loss 3.80986438 - samples/sec: 331.57 - lr: 0.000781\n",
            "2021-08-10 20:55:20,868 epoch 57 - iter 198/220 - loss 3.81718043 - samples/sec: 321.85 - lr: 0.000781\n",
            "2021-08-10 20:55:23,050 epoch 57 - iter 220/220 - loss 3.79808905 - samples/sec: 323.10 - lr: 0.000781\n",
            "2021-08-10 20:55:23,051 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:55:23,052 EPOCH 57 done: loss 3.7981 - lr 0.0007813\n",
            "2021-08-10 20:55:24,330 DEV : loss 3.3089373111724854 - score 0.7079\n",
            "Epoch    57: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2021-08-10 20:55:24,368 BAD EPOCHS (no improvement): 4\n",
            "2021-08-10 20:55:24,369 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:55:26,579 epoch 58 - iter 22/220 - loss 4.04624342 - samples/sec: 319.47 - lr: 0.000391\n",
            "2021-08-10 20:55:28,754 epoch 58 - iter 44/220 - loss 3.97850081 - samples/sec: 324.01 - lr: 0.000391\n",
            "2021-08-10 20:55:31,008 epoch 58 - iter 66/220 - loss 3.92282664 - samples/sec: 312.79 - lr: 0.000391\n",
            "2021-08-10 20:55:33,230 epoch 58 - iter 88/220 - loss 3.87388444 - samples/sec: 317.26 - lr: 0.000391\n",
            "2021-08-10 20:55:35,499 epoch 58 - iter 110/220 - loss 3.86846434 - samples/sec: 310.66 - lr: 0.000391\n",
            "2021-08-10 20:55:37,711 epoch 58 - iter 132/220 - loss 3.83832479 - samples/sec: 318.67 - lr: 0.000391\n",
            "2021-08-10 20:55:39,888 epoch 58 - iter 154/220 - loss 3.83091965 - samples/sec: 323.71 - lr: 0.000391\n",
            "2021-08-10 20:55:41,988 epoch 58 - iter 176/220 - loss 3.79982073 - samples/sec: 335.77 - lr: 0.000391\n",
            "2021-08-10 20:55:44,284 epoch 58 - iter 198/220 - loss 3.80520345 - samples/sec: 306.86 - lr: 0.000391\n",
            "2021-08-10 20:55:46,472 epoch 58 - iter 220/220 - loss 3.80152170 - samples/sec: 322.18 - lr: 0.000391\n",
            "2021-08-10 20:55:46,474 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:55:46,476 EPOCH 58 done: loss 3.8015 - lr 0.0003906\n",
            "2021-08-10 20:55:47,751 DEV : loss 3.3087849617004395 - score 0.708\n",
            "2021-08-10 20:55:47,790 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 20:55:47,791 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:55:49,968 epoch 59 - iter 22/220 - loss 3.86925508 - samples/sec: 323.97 - lr: 0.000391\n",
            "2021-08-10 20:55:52,096 epoch 59 - iter 44/220 - loss 3.77763315 - samples/sec: 331.27 - lr: 0.000391\n",
            "2021-08-10 20:55:54,298 epoch 59 - iter 66/220 - loss 3.76001095 - samples/sec: 320.09 - lr: 0.000391\n",
            "2021-08-10 20:55:56,574 epoch 59 - iter 88/220 - loss 3.76374002 - samples/sec: 309.67 - lr: 0.000391\n",
            "2021-08-10 20:55:58,763 epoch 59 - iter 110/220 - loss 3.78706343 - samples/sec: 322.07 - lr: 0.000391\n",
            "2021-08-10 20:56:00,929 epoch 59 - iter 132/220 - loss 3.82044528 - samples/sec: 325.31 - lr: 0.000391\n",
            "2021-08-10 20:56:03,194 epoch 59 - iter 154/220 - loss 3.82444944 - samples/sec: 311.20 - lr: 0.000391\n",
            "2021-08-10 20:56:05,385 epoch 59 - iter 176/220 - loss 3.81429984 - samples/sec: 321.76 - lr: 0.000391\n",
            "2021-08-10 20:56:07,553 epoch 59 - iter 198/220 - loss 3.78969579 - samples/sec: 324.99 - lr: 0.000391\n",
            "2021-08-10 20:56:09,949 epoch 59 - iter 220/220 - loss 3.78660462 - samples/sec: 294.29 - lr: 0.000391\n",
            "2021-08-10 20:56:09,950 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:56:09,951 EPOCH 59 done: loss 3.7866 - lr 0.0003906\n",
            "2021-08-10 20:56:11,248 DEV : loss 3.3074302673339844 - score 0.708\n",
            "2021-08-10 20:56:11,285 BAD EPOCHS (no improvement): 2\n",
            "2021-08-10 20:56:11,287 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:56:13,487 epoch 60 - iter 22/220 - loss 3.89892996 - samples/sec: 320.55 - lr: 0.000391\n",
            "2021-08-10 20:56:15,636 epoch 60 - iter 44/220 - loss 3.84805143 - samples/sec: 328.14 - lr: 0.000391\n",
            "2021-08-10 20:56:17,834 epoch 60 - iter 66/220 - loss 3.83251857 - samples/sec: 320.61 - lr: 0.000391\n",
            "2021-08-10 20:56:20,149 epoch 60 - iter 88/220 - loss 3.87153889 - samples/sec: 304.54 - lr: 0.000391\n",
            "2021-08-10 20:56:22,376 epoch 60 - iter 110/220 - loss 3.85307812 - samples/sec: 316.50 - lr: 0.000391\n",
            "2021-08-10 20:56:24,583 epoch 60 - iter 132/220 - loss 3.82280418 - samples/sec: 319.44 - lr: 0.000391\n",
            "2021-08-10 20:56:26,784 epoch 60 - iter 154/220 - loss 3.78409961 - samples/sec: 320.15 - lr: 0.000391\n",
            "2021-08-10 20:56:28,951 epoch 60 - iter 176/220 - loss 3.79649008 - samples/sec: 325.39 - lr: 0.000391\n",
            "2021-08-10 20:56:31,179 epoch 60 - iter 198/220 - loss 3.81136291 - samples/sec: 316.28 - lr: 0.000391\n",
            "2021-08-10 20:56:33,316 epoch 60 - iter 220/220 - loss 3.77302865 - samples/sec: 329.75 - lr: 0.000391\n",
            "2021-08-10 20:56:33,318 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:56:33,319 EPOCH 60 done: loss 3.7730 - lr 0.0003906\n",
            "2021-08-10 20:56:34,588 DEV : loss 3.308622360229492 - score 0.7079\n",
            "2021-08-10 20:56:34,628 BAD EPOCHS (no improvement): 3\n",
            "2021-08-10 20:56:34,629 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:56:37,743 epoch 61 - iter 22/220 - loss 3.52778366 - samples/sec: 226.31 - lr: 0.000391\n",
            "2021-08-10 20:56:40,011 epoch 61 - iter 44/220 - loss 3.65679252 - samples/sec: 310.92 - lr: 0.000391\n",
            "2021-08-10 20:56:42,227 epoch 61 - iter 66/220 - loss 3.63272151 - samples/sec: 318.08 - lr: 0.000391\n",
            "2021-08-10 20:56:44,396 epoch 61 - iter 88/220 - loss 3.69468057 - samples/sec: 324.86 - lr: 0.000391\n",
            "2021-08-10 20:56:46,592 epoch 61 - iter 110/220 - loss 3.72298713 - samples/sec: 321.10 - lr: 0.000391\n",
            "2021-08-10 20:56:48,764 epoch 61 - iter 132/220 - loss 3.73621467 - samples/sec: 324.49 - lr: 0.000391\n",
            "2021-08-10 20:56:50,867 epoch 61 - iter 154/220 - loss 3.72681641 - samples/sec: 335.16 - lr: 0.000391\n",
            "2021-08-10 20:56:53,085 epoch 61 - iter 176/220 - loss 3.76106050 - samples/sec: 317.79 - lr: 0.000391\n",
            "2021-08-10 20:56:55,225 epoch 61 - iter 198/220 - loss 3.76130469 - samples/sec: 329.38 - lr: 0.000391\n",
            "2021-08-10 20:56:57,395 epoch 61 - iter 220/220 - loss 3.78438427 - samples/sec: 324.74 - lr: 0.000391\n",
            "2021-08-10 20:56:57,396 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:56:57,397 EPOCH 61 done: loss 3.7844 - lr 0.0003906\n",
            "2021-08-10 20:56:58,671 DEV : loss 3.307464122772217 - score 0.7082\n",
            "Epoch    61: reducing learning rate of group 0 to 1.9531e-04.\n",
            "2021-08-10 20:56:58,710 BAD EPOCHS (no improvement): 4\n",
            "2021-08-10 20:56:58,712 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:57:00,871 epoch 62 - iter 22/220 - loss 3.71067297 - samples/sec: 326.65 - lr: 0.000195\n",
            "2021-08-10 20:57:03,049 epoch 62 - iter 44/220 - loss 3.79533773 - samples/sec: 323.64 - lr: 0.000195\n",
            "2021-08-10 20:57:05,252 epoch 62 - iter 66/220 - loss 3.79261588 - samples/sec: 319.97 - lr: 0.000195\n",
            "2021-08-10 20:57:07,395 epoch 62 - iter 88/220 - loss 3.76161116 - samples/sec: 328.85 - lr: 0.000195\n",
            "2021-08-10 20:57:09,624 epoch 62 - iter 110/220 - loss 3.73734543 - samples/sec: 316.30 - lr: 0.000195\n",
            "2021-08-10 20:57:11,756 epoch 62 - iter 132/220 - loss 3.74224965 - samples/sec: 330.45 - lr: 0.000195\n",
            "2021-08-10 20:57:14,009 epoch 62 - iter 154/220 - loss 3.73866297 - samples/sec: 312.83 - lr: 0.000195\n",
            "2021-08-10 20:57:16,203 epoch 62 - iter 176/220 - loss 3.79328511 - samples/sec: 321.33 - lr: 0.000195\n",
            "2021-08-10 20:57:18,487 epoch 62 - iter 198/220 - loss 3.78916666 - samples/sec: 308.54 - lr: 0.000195\n",
            "2021-08-10 20:57:20,700 epoch 62 - iter 220/220 - loss 3.79446429 - samples/sec: 318.58 - lr: 0.000195\n",
            "2021-08-10 20:57:20,701 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:57:20,703 EPOCH 62 done: loss 3.7945 - lr 0.0001953\n",
            "2021-08-10 20:57:21,964 DEV : loss 3.307603597640991 - score 0.7079\n",
            "2021-08-10 20:57:22,004 BAD EPOCHS (no improvement): 1\n",
            "2021-08-10 20:57:22,006 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:57:24,272 epoch 63 - iter 22/220 - loss 3.76042402 - samples/sec: 311.16 - lr: 0.000195\n",
            "2021-08-10 20:57:26,426 epoch 63 - iter 44/220 - loss 3.90844526 - samples/sec: 327.17 - lr: 0.000195\n",
            "2021-08-10 20:57:28,614 epoch 63 - iter 66/220 - loss 3.93355501 - samples/sec: 322.25 - lr: 0.000195\n",
            "2021-08-10 20:57:30,823 epoch 63 - iter 88/220 - loss 3.87526978 - samples/sec: 318.98 - lr: 0.000195\n",
            "2021-08-10 20:57:32,991 epoch 63 - iter 110/220 - loss 3.87721826 - samples/sec: 325.08 - lr: 0.000195\n",
            "2021-08-10 20:57:35,109 epoch 63 - iter 132/220 - loss 3.86297539 - samples/sec: 332.86 - lr: 0.000195\n",
            "2021-08-10 20:57:37,392 epoch 63 - iter 154/220 - loss 3.79362339 - samples/sec: 308.67 - lr: 0.000195\n",
            "2021-08-10 20:57:39,565 epoch 63 - iter 176/220 - loss 3.82663914 - samples/sec: 324.35 - lr: 0.000195\n",
            "2021-08-10 20:57:41,812 epoch 63 - iter 198/220 - loss 3.80552637 - samples/sec: 313.68 - lr: 0.000195\n",
            "2021-08-10 20:57:44,061 epoch 63 - iter 220/220 - loss 3.79878607 - samples/sec: 313.38 - lr: 0.000195\n",
            "2021-08-10 20:57:44,062 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:57:44,063 EPOCH 63 done: loss 3.7988 - lr 0.0001953\n",
            "2021-08-10 20:57:45,351 DEV : loss 3.307556629180908 - score 0.7079\n",
            "2021-08-10 20:57:45,388 BAD EPOCHS (no improvement): 2\n",
            "2021-08-10 20:57:45,390 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:57:47,512 epoch 64 - iter 22/220 - loss 3.78282686 - samples/sec: 332.32 - lr: 0.000195\n",
            "2021-08-10 20:57:49,677 epoch 64 - iter 44/220 - loss 3.77483835 - samples/sec: 325.53 - lr: 0.000195\n",
            "2021-08-10 20:57:51,843 epoch 64 - iter 66/220 - loss 3.92590499 - samples/sec: 325.56 - lr: 0.000195\n",
            "2021-08-10 20:57:54,020 epoch 64 - iter 88/220 - loss 3.84979902 - samples/sec: 323.70 - lr: 0.000195\n",
            "2021-08-10 20:57:56,157 epoch 64 - iter 110/220 - loss 3.83650868 - samples/sec: 329.81 - lr: 0.000195\n",
            "2021-08-10 20:57:58,332 epoch 64 - iter 132/220 - loss 3.80910731 - samples/sec: 324.06 - lr: 0.000195\n",
            "2021-08-10 20:58:00,634 epoch 64 - iter 154/220 - loss 3.78989825 - samples/sec: 306.22 - lr: 0.000195\n",
            "2021-08-10 20:58:02,863 epoch 64 - iter 176/220 - loss 3.81340725 - samples/sec: 316.22 - lr: 0.000195\n",
            "2021-08-10 20:58:05,049 epoch 64 - iter 198/220 - loss 3.80819480 - samples/sec: 322.31 - lr: 0.000195\n",
            "2021-08-10 20:58:07,325 epoch 64 - iter 220/220 - loss 3.80734817 - samples/sec: 309.71 - lr: 0.000195\n",
            "2021-08-10 20:58:07,327 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:58:07,328 EPOCH 64 done: loss 3.8073 - lr 0.0001953\n",
            "2021-08-10 20:58:08,594 DEV : loss 3.307065010070801 - score 0.7079\n",
            "2021-08-10 20:58:08,632 BAD EPOCHS (no improvement): 3\n",
            "2021-08-10 20:58:08,634 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:58:10,854 epoch 65 - iter 22/220 - loss 3.70553483 - samples/sec: 317.62 - lr: 0.000195\n",
            "2021-08-10 20:58:12,997 epoch 65 - iter 44/220 - loss 3.76438696 - samples/sec: 328.90 - lr: 0.000195\n",
            "2021-08-10 20:58:15,129 epoch 65 - iter 66/220 - loss 3.82390849 - samples/sec: 330.69 - lr: 0.000195\n",
            "2021-08-10 20:58:17,309 epoch 65 - iter 88/220 - loss 3.82247961 - samples/sec: 323.26 - lr: 0.000195\n",
            "2021-08-10 20:58:19,501 epoch 65 - iter 110/220 - loss 3.80931255 - samples/sec: 321.54 - lr: 0.000195\n",
            "2021-08-10 20:58:21,819 epoch 65 - iter 132/220 - loss 3.83636326 - samples/sec: 304.01 - lr: 0.000195\n",
            "2021-08-10 20:58:23,986 epoch 65 - iter 154/220 - loss 3.83459590 - samples/sec: 325.26 - lr: 0.000195\n",
            "2021-08-10 20:58:26,098 epoch 65 - iter 176/220 - loss 3.85461576 - samples/sec: 333.85 - lr: 0.000195\n",
            "2021-08-10 20:58:28,315 epoch 65 - iter 198/220 - loss 3.84416276 - samples/sec: 317.83 - lr: 0.000195\n",
            "2021-08-10 20:58:30,461 epoch 65 - iter 220/220 - loss 3.82519129 - samples/sec: 328.43 - lr: 0.000195\n",
            "2021-08-10 20:58:30,462 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:58:30,463 EPOCH 65 done: loss 3.8252 - lr 0.0001953\n",
            "2021-08-10 20:58:31,722 DEV : loss 3.3071250915527344 - score 0.7079\n",
            "Epoch    65: reducing learning rate of group 0 to 9.7656e-05.\n",
            "2021-08-10 20:58:31,758 BAD EPOCHS (no improvement): 4\n",
            "2021-08-10 20:58:31,760 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:58:31,763 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:58:31,764 learning rate too small - quitting training!\n",
            "2021-08-10 20:58:31,767 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:58:34,102 ----------------------------------------------------------------------------------------------------\n",
            "2021-08-10 20:58:34,104 Testing using best model ...\n",
            "2021-08-10 20:58:34,106 loading file resources/taggers/example-pos/best-model.pt\n",
            "2021-08-10 20:58:38,304 0.7173\t0.7139\t0.7156\n",
            "2021-08-10 20:58:38,305 \n",
            "Results:\n",
            "- F1-score (micro) 0.7156\n",
            "- F1-score (macro) 0.5709\n",
            "\n",
            "By class:\n",
            "Actor      tp: 1210 - fp: 112 - fn: 64 - precision: 0.9153 - recall: 0.9498 - f1-score: 0.9322\n",
            "Award      tp: 30 - fp: 35 - fn: 36 - precision: 0.4615 - recall: 0.4545 - f1-score: 0.4580\n",
            "Character_Name tp: 167 - fp: 73 - fn: 116 - precision: 0.6958 - recall: 0.5901 - f1-score: 0.6386\n",
            "Director   tp: 394 - fp: 92 - fn: 31 - precision: 0.8107 - recall: 0.9271 - f1-score: 0.8650\n",
            "Genre      tp: 589 - fp: 233 - fn: 200 - precision: 0.7165 - recall: 0.7465 - f1-score: 0.7312\n",
            "Opinion    tp: 81 - fp: 106 - fn: 114 - precision: 0.4332 - recall: 0.4154 - f1-score: 0.4241\n",
            "Origin     tp: 71 - fp: 98 - fn: 119 - precision: 0.4201 - recall: 0.3737 - f1-score: 0.3955\n",
            "Plot       tp: 775 - fp: 751 - fn: 802 - precision: 0.5079 - recall: 0.4914 - f1-score: 0.4995\n",
            "Quote      tp: 13 - fp: 10 - fn: 34 - precision: 0.5652 - recall: 0.2766 - f1-score: 0.3714\n",
            "Relationship tp: 88 - fp: 46 - fn: 83 - precision: 0.6567 - recall: 0.5146 - f1-score: 0.5770\n",
            "Soundtrack tp: 0 - fp: 8 - fn: 8 - precision: 0.0000 - recall: 0.0000 - f1-score: 0.0000\n",
            "Year       tp: 641 - fp: 36 - fn: 20 - precision: 0.9468 - recall: 0.9697 - f1-score: 0.9581\n",
            "2021-08-10 20:58:38,307 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [11.056137084960938,\n",
              "  6.994250297546387,\n",
              "  6.255899429321289,\n",
              "  5.731180191040039,\n",
              "  4.86782169342041,\n",
              "  4.831173419952393,\n",
              "  4.531966686248779,\n",
              "  4.474660396575928,\n",
              "  4.210536956787109,\n",
              "  4.048767566680908,\n",
              "  3.975076913833618,\n",
              "  4.236865997314453,\n",
              "  3.994971752166748,\n",
              "  3.789268732070923,\n",
              "  3.8494579792022705,\n",
              "  3.8864622116088867,\n",
              "  3.9349114894866943,\n",
              "  3.640432357788086,\n",
              "  3.753237009048462,\n",
              "  3.5540337562561035,\n",
              "  3.592362403869629,\n",
              "  3.474743604660034,\n",
              "  3.4817867279052734,\n",
              "  3.464876890182495,\n",
              "  3.5183303356170654,\n",
              "  3.506711721420288,\n",
              "  3.4504611492156982,\n",
              "  3.484105110168457,\n",
              "  3.4307191371917725,\n",
              "  3.440380811691284,\n",
              "  3.3953638076782227,\n",
              "  3.4269495010375977,\n",
              "  3.4015071392059326,\n",
              "  3.366137981414795,\n",
              "  3.335923194885254,\n",
              "  3.3983073234558105,\n",
              "  3.3886404037475586,\n",
              "  3.3519036769866943,\n",
              "  3.3473570346832275,\n",
              "  3.3135433197021484,\n",
              "  3.3447988033294678,\n",
              "  3.3290343284606934,\n",
              "  3.330641984939575,\n",
              "  3.321019172668457,\n",
              "  3.3188891410827637,\n",
              "  3.305068016052246,\n",
              "  3.3102598190307617,\n",
              "  3.318877696990967,\n",
              "  3.312084913253784,\n",
              "  3.3115923404693604,\n",
              "  3.312028169631958,\n",
              "  3.305349349975586,\n",
              "  3.3058133125305176,\n",
              "  3.3085503578186035,\n",
              "  3.306532621383667,\n",
              "  3.305368185043335,\n",
              "  3.3089373111724854,\n",
              "  3.3087849617004395,\n",
              "  3.3074302673339844,\n",
              "  3.308622360229492,\n",
              "  3.307464122772217,\n",
              "  3.307603597640991,\n",
              "  3.307556629180908,\n",
              "  3.307065010070801,\n",
              "  3.3071250915527344],\n",
              " 'dev_score_history': [0.4601431980906921,\n",
              "  0.571496324401233,\n",
              "  0.5662847790507365,\n",
              "  0.6098572086596039,\n",
              "  0.6447488584474886,\n",
              "  0.6526932612125309,\n",
              "  0.6645116601246825,\n",
              "  0.6567967698519516,\n",
              "  0.6589411497386958,\n",
              "  0.6713700500682749,\n",
              "  0.6728172817281728,\n",
              "  0.6647072122993444,\n",
              "  0.688883918586446,\n",
              "  0.6873023045639404,\n",
              "  0.6812443642921551,\n",
              "  0.6850481954718673,\n",
              "  0.6810616284300496,\n",
              "  0.6946616037525128,\n",
              "  0.6967157417893546,\n",
              "  0.7052280311457174,\n",
              "  0.6946803755029056,\n",
              "  0.7083427029458061,\n",
              "  0.6958089229382605,\n",
              "  0.7124270973530731,\n",
              "  0.6967396158999554,\n",
              "  0.6978513876454789,\n",
              "  0.7154070419376543,\n",
              "  0.703125,\n",
              "  0.6999325691166555,\n",
              "  0.7047279214986619,\n",
              "  0.7082025997310624,\n",
              "  0.7088046129962297,\n",
              "  0.7154579729430028,\n",
              "  0.7050938337801608,\n",
              "  0.7116976067993739,\n",
              "  0.7054367201426025,\n",
              "  0.7054871220604703,\n",
              "  0.7101093505913858,\n",
              "  0.7087421944692239,\n",
              "  0.7063296801610378,\n",
              "  0.7058035714285714,\n",
              "  0.712884529647793,\n",
              "  0.7105263157894737,\n",
              "  0.7086403215003347,\n",
              "  0.7122125474436257,\n",
              "  0.7108138238573021,\n",
              "  0.7108138238573021,\n",
              "  0.710625974604589,\n",
              "  0.7095333779861577,\n",
              "  0.709691826708352,\n",
              "  0.7088268156424581,\n",
              "  0.7092451987494416,\n",
              "  0.7092166927025219,\n",
              "  0.7097925496319429,\n",
              "  0.7083240348136576,\n",
              "  0.7086122266845158,\n",
              "  0.7078777058692255,\n",
              "  0.7080357142857142,\n",
              "  0.7080357142857142,\n",
              "  0.7078777058692255,\n",
              "  0.7081659973226238,\n",
              "  0.7078777058692255,\n",
              "  0.7078777058692255,\n",
              "  0.7078777058692255,\n",
              "  0.7078777058692255],\n",
              " 'test_score': 0.7155575143234905,\n",
              " 'train_loss_history': [24.51417723785747,\n",
              "  11.196989737857471,\n",
              "  8.512778563932939,\n",
              "  7.499400112845681,\n",
              "  6.860959033532576,\n",
              "  6.439304273778742,\n",
              "  6.11960089748556,\n",
              "  5.871568653800271,\n",
              "  5.610373965176669,\n",
              "  5.539740232987837,\n",
              "  5.352048115296797,\n",
              "  5.2790012316270305,\n",
              "  5.155916784026406,\n",
              "  5.053621331128207,\n",
              "  5.024665551835841,\n",
              "  4.91898378350518,\n",
              "  4.8466531991958615,\n",
              "  4.563992150263353,\n",
              "  4.475215957381509,\n",
              "  4.434929569201036,\n",
              "  4.394053922999989,\n",
              "  4.342332496426322,\n",
              "  4.316195214878429,\n",
              "  4.3328267921100965,\n",
              "  4.292567738619717,\n",
              "  4.252374445308338,\n",
              "  4.2287580002437934,\n",
              "  4.219326368245212,\n",
              "  4.165485324642875,\n",
              "  4.165365730632435,\n",
              "  4.129052438519218,\n",
              "  4.037877580252561,\n",
              "  4.016015325893055,\n",
              "  3.974324369430542,\n",
              "  3.984361915154891,\n",
              "  3.9764912377704276,\n",
              "  3.925077952038158,\n",
              "  3.9509867072105407,\n",
              "  3.8903007279742847,\n",
              "  3.9016326785087587,\n",
              "  3.891228835149245,\n",
              "  3.848962517218156,\n",
              "  3.8500026746229694,\n",
              "  3.8342095906084235,\n",
              "  3.8523762182755905,\n",
              "  3.818523423238234,\n",
              "  3.8054943149740046,\n",
              "  3.806347503445365,\n",
              "  3.814778785272078,\n",
              "  3.802772895856337,\n",
              "  3.776772484996102,\n",
              "  3.802107508616014,\n",
              "  3.786626672744751,\n",
              "  3.8146294019439004,\n",
              "  3.823803909258409,\n",
              "  3.78469035950574,\n",
              "  3.798089053955945,\n",
              "  3.8015217000787906,\n",
              "  3.7866046222773466,\n",
              "  3.773028652234511,\n",
              "  3.784384267980402,\n",
              "  3.794464286890897,\n",
              "  3.798786071213809,\n",
              "  3.8073481733148746,\n",
              "  3.8251912864771755]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPn-KtHV4LFL"
      },
      "source": [
        "#### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjVMZ2bc4M8S"
      },
      "source": [
        "# Individual class scores and overall scores, generated in the training.log file (at the very end).\n",
        "# https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin\n",
        "\"\"\"\n",
        "Results:\n",
        "- F1-score (micro) 0.7156\n",
        "- F1-score (macro) 0.5709\n",
        "\n",
        "By class:\n",
        "Actor      tp: 1210 - fp: 112 - fn: 64 - precision: 0.9153 - recall: 0.9498 - f1-score: 0.9322\n",
        "Award      tp: 30 - fp: 35 - fn: 36 - precision: 0.4615 - recall: 0.4545 - f1-score: 0.4580\n",
        "Character_Name tp: 167 - fp: 73 - fn: 116 - precision: 0.6958 - recall: 0.5901 - f1-score: 0.6386\n",
        "Director   tp: 394 - fp: 92 - fn: 31 - precision: 0.8107 - recall: 0.9271 - f1-score: 0.8650\n",
        "Genre      tp: 589 - fp: 233 - fn: 200 - precision: 0.7165 - recall: 0.7465 - f1-score: 0.7312\n",
        "Opinion    tp: 81 - fp: 106 - fn: 114 - precision: 0.4332 - recall: 0.4154 - f1-score: 0.4241\n",
        "Origin     tp: 71 - fp: 98 - fn: 119 - precision: 0.4201 - recall: 0.3737 - f1-score: 0.3955\n",
        "Plot       tp: 775 - fp: 751 - fn: 802 - precision: 0.5079 - recall: 0.4914 - f1-score: 0.4995\n",
        "Quote      tp: 13 - fp: 10 - fn: 34 - precision: 0.5652 - recall: 0.2766 - f1-score: 0.3714\n",
        "Relationship tp: 88 - fp: 46 - fn: 83 - precision: 0.6567 - recall: 0.5146 - f1-score: 0.5770\n",
        "Soundtrack tp: 0 - fp: 8 - fn: 8 - precision: 0.0000 - recall: 0.0000 - f1-score: 0.0000\n",
        "Year       tp: 641 - fp: 36 - fn: 20 - precision: 0.9468 - recall: 0.9697 - f1-score: 0.9581\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "uxv5K-hl5Li6",
        "outputId": "5cf3b199-bca0-4ba3-ac51-248be7c3673b"
      },
      "source": [
        "# Read the loss.tsv\n",
        "import pandas as pd\n",
        "df = pd.read_csv('resources/taggers/example-pos/loss.tsv', sep='\\t', header=0)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EPOCH</th>\n",
              "      <th>TIMESTAMP</th>\n",
              "      <th>BAD_EPOCHS</th>\n",
              "      <th>LEARNING_RATE</th>\n",
              "      <th>TRAIN_LOSS</th>\n",
              "      <th>DEV_LOSS</th>\n",
              "      <th>DEV_PRECISION</th>\n",
              "      <th>DEV_RECALL</th>\n",
              "      <th>DEV_F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>20:32:50</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>24.514177</td>\n",
              "      <td>11.056137</td>\n",
              "      <td>0.5010</td>\n",
              "      <td>0.4254</td>\n",
              "      <td>0.4601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20:33:16</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>11.196990</td>\n",
              "      <td>6.994250</td>\n",
              "      <td>0.6176</td>\n",
              "      <td>0.5318</td>\n",
              "      <td>0.5715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>20:33:42</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>8.512779</td>\n",
              "      <td>6.255899</td>\n",
              "      <td>0.6022</td>\n",
              "      <td>0.5344</td>\n",
              "      <td>0.5663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>20:34:05</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>7.499400</td>\n",
              "      <td>5.731180</td>\n",
              "      <td>0.6378</td>\n",
              "      <td>0.5843</td>\n",
              "      <td>0.6099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>20:34:31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>6.860959</td>\n",
              "      <td>4.867822</td>\n",
              "      <td>0.6679</td>\n",
              "      <td>0.6231</td>\n",
              "      <td>0.6447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>61</td>\n",
              "      <td>20:56:58</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>3.784384</td>\n",
              "      <td>3.307464</td>\n",
              "      <td>0.7162</td>\n",
              "      <td>0.7004</td>\n",
              "      <td>0.7082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>62</td>\n",
              "      <td>20:57:22</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>3.794464</td>\n",
              "      <td>3.307604</td>\n",
              "      <td>0.7160</td>\n",
              "      <td>0.6999</td>\n",
              "      <td>0.7079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>63</td>\n",
              "      <td>20:57:45</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>3.798786</td>\n",
              "      <td>3.307557</td>\n",
              "      <td>0.7160</td>\n",
              "      <td>0.6999</td>\n",
              "      <td>0.7079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>64</td>\n",
              "      <td>20:58:08</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>3.807348</td>\n",
              "      <td>3.307065</td>\n",
              "      <td>0.7160</td>\n",
              "      <td>0.6999</td>\n",
              "      <td>0.7079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>65</td>\n",
              "      <td>20:58:31</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>3.825191</td>\n",
              "      <td>3.307125</td>\n",
              "      <td>0.7160</td>\n",
              "      <td>0.6999</td>\n",
              "      <td>0.7079</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>65 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    EPOCH TIMESTAMP  BAD_EPOCHS  ...  DEV_PRECISION  DEV_RECALL  DEV_F1\n",
              "0       1  20:32:50           0  ...         0.5010      0.4254  0.4601\n",
              "1       2  20:33:16           0  ...         0.6176      0.5318  0.5715\n",
              "2       3  20:33:42           1  ...         0.6022      0.5344  0.5663\n",
              "3       4  20:34:05           0  ...         0.6378      0.5843  0.6099\n",
              "4       5  20:34:31           0  ...         0.6679      0.6231  0.6447\n",
              "..    ...       ...         ...  ...            ...         ...     ...\n",
              "60     61  20:56:58           4  ...         0.7162      0.7004  0.7082\n",
              "61     62  20:57:22           1  ...         0.7160      0.6999  0.7079\n",
              "62     63  20:57:45           2  ...         0.7160      0.6999  0.7079\n",
              "63     64  20:58:08           3  ...         0.7160      0.6999  0.7079\n",
              "64     65  20:58:31           4  ...         0.7160      0.6999  0.7079\n",
              "\n",
              "[65 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7Wz7DMV9rbB"
      },
      "source": [
        "* Final training loss : 3.825191\n",
        "* Final dev loss : 3.307125\t\n",
        "* Final dev precision : 0.7160\t\n",
        "* Final dev recall : 0.6999\n",
        "* Final dev F1 score : 0.7079\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "ecz8XrHL5hOK",
        "outputId": "aa905209-70c1-47e1-cda8-8b3fa281105c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "font = {'family':'serif','color':'darkred','size':15}\n",
        "fontHead = {'family':'serif','color':'blue','size':20}\n",
        "\n",
        "plt.plot(df[\"TRAIN_LOSS\"],color=\"orange\",label='Train loss')\n",
        "plt.plot(df[\"DEV_LOSS\"],label='Dev loss')\n",
        "plt.xlabel(\"Epoch\",fontdict = font)\n",
        "plt.ylabel(\"Loss\",fontdict = font)\n",
        "plt.title(\"Loss wrt epoch\",fontdict=fontHead)\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "OoJ5krnc7ZgB",
        "outputId": "ad94d890-77ac-4d2a-821f-54eaff0affd0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "font = {'family':'serif','color':'darkred','size':15}\n",
        "fontHead = {'family':'serif','color':'blue','size':20}\n",
        "\n",
        "plt.plot(df[\"DEV_PRECISION\"],color=\"orange\",label='Dev Precision')\n",
        "plt.plot(df[\"DEV_RECALL\"],label='Dev Recall')\n",
        "plt.plot(df[\"DEV_F1\"],color=\"red\",label='Dev F1')\n",
        "plt.xlabel(\"Epoch\",fontdict = font)\n",
        "plt.ylabel(\"Measure\",fontdict = font)\n",
        "plt.title(\"Dev Precision/Recall and F1 wrt epoch\",fontdict=fontHead)\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WQc8oz88ZGB"
      },
      "source": [
        "#### Few Prediction made by trained model on test set\n",
        "The predcitions can be viewed in the file generated test.tsv.\n",
        "It contains predictions as follows, wher first column is the word, second is the actual tag and third is the predicted tag:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM_s85XI8uDA"
      },
      "source": [
        "# First example of test file. all tags are correctly predicted (Format: Word, Actual Tag, Predicted Tag)\n",
        "\"\"\"\n",
        "i O O\n",
        "need O O\n",
        "that O O\n",
        "movie O O\n",
        "which O O\n",
        "involves O B-Plot\n",
        "aliens B-Plot I-Plot\n",
        "invading I-Plot I-Plot\n",
        "earth I-Plot I-Plot\n",
        "in I-Plot I-Plot\n",
        "a I-Plot I-Plot\n",
        "particular I-Plot I-Plot\n",
        "united I-Plot I-Plot\n",
        "states I-Plot I-Plot\n",
        "place I-Plot I-Plot\n",
        "in I-Plot I-Plot\n",
        "california I-Plot I-Plot\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDqNTu2K8wJY"
      },
      "source": [
        "# Second example of test file, excepted the tag for word 'remade' all are correctlt predected\n",
        "\"\"\"\n",
        "what O O\n",
        "soviet B-Genre B-Genre\n",
        "science I-Genre I-Genre\n",
        "fiction I-Genre I-Genre\n",
        "classic B-Opinion I-Genre\n",
        "about O O\n",
        "a B-Plot B-Plot\n",
        "mysterious I-Plot I-Plot\n",
        "planet I-Plot I-Plot\n",
        "was O O\n",
        "later O O\n",
        "remade B-Relationship O\n",
        "by O O\n",
        "steven B-Director B-Director\n",
        "soderbergh I-Director I-Director\n",
        "and O O\n",
        "george B-Actor B-Actor\n",
        "clooney I-Actor I-Actor\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEHsziZK-Erp"
      },
      "source": [
        "#### Some prediction made by self made example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N22HGcPv-JPL",
        "outputId": "7fac1d6b-0827-45c6-ecba-95ccde592061"
      },
      "source": [
        "model = SequenceTagger.load('resources/taggers/example-pos/final-model.pt') # load the trained model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-10 21:32:24,168 loading file resources/taggers/example-pos/final-model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxmjBtXF-XR5",
        "outputId": "f47a181d-3482-4396-9f87-bc1ecc334fbf"
      },
      "source": [
        "sentence = Sentence('list the five star rated movies starring mel gibson')\n",
        "model.predict(sentence) # predict the tags\n",
        "print(sentence.to_tagged_string())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "list the five star rated movies starring mel <B-Actor> gibson <I-Actor>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dg98qJSI-aCZ",
        "outputId": "0e2e4287-7e36-467f-d488-310d92ec01b1"
      },
      "source": [
        "sentence = Sentence('want to see an indian movie')\n",
        "model.predict(sentence) # predict the tags\n",
        "print(sentence.to_tagged_string())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "want to see an indian <B-Genre> movie\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4K3QEycc-ggB",
        "outputId": "7ab79cee-2a72-49f5-804a-944e804a7309"
      },
      "source": [
        "sentence = Sentence('which is the latest movie directed by Martin Scorsese')\n",
        "model.predict(sentence) # predict the tags\n",
        "print(sentence.to_tagged_string())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "which is the latest movie directed by Martin <B-Director> Scorsese <I-Director>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w33_Qo0u-x1y"
      },
      "source": [
        "It works good!!"
      ]
    }
  ]
}